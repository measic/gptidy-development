{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["<h1>Data Processing Model</h1>"]}, {"cell_type": "code", "execution_count": 1, "metadata": {"collapsed": true}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import os\n", "from scipy import stats\n", "\n", "from sklearn.preprocessing import OneHotEncoder"]}, {"cell_type": "code", "execution_count": 2, "metadata": {"collapsed": true}, "outputs": [], "source": ["# some global variables\n", "\n", "data_filepath = \"./data/\"\n"]}, {"cell_type": "code", "execution_count": 3, "metadata": {"collapsed": true}, "outputs": [], "source": ["def is_int(x):\n", "    try: \n", "        int(x)\n", "        return True\n", "    except ValueError:\n", "        return False"]}, {"cell_type": "code", "execution_count": 4, "metadata": {"collapsed": true}, "outputs": [], "source": ["def NONE(X):\n", "    \"\"\"Return the values - placeholder function for other operations\"\"\"\n", "    return X"]}, {"cell_type": "code", "execution_count": 5, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Encoding Functions\n", "\n", "def MAP(X):\n", "    \"\"\"Map all values to integer numbers.\"\"\"\n", "    \"\"\"NaN values are treated as a unique value.\"\"\"\n", "    \n", "    # create an encoding for categorical vars\n", "    unique_elems = set(X)\n", "    mapping = {label:idx for idx, label in enumerate(unique_elems)}\n", "    return X.map(mapping).astype(int)\n", "\n", "def LOO(X):\n", "    \"\"\"Perform Leave One Out counting for the features.\"\"\"\n", "    \n", "    # map features to ordinal values first\n", "    X = MAP(X)\n", "    \n", "    # perform counts\n", "    mapping = {idx:(count-1) for idx, count in enumerate(np.bincount(X))}\n", "    return X.map(mapping).astype(int)\n", "    \n", "\n", "def OHE(df_cv, df_all, col_name, feature_names, feature_threshold=0.02):\n", "    \"\"\"Map categorical values to a one hot encoding scheme.\"\"\"\n", "    \n", "    X_cv = MAP(df_cv[col_name])\n", "    X_all = MAP(df_all[col_name])\n", "    \n", "    X_cv = X_cv.values.reshape(-1, 1)\n", "    X_all = X_all.values.reshape(-1, 1)\n", "    OHE = OneHotEncoder(sparse=False).fit(X_all)\n", "    X_cv_ohe = OHE.transform(X_cv)\n", "    X_all_ohe = OHE.transform(X_all)\n", "    \n", "    low_freq_features = []\n", "    for i in range(X_all_ohe.shape[1]):\n", "        new_feature = col_name + str(i)\n", "        \n", "        # determine the frequency of the categorical data value\n", "        freq = np.sum(X_all_ohe[:, i]) / X_all_ohe.shape[0]\n", "        if freq > feature_threshold:\n", "            df_cv[new_feature] = X_cv_ohe[:, i]\n", "            df_all[new_feature] = X_all_ohe[:, i]\n", "            feature_names.append(new_feature)\n", "        else:\n", "            low_freq_features.append(i)\n", "    \n", "    # aggregate low frequency features\n", "    if len(low_freq_features) > 0:\n", "        extra_label = col_name + str(X_all_ohe.shape[1])\n", "        feature_names.append(extra_label)\n", "        \n", "        X_all_extra = np.array([0 for x in range(X_all.shape[0])])\n", "        X_cv_extra = np.array([0 for x in range(X_cv.shape[0])])\n", "        \n", "        for i in low_freq_features:\n", "            for idx, val in enumerate(X_all_ohe[:, i]):\n", "                if val == 1:\n", "                    X_all_extra[idx] = 1\n", "            for idx, val in enumerate(X_cv_ohe[:, i]):\n", "                if val == 1:\n", "                    X_cv_extra[idx] = 1\n", "        \n", "        df_cv[extra_label] = X_cv_extra\n", "        df_all[extra_label] = X_all_extra                    \n", "            \n", "    feature_names.remove(col_name)\n", "    df_cv = df_cv.drop(col_name, axis=1)\n", "    df_all = df_all.drop(col_name, axis=1)\n", "    \n", "    return df_cv, df_all, feature_names\n", "\n"]}, {"cell_type": "code", "execution_count": 6, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Scaling Functions\n", "\n", "def NRM1(X):\n", "    \"\"\"Scale by dividing by the 1-norm\"\"\"\n", "    norm = np.linalg.norm(X, ord=1)\n", "    return X / norm\n", "\n", "def SCL1(X):\n", "    \"\"\"Scale between (-1, 1)\"\"\"\n", "    mean = X.mean()\n", "    maximum = X.max()\n", "    minimum = X.min()\n", "    return (X - mean) / (maximum - minimum)\n", "\n", "def TRSH(X, threshold_value=20):\n", "    X = [0 if val < threshold_value else 1 for val in X]\n", "    return X"]}, {"cell_type": "code", "execution_count": 7, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Imputing Functions\n", "\n", "def UNIQ(X, value=-1):\n", "    \"\"\"Replace missing Values with unique value\"\"\"\n", "    \n", "    X.fillna(value=value, inplace=True)    \n", "    return X\n", "\n", "def MEAN(X):\n", "    \"\"\"Replace missing values with the mean of the others\"\"\"\n", "    \n", "    mean = np.mean(X)\n", "    X.fillna(value=mean, inplace=True)\n", "    return X\n", "\n", "def MED(X):\n", "    \"\"\"Replace missing values with median of data\"\"\"\n", "    \n", "    median = np.nanmedian(X)\n", "    X.fillna(value=median, inplace=True)\n", "    return X\n", "\n", "def CONST(X, value=0):\n", "    \"\"\"Replace missing values with a constant.\"\"\"\n", "    \n", "    X.fillna(value=int(value), inplace=True)\n", "    return X\n", "\n", "def MODE(X):\n", "    \"\"\"Replace missing values with the mode.\"\"\"\n", "    \n", "    mode = stats.mode(X)[0][0]\n", "    X.fillna(value=mode, inplace=True)\n", "    return X\n", "\n", "def DEL(df_cv, df_all, col_name, feature_names):\n", "    df_cv = df_cv.drop(col_name, axis=1)\n", "    df_all = df_all.drop(col_name, axis=1)\n", "    feature_names.remove(col_name)\n", "    \n", "    return df_cv, df_all, feature_names"]}, {"cell_type": "code", "execution_count": 8, "metadata": {"collapsed": true}, "outputs": [], "source": ["class Preprocessor:\n", "    \n", "    def __init__(self, train_data_file, train_label_file, train_ids_file,\n", "                 instr_file, test_data_file=None, test_ids_file=None):\n", "        \"\"\"A class to process and reformat data\n", "        for use in learning models\"\"\"\n", "        \n", "        # initialize the data the data filenames\n", "        self.train_data_file = train_data_file\n", "        self.train_label_file = train_label_file\n", "        self.train_ids_file = train_ids_file\n", "        self.instr_file = instr_file\n", "        \n", "        # test data is optional\n", "        self.test_data_file = test_data_file\n", "        self.test_ids_file = test_ids_file\n", "        \n", "    def read_data(self):\n", "        \"\"\"Reads in data from the files passed to constructor\"\"\"\n", "        \n", "        # read in the data\n", "        train_X_df = pd.read_csv(self.train_data_file)\n", "        train_y_df = pd.read_csv(self.train_label_file)\n", "        train_ids_df = pd.read_csv(self.train_ids_file)\n", "        self.instr_df = pd.read_csv(self.instr_file)\n", "        \n", "        self.feature_names = [feature for feature in train_X_df]\n", "        self.original_feature_names = [feature for feature in train_X_df]\n", "        self.label_names = [feature for feature in train_y_df]\n", "        self.id_names = [feature for feature in train_ids_df]\n", "        \n", "        # create cross validation data\n", "        self.cv_X_df = pd.DataFrame(train_X_df)\n", "        self.cv_y_df = pd.DataFrame(train_y_df)\n", "        self.cv_ids_df = pd.DataFrame(train_ids_df)\n", "        \n", "        # read in the test data if it exists\n", "        if self.test_data_file != None:\n", "            self.test_X_df = pd.read_csv(self.test_data_file)\n", "            self.test_ids_df = pd.read_csv(self.test_ids_file)\n", "            self.all_X_df = train_X_df.append(self.test_X_df)\n", "        else:\n", "            self.test_X_df = None\n", "            self.test_ids_df = None\n", "            self.all_X_df = pd.DataFrame(train_X_df)\n", "        \n", "        # determine the shape of the input data\n", "        self.train_X_shape = train_X_df.shape\n", "        self.train_y_shape = train_y_df.shape\n", "        self.train_ids_shape = train_ids_df.shape\n", "        self.instr_shape = self.instr_df.shape\n", "        self.all_shape = self.all_X_df.shape\n", "        \n", "        # get size of test data if it exists\n", "        if self.test_data_file != None:\n", "            self.test_X_shape = self.test_X_df.shape\n", "            self.test_ids_shape = self.test_ids_df.shape\n", "        else:\n", "            self.test_X_shape = None\n", "            self.test_ids_shape = None\n", "\n", "        \n", "    def process(self, shuffle_train_data=False):\n", "        \"\"\"Performs the processing on cross validation and train/test data\"\"\"\n", "        \n", "        # ADD OPTION TO SHUFFLE DATA HERE\n", "        \n", "        # processing on all data - remember to include cv_X and all_X for each condition\n", "        for col in self.original_feature_names:\n", "            print(col)\n", "            \n", "            # determine what to perform at each of the steps\n", "            col_instr = self.instr_df[col].values\n", "            col_enc = col_instr[1]\n", "            col_scl = col_instr[2]\n", "            col_imp = col_instr[3]\n", "\n", "            # impute values\n", "            # imputed first so that other functions will not use nan values in calculations\n", "            if col_imp == 'UNIQ':\n", "                self.cv_X_df[col] = UNIQ(self.cv_X_df[col], value=-1)\n", "                self.all_X_df[col] = UNIQ(self.all_X_df[col], value=-1)\n", "            if col_imp == 'MEAN':\n", "                self.cv_X_df[col] = MEAN(self.cv_X_df[col])\n", "                self.all_X_df[col] = MEAN(self.all_X_df[col])\n", "            if col_imp == 'MODE':\n", "                self.cv_X_df[col] = MODE(self.cv_X_df[col])\n", "                self.all_X_df[col] = MODE(self.all_X_df[col])\n", "            if col_imp == 'MED':\n", "                self.cv_X_df[col] = MED(self.cv_X_df[col])\n", "                self.all_X_df[col] = MED(self.all_X_df[col])\n", "            if is_int(col_imp):\n", "                self.cv_X_df[col] = CONST(self.cv_X_df[col], col_imp)\n", "                self.all_X_df[col] = CONST(self.all_X_df[col], col_imp)\n", "            if col_imp == 'DEL':\n", "                self.cv_X_df, self.all_X_df, self.feature_names = DEL(\n", "                    self.cv_X_df, self.all_X_df, col, self.feature_names)\n", "            \n", "            \n", "            # perform encoding of data\n", "            if col_enc == 'MAP':\n", "                self.cv_X_df[col] = MAP(self.cv_X_df[col])\n", "                self.all_X_df[col] = MAP(self.all_X_df[col])\n", "            if col_enc == 'OHE':\n", "                self.cv_X_df, self.all_X_df, self.feature_names = OHE(\n", "                    df_cv=self.cv_X_df, df_all=self.all_X_df, col_name=col, \n", "                    feature_names=self.feature_names)\n", "            if col_enc == 'LOO':\n", "                self.cv_X_df[col] = LOO(self.cv_X_df[col])\n", "                self.all_X_df[col] = LOO(self.all_X_df[col])\n", "            \n", "\n", "            # perform scaling\n", "            if col_scl == 'NRM1':\n", "                self.cv_X_df[col] = NRM1(self.cv_X_df[col])\n", "                self.all_X_df[col] = NRM1(self.all_X_df[col])\n", "            if col_scl == 'SCL1':\n", "                self.cv_X_df[col] = SCL1(self.cv_X_df[col])\n", "                self.all_X_df[col] = SCL1(self.all_X_df[col])\n", "            if col_scl == 'TRSH':\n", "                self.cv_X_df[col] = TRSH(self.cv_X_df[col])\n", "                self.all_X_df[col] = TRSH(self.all_X_df[col])\n", "\n", "        \n", "        # get the values from the dataframes\n", "        self.cv_X = self.cv_X_df.values\n", "        self.cv_y = self.cv_y_df.values\n", "        self.cv_ids = self.cv_ids_df.values\n", "        \n", "        all_X = self.all_X_df.values\n", "        self.train_X = all_X[:self.train_X_shape[0], :]\n", "        self.train_y = self.cv_y_df.values\n", "        self.train_ids = self.cv_ids_df.values\n", "        \n", "        if self.test_data_file != None:\n", "            self.test_X = all_X[self.train_X_shape[0]:, :]\n", "            self.test_ids = self.test_ids_df.values\n", "        else:\n", "            self.test_X = None\n", "            self.test_ids = None\n", "        \n", "    def write_data(self, out_dir='./processed_data/'):\n", "        \"\"\"Writes all of the data to output files\"\"\"\n", "        \n", "        # create the output directory if it does not exist\n", "        if not os.path.exists(out_dir):\n", "            os.makedirs(out_dir)\n", "            \n", "        # convert arrays back into DataFrames\n", "        cv_X_df = pd.DataFrame(self.cv_X,  columns=self.feature_names)\n", "        cv_y_df = pd.DataFrame(self.cv_y, columns=self.label_names)\n", "        cv_ids_df = pd.DataFrame(self.cv_ids, columns=self.id_names)\n", "        train_X_df = pd.DataFrame(self.train_X, columns=self.feature_names)\n", "        train_y_df = pd.DataFrame(self.train_y, columns=self.label_names)\n", "        train_ids_df = pd.DataFrame(self.train_ids, columns=self.id_names)\n", "        if self.test_data_file != None:\n", "            test_X_df = pd.DataFrame(self.test_X, columns=self.feature_names)\n", "            test_ids_df = pd.DataFrame(self.test_ids, columns=self.id_names)\n", "        \n", "        # write the dataframes to file\n", "        cv_X_df.to_csv(out_dir+'cv_X.csv', index=False)\n", "        cv_y_df.to_csv(out_dir+'cv_y.csv', index=False)\n", "        cv_ids_df.to_csv(out_dir+'cv_ids.csv', index=False)\n", "        train_X_df.to_csv(out_dir+'train_X.csv', index=False)\n", "        train_y_df.to_csv(out_dir+'train_y.csv', index=False)\n", "        train_ids_df.to_csv(out_dir+'train_ids.csv', index=False)\n", "        if self.test_data_file != None:\n", "            test_X_df.to_csv(out_dir+'test_X.csv', index=False)\n", "            test_ids_df.to_csv(out_dir+'test_ids.csv', index=False)\n", "        \n", "    def select_features(self):\n", "        \"\"\"Perform features selection / compression algs like PCA.\"\"\"\n", "        \"\"\"These will be implemented once more has been done.\"\"\"\n", "        self.feature_names = self.feature_names"]}, {"cell_type": "code", "execution_count": 9, "metadata": {"scrolled": false}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["pixel0\n", "pixel1\n", "pixel2\n", "pixel3\n", "pixel4\n", "pixel5\n", "pixel6\n", "pixel7\n", "pixel8\n", "pixel9\n", "pixel10\n", "pixel11\n", "pixel12\n", "pixel13\n", "pixel14\n", "pixel15\n", "pixel16\n", "pixel17\n", "pixel18\n", "pixel19\n", "pixel20\n", "pixel21\n", "pixel22\n", "pixel23\n", "pixel24\n", "pixel25\n", "pixel26\n", "pixel27\n", "pixel28\n", "pixel29\n", "pixel30\n", "pixel31\n", "pixel32\n", "pixel33\n", "pixel34\n", "pixel35\n", "pixel36\n", "pixel37\n", "pixel38\n", "pixel39\n", "pixel40\n", "pixel41\n", "pixel42\n", "pixel43\n", "pixel44\n", "pixel45\n", "pixel46\n", "pixel47\n", "pixel48\n", "pixel49\n", "pixel50\n", "pixel51\n", "pixel52\n", "pixel53\n", "pixel54\n", "pixel55\n", "pixel56\n", "pixel57\n", "pixel58\n", "pixel59\n", "pixel60\n", "pixel61\n", "pixel62\n", "pixel63\n", "pixel64\n", "pixel65\n", "pixel66\n", "pixel67\n", "pixel68\n", "pixel69\n", "pixel70\n", "pixel71\n", "pixel72\n", "pixel73\n", "pixel74\n", "pixel75\n", "pixel76\n", "pixel77\n", "pixel78\n", "pixel79\n", "pixel80\n", "pixel81\n", "pixel82\n", "pixel83\n", "pixel84\n", "pixel85\n", "pixel86\n", "pixel87\n", "pixel88\n", "pixel89\n", "pixel90\n", "pixel91\n", "pixel92\n", "pixel93\n", "pixel94\n", "pixel95\n", "pixel96\n", "pixel97\n", "pixel98\n", "pixel99\n", "pixel100\n", "pixel101\n", "pixel102\n", "pixel103\n", "pixel104\n", "pixel105\n", "pixel106\n", "pixel107\n", "pixel108\n", "pixel109\n", "pixel110\n", "pixel111\n", "pixel112\n", "pixel113\n", "pixel114\n", "pixel115\n", "pixel116\n", "pixel117\n", "pixel118\n", "pixel119\n", "pixel120\n", "pixel121\n", "pixel122\n", "pixel123\n", "pixel124\n", "pixel125\n", "pixel126\n", "pixel127\n", "pixel128\n", "pixel129\n", "pixel130\n", "pixel131\n", "pixel132\n", "pixel133\n", "pixel134\n", "pixel135\n", "pixel136\n", "pixel137\n", "pixel138\n", "pixel139\n", "pixel140\n", "pixel141\n", "pixel142\n", "pixel143\n", "pixel144\n", "pixel145\n", "pixel146\n", "pixel147\n", "pixel148\n", "pixel149\n", "pixel150\n", "pixel151\n", "pixel152\n", "pixel153\n", "pixel154\n", "pixel155\n", "pixel156\n", "pixel157\n", "pixel158\n", "pixel159\n", "pixel160\n", "pixel161\n", "pixel162\n", "pixel163\n", "pixel164\n", "pixel165\n", "pixel166\n", "pixel167\n", "pixel168\n", "pixel169\n", "pixel170\n", "pixel171\n", "pixel172\n", "pixel173\n", "pixel174\n", "pixel175\n", "pixel176\n", "pixel177\n", "pixel178\n", "pixel179\n", "pixel180\n", "pixel181\n", "pixel182\n", "pixel183\n", "pixel184\n", "pixel185\n", "pixel186\n", "pixel187\n", "pixel188\n", "pixel189\n", "pixel190\n", "pixel191\n", "pixel192\n", "pixel193\n", "pixel194\n", "pixel195\n", "pixel196\n", "pixel197\n", "pixel198\n", "pixel199\n", "pixel200\n", "pixel201\n", "pixel202\n", "pixel203\n", "pixel204\n", "pixel205\n", "pixel206\n", "pixel207\n", "pixel208\n", "pixel209\n", "pixel210\n", "pixel211\n", "pixel212\n", "pixel213\n", "pixel214\n", "pixel215\n", "pixel216\n", "pixel217\n", "pixel218\n", "pixel219\n", "pixel220\n", "pixel221\n", "pixel222\n", "pixel223\n", "pixel224\n", "pixel225\n", "pixel226\n", "pixel227\n", "pixel228\n", "pixel229\n", "pixel230\n", "pixel231\n", "pixel232\n", "pixel233\n", "pixel234\n", "pixel235\n", "pixel236\n", "pixel237\n", "pixel238\n", "pixel239\n", "pixel240\n", "pixel241\n", "pixel242\n", "pixel243\n", "pixel244\n", "pixel245\n", "pixel246\n", "pixel247\n", "pixel248\n", "pixel249\n", "pixel250\n", "pixel251\n", "pixel252\n", "pixel253\n", "pixel254\n", "pixel255\n", "pixel256\n", "pixel257\n", "pixel258\n", "pixel259\n", "pixel260\n", "pixel261\n", "pixel262\n", "pixel263\n", "pixel264\n", "pixel265\n", "pixel266\n", "pixel267\n", "pixel268\n", "pixel269\n", "pixel270\n", "pixel271\n", "pixel272\n", "pixel273\n", "pixel274\n", "pixel275\n", "pixel276\n", "pixel277\n", "pixel278\n", "pixel279\n", "pixel280\n", "pixel281\n", "pixel282\n", "pixel283\n", "pixel284\n", "pixel285\n", "pixel286\n", "pixel287\n", "pixel288\n", "pixel289\n", "pixel290\n", "pixel291\n", "pixel292\n", "pixel293\n", "pixel294\n", "pixel295\n", "pixel296\n", "pixel297\n", "pixel298\n", "pixel299\n", "pixel300\n", "pixel301\n", "pixel302\n", "pixel303\n", "pixel304\n", "pixel305\n", "pixel306\n", "pixel307\n", "pixel308\n", "pixel309\n", "pixel310\n", "pixel311\n", "pixel312\n", "pixel313\n", "pixel314\n", "pixel315\n", "pixel316\n", "pixel317\n", "pixel318\n", "pixel319\n", "pixel320\n", "pixel321\n", "pixel322\n", "pixel323\n", "pixel324\n", "pixel325\n", "pixel326\n", "pixel327\n", "pixel328\n", "pixel329\n", "pixel330\n", "pixel331\n", "pixel332\n", "pixel333\n", "pixel334\n", "pixel335\n", "pixel336\n", "pixel337\n", "pixel338\n", "pixel339\n", "pixel340\n", "pixel341\n", "pixel342\n", "pixel343\n", "pixel344\n", "pixel345\n", "pixel346\n", "pixel347\n", "pixel348\n", "pixel349\n", "pixel350\n", "pixel351\n", "pixel352\n", "pixel353\n", "pixel354\n", "pixel355\n", "pixel356\n", "pixel357\n", "pixel358\n", "pixel359\n", "pixel360\n", "pixel361\n", "pixel362\n", "pixel363\n", "pixel364\n", "pixel365\n", "pixel366\n", "pixel367\n", "pixel368\n", "pixel369\n", "pixel370\n", "pixel371\n", "pixel372\n", "pixel373\n", "pixel374\n", "pixel375\n", "pixel376\n", "pixel377\n", "pixel378\n", "pixel379\n", "pixel380\n", "pixel381\n", "pixel382\n", "pixel383\n", "pixel384\n", "pixel385\n", "pixel386\n", "pixel387\n", "pixel388\n", "pixel389\n", "pixel390\n", "pixel391\n", "pixel392\n", "pixel393\n", "pixel394\n", "pixel395\n", "pixel396\n", "pixel397\n", "pixel398\n", "pixel399\n", "pixel400\n", "pixel401\n", "pixel402\n", "pixel403\n", "pixel404\n", "pixel405\n", "pixel406\n", "pixel407\n", "pixel408\n", "pixel409\n", "pixel410\n", "pixel411\n", "pixel412\n", "pixel413\n", "pixel414\n", "pixel415\n", "pixel416\n", "pixel417\n", "pixel418\n", "pixel419\n", "pixel420\n", "pixel421\n", "pixel422\n", "pixel423\n", "pixel424\n", "pixel425\n", "pixel426\n", "pixel427\n", "pixel428\n", "pixel429\n", "pixel430\n", "pixel431\n", "pixel432\n", "pixel433\n", "pixel434\n", "pixel435\n", "pixel436\n", "pixel437\n", "pixel438\n", "pixel439\n", "pixel440\n", "pixel441\n", "pixel442\n", "pixel443\n", "pixel444\n", "pixel445\n", "pixel446\n", "pixel447\n", "pixel448\n", "pixel449\n", "pixel450\n", "pixel451\n", "pixel452\n", "pixel453\n", "pixel454\n", "pixel455\n", "pixel456\n", "pixel457\n", "pixel458\n", "pixel459\n", "pixel460\n", "pixel461\n", "pixel462\n", "pixel463\n", "pixel464\n", "pixel465\n", "pixel466\n", "pixel467\n", "pixel468\n", "pixel469\n", "pixel470\n", "pixel471\n", "pixel472\n", "pixel473\n", "pixel474\n", "pixel475\n", "pixel476\n", "pixel477\n", "pixel478\n", "pixel479\n", "pixel480\n", "pixel481\n", "pixel482\n", "pixel483\n", "pixel484\n", "pixel485\n", "pixel486\n", "pixel487\n", "pixel488\n", "pixel489\n", "pixel490\n", "pixel491\n", "pixel492\n", "pixel493\n", "pixel494\n", "pixel495\n", "pixel496\n", "pixel497\n", "pixel498\n", "pixel499\n", "pixel500\n", "pixel501\n", "pixel502\n", "pixel503\n", "pixel504\n", "pixel505\n", "pixel506\n", "pixel507\n", "pixel508\n", "pixel509\n", "pixel510\n", "pixel511\n", "pixel512\n", "pixel513\n", "pixel514\n", "pixel515\n", "pixel516\n", "pixel517\n", "pixel518\n", "pixel519\n", "pixel520\n", "pixel521\n", "pixel522\n", "pixel523\n", "pixel524\n", "pixel525\n", "pixel526\n", "pixel527\n", "pixel528\n", "pixel529\n", "pixel530\n", "pixel531\n", "pixel532\n", "pixel533\n", "pixel534\n", "pixel535\n", "pixel536\n", "pixel537\n", "pixel538\n", "pixel539\n", "pixel540\n", "pixel541\n", "pixel542\n", "pixel543\n", "pixel544\n", "pixel545\n", "pixel546\n", "pixel547\n", "pixel548\n", "pixel549\n", "pixel550\n", "pixel551\n", "pixel552\n", "pixel553\n", "pixel554\n", "pixel555\n", "pixel556\n", "pixel557\n", "pixel558\n", "pixel559\n", "pixel560\n", "pixel561\n", "pixel562\n", "pixel563\n", "pixel564\n", "pixel565\n", "pixel566\n", "pixel567\n", "pixel568\n", "pixel569\n", "pixel570\n", "pixel571\n", "pixel572\n", "pixel573\n", "pixel574\n", "pixel575\n", "pixel576\n", "pixel577\n", "pixel578\n", "pixel579\n", "pixel580\n", "pixel581\n", "pixel582\n", "pixel583\n", "pixel584\n", "pixel585\n", "pixel586\n", "pixel587\n", "pixel588\n", "pixel589\n", "pixel590\n", "pixel591\n", "pixel592\n", "pixel593\n", "pixel594\n", "pixel595\n", "pixel596\n", "pixel597\n", "pixel598\n", "pixel599\n", "pixel600\n", "pixel601\n", "pixel602\n", "pixel603\n", "pixel604\n", "pixel605\n", "pixel606\n", "pixel607\n", "pixel608\n", "pixel609\n", "pixel610\n", "pixel611\n", "pixel612\n", "pixel613\n", "pixel614\n", "pixel615\n", "pixel616\n", "pixel617\n", "pixel618\n", "pixel619\n", "pixel620\n", "pixel621\n", "pixel622\n", "pixel623\n", "pixel624\n", "pixel625\n", "pixel626\n", "pixel627\n", "pixel628\n", "pixel629\n", "pixel630\n", "pixel631\n", "pixel632\n", "pixel633\n", "pixel634\n", "pixel635\n", "pixel636\n", "pixel637\n", "pixel638\n", "pixel639\n", "pixel640\n", "pixel641\n", "pixel642\n", "pixel643\n", "pixel644\n", "pixel645\n", "pixel646\n", "pixel647\n", "pixel648\n", "pixel649\n", "pixel650\n", "pixel651\n", "pixel652\n", "pixel653\n", "pixel654\n", "pixel655\n", "pixel656\n", "pixel657\n", "pixel658\n", "pixel659\n", "pixel660\n", "pixel661\n", "pixel662\n", "pixel663\n", "pixel664\n", "pixel665\n", "pixel666\n", "pixel667\n", "pixel668\n", "pixel669\n", "pixel670\n", "pixel671\n", "pixel672\n", "pixel673\n", "pixel674\n", "pixel675\n", "pixel676\n", "pixel677\n", "pixel678\n", "pixel679\n", "pixel680\n", "pixel681\n", "pixel682\n", "pixel683\n", "pixel684\n", "pixel685\n", "pixel686\n", "pixel687\n", "pixel688\n", "pixel689\n", "pixel690\n", "pixel691\n", "pixel692\n", "pixel693\n", "pixel694\n", "pixel695\n", "pixel696\n", "pixel697\n", "pixel698\n", "pixel699\n", "pixel700\n", "pixel701\n", "pixel702\n", "pixel703\n", "pixel704\n", "pixel705\n", "pixel706\n", "pixel707\n", "pixel708\n", "pixel709\n", "pixel710\n", "pixel711\n", "pixel712\n", "pixel713\n", "pixel714\n", "pixel715\n", "pixel716\n", "pixel717\n", "pixel718\n", "pixel719\n", "pixel720\n", "pixel721\n", "pixel722\n", "pixel723\n", "pixel724\n", "pixel725\n", "pixel726\n", "pixel727\n", "pixel728\n", "pixel729\n", "pixel730\n", "pixel731\n", "pixel732\n", "pixel733\n", "pixel734\n", "pixel735\n", "pixel736\n", "pixel737\n", "pixel738\n", "pixel739\n", "pixel740\n", "pixel741\n", "pixel742\n", "pixel743\n", "pixel744\n", "pixel745\n", "pixel746\n", "pixel747\n", "pixel748\n", "pixel749\n", "pixel750\n", "pixel751\n", "pixel752\n", "pixel753\n", "pixel754\n", "pixel755\n", "pixel756\n", "pixel757\n", "pixel758\n", "pixel759\n", "pixel760\n", "pixel761\n", "pixel762\n", "pixel763\n", "pixel764\n", "pixel765\n", "pixel766\n", "pixel767\n", "pixel768\n", "pixel769\n", "pixel770\n", "pixel771\n", "pixel772\n", "pixel773\n", "pixel774\n", "pixel775\n", "pixel776\n", "pixel777\n", "pixel778\n", "pixel779\n", "pixel780\n", "pixel781\n", "pixel782\n", "pixel783\n"]}], "source": ["# some simple testing code and such\n", "dataset = 'mnist'\n", "train_data = data_filepath+dataset+'_data_train.csv'\n", "train_labels = data_filepath+dataset+'_labels_train.csv'\n", "train_ids = data_filepath+dataset+'_ids_train.csv'\n", "test_data = data_filepath+dataset+'_data_test.csv'\n", "test_ids = data_filepath+dataset+'_ids_test.csv'\n", "description = data_filepath+dataset+'_feature_descriptions.csv'\n", "\n", "proc = Preprocessor(train_data_file=train_data,\n", "                 train_label_file=train_labels,\n", "                 train_ids_file=train_ids,\n", "                 test_data_file=test_data,\n", "                 test_ids_file=test_ids,\n", "                 instr_file=description)\n", "\n", "proc.read_data()\n", "\n", "proc.process()\n", "\n", "# doesn't do anything yet, hasn't been implemented\n", "proc.select_features()\n", "\n", "# data is written to output directory\n", "# any existing data is overwritten\n", "proc.write_data()\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": []}], "metadata": {"anaconda-cloud": {}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.5.2"}}, "nbformat": 4, "nbformat_minor": 1}