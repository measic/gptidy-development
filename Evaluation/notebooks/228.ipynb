{"cells": [{"cell_type": "code", "execution_count": 10, "metadata": {"scrolled": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Step #100 A = [[0.05347275]\n", " [0.61744994]] b = [[1.5994107]]\n", "Loss = [1.3858198]\n", "Step #200 A = [[0.00217406]\n", " [0.2849031 ]] b = [[1.273552]]\n", "Loss = [1.08819]\n", "Step #300 A = [[ 0.00597821]\n", " [-0.0170242 ]] b = [[1.0095139]]\n", "Loss = [0.9280102]\n", "Step #400 A = [[ 0.01317948]\n", " [-0.28076297]] b = [[0.80504346]]\n", "Loss = [0.82495236]\n", "Step #500 A = [[ 0.01434606]\n", " [-0.50339764]] b = [[0.62217003]]\n", "Loss = [0.72556305]\n", "[[1629    2]\n", " [1389   44]]\n"]}], "source": ["\"\"\"\n", "Experimenting with support vector machines\n", "\"\"\"\n", "# Importing all the libraries \n", "import os\n", "import json\n", "import numpy                  as np\n", "import tensorflow             as tf\n", "import matplotlib.pyplot      as plt\n", "from sklearn                  import svm\n", "\n", "# These modules are used for the confusion matrix\n", "from sklearn.model_selection  import train_test_split\n", "from sklearn.metrics          import confusion_matrix\n", "from sklearn.utils.multiclass import unique_labels\n", "\n", "\n", "class ClassifySVM:\n", "    \"\"\"\n", "    data:   numpy array consisting of data consisting of float values.\n", "    target: The target values associated with the input data.\n", "    \"\"\"\n", "    \n", "    # def ConfusionMatrix(self, data, target):   \n", "    def SupportVectorClassify(self, data, target):\n", "\n", "        # Spliting the datasets into training and testing portions\n", "        sess          = tf.Session()\n", "        train_indices = np.random.choice(len(data), round(len(data) * 0.8), replace=False)\n", "        test_indices  = np.array(list(set(range(len(data))) - set(train_indices)))\n", "\n", "        Beta_train    = data[train_indices]\n", "        Beta_test     = data[test_indices]\n", "        target_train  = target[train_indices]\n", "        target_test   = target[test_indices]\n", "\n", "        # Here we want a very large batch size to achieve convergence. \n", "        # The A variable will take on the 2 x 1 shape. (In the book, this is done because there are 2 predictor variables.)\n", "        batch_size    = 25000\n", "        x_data        = tf.placeholder(shape = [None, 2], dtype=tf.float32)\n", "        y_target      = tf.placeholder(shape = [None, 1], dtype=tf.float32)\n", "        A = tf.Variable(tf.random_normal(shape=[2,1]))\n", "        b = tf.Variable(tf.random_normal(shape=[1,1]))\n", "\n", "        # For correctly classified points, values of >= 1 if target is 1.\n", "        model_output = tf.subtract(tf.matmul(x_data, A), b)\n", "\n", "        # Calculate the L2 normm of a vector. \n", "        # Margin parameter: a\n", "        l2_norm      = tf.reduce_sum(tf.square(A))\n", "        alpha        = tf.constant([0.1])\n", "\n", "        # Declaring classification loss and adding together the two terms.\n", "        classification_term = tf.reduce_mean(tf.maximum(0., tf.subtract(1., tf.multiply(model_output, y_target))))\n", "        loss                = tf.add(classification_term, tf.multiply(alpha, l2_norm))\n", "\n", "        # Declaring the prediction and accuracy functions to evaluate bot the training and test sets.\n", "        prediction = tf.sign(model_output)\n", "        accuracy   = tf.reduce_mean(tf.cast(tf.equal(prediction, y_target), tf.float32))\n", "\n", "        # Declaring optimization function and initializing model variables.\n", "        my_opt     = tf.train.GradientDescentOptimizer(0.01)\n", "        train_step = my_opt.minimize(loss)\n", "        init       = tf.global_variables_initializer()\n", "        sess.run(init)\n", "\n", "        # Starting the training loop. \n", "        # Making sure to record loss and training accuracy for both training and test sets. \n", "        loss_vec = []\n", "        train_accuracy  = []\n", "        test_accuracy   = []\n", "        \n", "        test_record = {}\n", "\n", "        for i in range(500):\n", "            rand_index = np.random.choice(len(Beta_train), size=batch_size)\n", "            \n", "            rand_x     = Beta_train[rand_index]\n", "            rand_y     = np.transpose([target_train[rand_index]])\n", "            no_end     = sess.run(train_step, feed_dict = {x_data: rand_x, y_target: rand_y})\n", "            \n", "            # Storing the loss from each iteration into loss_vec\n", "            temp_loss  = sess.run(loss, feed_dict = {x_data:rand_x, y_target:rand_y})\n", "            loss_vec.append(temp_loss)\n", "\n", "            # Storing train accuracies for each iteration of classification\n", "            train_acc_temp = sess.run(accuracy, feed_dict={x_data:Beta_train, y_target:np.transpose([target_train])})\n", "            train_accuracy.append(train_acc_temp)\n", "\n", "            # Storing test accuracies for each iteration of classification\n", "            test_acc_temp = sess.run(accuracy, feed_dict={x_data:Beta_test, y_target:np.transpose([target_test])})\n", "            test_accuracy.append(test_acc_temp)\n", "            \n", "            if (i+1)%100 == 0:\n", "                print('Step #' + str(i + 1) + ' A = ' + str(sess.run(A)) + ' b = ' + str(sess.run(b)))\n", "                print('Loss = ' + str(temp_loss))\n", "                \n", "        test_prediction = sess.run(prediction, feed_dict={x_data:Beta_test, y_target:np.transpose([target_test])})\n", "        print(confusion_matrix(target_test, test_prediction))\n", "        \n", "        \"\"\"\n", "        with open(\"/Users/\" + os.getlogin() + \"/Desktop/SVMData.json\", \"w\") as repository:\n", "            json.dump(test_record, repository, sort_keys=True, indent=4)\n", "        repository.close()\n", "        \"\"\"\n", "\n", "        # Plotting the outputs (fit, loss and accuracy), the coefficients.\n", "        [[a1], [a2]] = sess.run(A)\n", "        [[b]]        = sess.run(b)\n", "        slope        = -a2/a1\n", "        y_intercept  = b/a1\n", "        x1_vals      = [d[1] for d in data]\n", "\n", "        best_fit     = []\n", "        for i in x1_vals:\n", "            best_fit.append(slope*i+y_intercept)\n", "\n", "        feature_x     = [d[1] for i,d in enumerate(data) if target[i] == 1]\n", "        feature_y     = [d[0] for i,d in enumerate(data) if target[i] == 1]\n", "        not_feature_x = [d[1] for i,d in enumerate(data) if target[i] == -1]\n", "        not_feature_y = [d[0] for i,d in enumerate(data) if target[i] == -1]\n", "\n", "        plt.plot(feature_x, feature_y, 'o', label='I. Distracted')\n", "        plt.plot(not_feature_x, not_feature_y, 'x', label='Not Distracted')\n", "        plt.plot(x1_vals, best_fit, 'r-', label='Linear Separator', linewidth=3)\n", "        plt.ylim([0, 10])\n", "        plt.legend(loc='upper left')\n", "        plt.title('Boundary Classification')\n", "        plt.xlabel('Delta & Beta')\n", "        plt.ylabel('targets')\n", "        plt.show()\n", "\n", "        plt.plot(train_accuracy, 'k-', label='Training Accuracy')\n", "        plt.plot(test_accuracy, 'r--', label='Test Accuracy')\n", "        plt.title('Train and Test Set Accuracies')\n", "        plt.xlabel('Generation')\n", "        plt.ylabel('Accuracy')\n", "        plt.legend(loc='lower right')\n", "        plt.show()\n", "\n", "        plt.plot(loss_vec, 'k-')\n", "        plt.title('Loss per Generation')\n", "        plt.xlabel('Generation')\n", "        plt.ylabel('Loss')\n", "        plt.show()\n", "        \n", "        \n", "# Reading from the csv file.\n", "path = r'/Users/KaushikBhimraj/Desktop/Merged1_Data.csv'\n", "\n", "# List comprehension used to create numpy arrays for inputs and targets.\n", "# Removing the heading row and converting the string values to int.  \n", "I           = [[line.split(',')[0], line.split(',')[1]] for line in open(path) if line[0:1] != '\\n'][1:]\n", "BetaDelta   = np.array([[float(val[0]), float(val[1])] for val in I])\n", "Target      = np.array([line.split(',')[2] for line in open(path) if line[0:1] != '\\n'][1:])\n", "\n", "# Converting target to -1 or 1 format.\n", "T           = np.array([float(1) if y == \"Distracted\\n\" else float(-1) for y in Target])\n", "\n", "# Calling the class object and the function inside it that will execute the suport vector algorithm.\n", "c = ClassifySVM()\n", "c.SupportVectorClassify(BetaDelta, T)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.0"}}, "nbformat": 4, "nbformat_minor": 2}