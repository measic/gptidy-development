{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTree-of-Thought prompting\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Tree-of-Thought prompting\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FILES = 350\n",
    "FOLDER_NAME = '../random_samples_formatting'\n",
    "GPT_SAVED_FILE_NAME = 'formatted_code_gpt'\n",
    "GPT_SAVED_FOLDER_NAME = 'reformatted_gpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in files from folder random_cells\n",
    "random_cells = []\n",
    "\n",
    "for i in range(NUM_FILES):\n",
    "    file_name = f'{FOLDER_NAME}/{i}.py'\n",
    "    with open(file_name, 'r') as f:\n",
    "        random_cells.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_prompt = \"\"\"Format the code delimited by triple backticks according to PEP 8 conventions. Do not add, remove, or change anything else. First, identify formatting issues in the code. Then, fix these issues in the code. Structure your response under the following headings: 'Identified formatting issues' (a short paragraph describing the formatting issues) and 'Formatted code' (the full code with all formatting issues fixed).\"\"\"\n",
    "\n",
    "shots_input = []\n",
    "shots_output = []\n",
    "for i in range(1, 5):\n",
    "    with open(f'../shots/shot{i}.py', 'r') as f:\n",
    "        shots_input.append(f.read())\n",
    "    with open(f'../shots/shot{i}_after.py', 'r') as f:\n",
    "        shots_output.append(f.read())\n",
    "\n",
    "ex1_input = f\"\"\"```python\n",
    "{shots_input[0]}\n",
    "```\"\"\"\n",
    "\n",
    "ex1_output = f\"\"\"First, we identify formatting issues in the code that violate PEP 8 conventions.\n",
    "\n",
    "Identified formatting issues:\n",
    "- Imports 'utils' and 'rain' should not be on the same line\n",
    "- The indentation in the function 'evaluate' contains tabs\n",
    "- The function 'evaluate' should have two tabs after its definition, not one\n",
    "\n",
    "Now, we fix these issues in the code. For the first issue, we separate the two import statements onto separate lines. For the second issue, we replace the tab with four spaces. For the third issue, we add two blank lines after the function 'evaluate'.\n",
    "\n",
    "Formatted code:\n",
    "```python\n",
    "{shots_output[0]}\n",
    "```\"\"\"\n",
    "\n",
    "ex2_input = f\"\"\"```python\n",
    "{shots_input[1]}\n",
    "```\"\"\"\n",
    "\n",
    "ex2_output = f\"\"\"First, we identify formatting issues in the code that violate PEP 8 conventions.\n",
    "\n",
    "Identified formatting issues:\n",
    "- Arithmetic operators should have whitespace around them\n",
    "- There is a line break after the binary operator but the line break should be before the binary operator\n",
    "- No statements should end with a semicolon\n",
    "\n",
    "Now, we fix these issues in the code. For the first issue, we add whitespace around the '*' operator. For second issue, we line break before the '*' operator, bringing the operator down to the next line. For the third issue, we remove the semicolon at the end of the line.\n",
    "\n",
    "Formatted code:\n",
    "```python\n",
    "{shots_output[1]}\n",
    "```\"\"\"\n",
    "\n",
    "ex3_input = f\"\"\"```python\n",
    "{shots_input[2]}\n",
    "```\"\"\"\n",
    "\n",
    "ex3_output = f\"\"\"First, we identify formatting issues in the code that violate PEP 8 conventions.\n",
    "\n",
    "Identified formatting issues:\n",
    "- Blank line contains whitespace but it should not\n",
    "- The if statement is too long and should be split into multiple lines\n",
    "- The code block inside the if-statement is not indented with 4 spaces\n",
    "\n",
    "Now, we fix these issues in the code. For the first issue, we remove the whitespace in the blank line. For the second issue, we split the if statement into two lines. For the third issue, we add an extra space to the indent of the variable assignment in the if statement so it is a multiple of 4.\n",
    "\n",
    "Formatted code:\n",
    "```python\n",
    "{shots_output[2]}\n",
    "```\"\"\"\n",
    "\n",
    "ex4_input = f\"\"\"```python\n",
    "{shots_input[3]}\n",
    "```\"\"\"\n",
    "\n",
    "ex4_output = f\"\"\"First, we identify formatting issues in the code that violate PEP 8 conventions.\n",
    "\n",
    "Identified formatting issues:\n",
    "- There should be two blank lines between the imports and the first function not one\n",
    "- The return statement in the function 'find' is too long and should be split into multiple lines\n",
    "- No blank lines should contain whitespace\n",
    "- The continuation line for the print statement is under-indented\n",
    "- The closing bracket of the variable assignment 'updated_offset' does not match the indentation of the opening bracket's line\n",
    "\n",
    "Now, we fix these issues in the code. For the first issue, we add an extra blank line after the import statement. For second issue, we split the return statement into two lines. For the third issue, we remove the whitespace in the blank line. For the fourth issue, we indent the second line of the print statement so that 'count' is aligned with 'new_prompt' in the line above. For the fifth issue, we remove indentation from the closing bracket of the variable assignment for 'updated_offset' so it is indented at the same level as the first line.\n",
    "\n",
    "Formatted code:\n",
    "```python\n",
    "{shots_output[3]}\n",
    "```\"\"\"\n",
    "\n",
    "identify_vote_prompt = \"\"\"Given an original task and multiple choices, choose the best answer for the original task. Analyze each choice in detail, then conclude in the last line 'The best choice is {s}', where s is the integer id of the choice. If all choices are equally good, return the smallest id. If no choice is good, return 0.\n",
    "Original task: Identify formatting issues in the code delimited by triple backticks according to PEP 8 conventions.\"\"\"\n",
    "\n",
    "identify_vote_ex1_input = f\"\"\"Code:\n",
    "```python\n",
    "{shots_input[0]}\n",
    "```\n",
    "\n",
    "Choice 1:\n",
    "- Imports 'utils' and 'rain' should not be on the same line\n",
    "- The indentation in the function 'evaluate' contains tabs\n",
    "- The function 'evaluate' should have two tabs after its definition, not one\n",
    "Choice 2:\n",
    "- Arithmetic operators should have whitespace around them\n",
    "- There is a line break after the binary operator but the line break should be before the binary operator\n",
    "- No statements should end with a semicolon\n",
    "Choice 3:\n",
    "- Variables are not in camelCase\"\"\"\n",
    "\n",
    "identify_vote_ex1_output = \"\"\"Choice 1 is the best choice. It correctly identifies each formatting issue according PEP 8 conventions. Each issue identified is present in the code. No issues are missing and no extra issues are identified.\n",
    "Choice 2 is not the best choice. None of the issues identified are actually present in the code and none of the issues present in the code are correctly identified.\n",
    "Choice 3 is not the best choice. Camel case is not a PEP 8 convention and is not a formatting issue.\n",
    "\n",
    "The best choice is 1.\"\"\"\n",
    "\n",
    "code_vote_prompt = \"\"\"Given an original task and multiple choices, choose the best answer for the original task. Analyze each choice in detail, then conclude in the last line 'The best choice is {s}', where s is the integer id of the choice. If all choices are equally good, return the smallest id. If no choice is good, return 0.\n",
    "Original task: Fix the following formatting issues in the code delimited by triple backticks. Do not add, remove, or change anything else. Output the formatted code with the identified issues rectified.\"\"\"\n",
    "\n",
    "code_vote_ex1_input = f\"\"\"Formatting issues to fix:\n",
    "- Imports 'utils' and 'rain' should not be on the same line\n",
    "- The indentation in the function 'evaluate' contains tabs\n",
    "- The function 'evaluate' should have two tabs after its definition, not one\n",
    "\n",
    "Code:\n",
    "```python\n",
    "{shots_input[0]}\n",
    "```\n",
    "\n",
    "Choice 1:\n",
    "```python\n",
    "{shots_input[0]}\n",
    "```\n",
    "Choice 2:\n",
    "```python\n",
    "{shots_output[0]}\n",
    "```\n",
    "Choice 3:\n",
    "```python\n",
    "import utils, rain\n",
    "\n",
    "\n",
    "def evaluate(x, y):\n",
    "    return rain.proccess(x, y)\n",
    "\n",
    "\n",
    "utils.print(evaluate(3, 4))\n",
    "```\"\"\"\n",
    "\n",
    "code_vote_ex1_output = \"\"\"Choice 1 is incorrect. It does not change any of the issues identified and simply outputs the original code.\n",
    "Choice 2 is correct. It correctly fixes each and every formatting issue identified without changing anything else.\n",
    "Choice 3 is incorrect. While it fixes the indentation issues and missing blank lines, it does not fix the multiple imports on one line.\n",
    "\n",
    "The best choice is 2.\"\"\"\n",
    "\n",
    "def get_cot_prompt(cell_src):\n",
    "    return [\n",
    "        {\"role\": \"user\", \"content\": main_prompt},\n",
    "        {\"role\": \"user\", \"content\": ex1_input},\n",
    "        {\"role\": \"assistant\", \"content\": ex1_output},\n",
    "        {\"role\": \"user\", \"content\": ex2_input},\n",
    "        {\"role\": \"assistant\", \"content\": ex2_output},\n",
    "        {\"role\": \"user\", \"content\": ex3_input},\n",
    "        {\"role\": \"assistant\", \"content\": ex3_output},\n",
    "        {\"role\": \"user\", \"content\": ex4_input},\n",
    "        {\"role\": \"assistant\", \"content\": ex4_output},\n",
    "        {\"role\" : \"user\", \"content\" : f\"```python\\n{cell_src}\\n```\"},\n",
    "    ]\n",
    "\n",
    "def get_identified_names(identify_trials, identify_completions):\n",
    "    identified_names = []\n",
    "    for i in range(identify_trials):\n",
    "        if identify_completions.choices[i].finish_reason == 'stop':\n",
    "            try:\n",
    "                issues = identify_completions.choices[i]['message']['content'].split('Identified formatting issues:')[1].strip(\"\\n\").split(\"\\n\")[0]\n",
    "            except:\n",
    "                print(\"unexpected format for issue\", identify_completions.choices[i]['message']['content'])\n",
    "                issues = None\n",
    "        else:\n",
    "            issues = None\n",
    "        identified_names.append(issues)\n",
    "    return identified_names\n",
    "\n",
    "def get_identify_vote_msgs(cell_src):\n",
    "    def func(choices):\n",
    "        final_msg = f\"Code:\\n```python\\n{cell_src}\\n```\\n\\n\"\n",
    "\n",
    "        for i, choice in enumerate(choices):\n",
    "            final_msg += f\"Choice {i + 1}:\\n{choice}\\n\"\n",
    "        \n",
    "        return [\n",
    "        {\"role\": \"user\", \"content\": identify_vote_prompt},\n",
    "        {\"role\": \"user\", \"content\": identify_vote_ex1_input},\n",
    "        {\"role\": \"assistant\", \"content\": identify_vote_ex1_output},\n",
    "        {\"role\": \"user\", \"content\": final_msg}\n",
    "        ]\n",
    "    \n",
    "    return func\n",
    "\n",
    "def get_code_vote_msgs(cell_src):\n",
    "    def func(new_issues, choices):\n",
    "        final_msg = f\"Formatting issues to fix:\\n{new_issues}\\n\\nCode:\\n```python\\n{cell_src}\\n```\\n\\n\"\n",
    "        \n",
    "        for i, choice in enumerate(choices):\n",
    "            final_msg += f\"Choice {i + 1}:\\n{choice}\\n\"\n",
    "        \n",
    "        return [\n",
    "        {\"role\": \"user\", \"content\": code_vote_prompt},\n",
    "        {\"role\": \"user\", \"content\": code_vote_ex1_input},\n",
    "        {\"role\": \"assistant\", \"content\": code_vote_ex1_output},\n",
    "        {\"role\" : \"user\", \"content\" : final_msg}\n",
    "        ]\n",
    "\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "identify_trials = 5\n",
    "code_trials = 3\n",
    "identify_vote_trials = 6\n",
    "code_vote_trials = 4\n",
    "identify_stop = \"Formatted code\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.855013"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimate cost\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "import utils\n",
    "\n",
    "def estimate_tokens():\n",
    "    in_tok = ''\n",
    "    out_tok = ''\n",
    "    for i, cell_src in enumerate(random_cells):\n",
    "        # trial\n",
    "        in_tok += main_prompt + ex1_input + ex1_output + ex2_input + ex2_output + ex3_input + ex3_output + ex4_input + ex4_output\n",
    "        in_tok += f\"```python\\n{cell_src}\\n```\"\n",
    "        out_tok += (ex1_output[:int(len(ex1_input)/2)] * identify_trials)\n",
    "        # vote trial\n",
    "        in_tok += identify_vote_prompt + identify_vote_ex1_input + identify_vote_ex1_output\n",
    "        in_tok += f\"```python\\n{cell_src}\\n```\\n\\n\"\n",
    "        out_tok += identify_vote_ex1_output * identify_vote_trials\n",
    "        # code\n",
    "        in_tok += main_prompt + ex1_input + ex1_output + ex2_input + ex2_output + ex3_input + ex3_output + ex4_input + ex4_output\n",
    "        in_tok += f\"```python\\n{cell_src}\\n```\"\n",
    "        in_tok += ex1_output[:int(len(ex1_input)/2)]\n",
    "        out_tok += (ex1_output[int(len(ex1_input)/2):] * code_trials)\n",
    "        # vote code\n",
    "        in_tok += code_vote_prompt + code_vote_ex1_input + code_vote_ex1_output\n",
    "        in_tok += f\"Original code:\\n```python\\n{cell_src}\\n```\\n\\nFormatting issues to fix: lalalalallaal\\n\\n\"\n",
    "        out_tok += code_vote_ex1_output * code_vote_trials\n",
    "    return in_tok, out_tok\n",
    "\n",
    "in_tok, out_tok = estimate_tokens()\n",
    "\n",
    "utils.gpt_35_turbo_token_dollar_cost(in_tok, out_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GPT Tree of Thought\n",
    "# import sys\n",
    "# sys.path.append('../../')\n",
    "# from tree_of_thought import solve_toc\n",
    "\n",
    "# # identify and remove unused using GPT\n",
    "# gpt_results = []\n",
    "# for i in range(NUM_FILES):\n",
    "#     input_msgs_cot = get_cot_prompt(random_cells[i])\n",
    "#     get_identified_names_func = get_identified_names\n",
    "#     get_identify_votes_msgs_func = get_identify_vote_msgs(random_cells[i])\n",
    "#     get_code_votes_msgs_func = get_code_vote_msgs(random_cells[i])\n",
    "\n",
    "#     print(f'Processing file {i}')\n",
    "#     identified, updated_code = solve_toc(input_msgs_cot, identify_trials, code_trials, identify_vote_trials, code_vote_trials, identify_stop, get_identified_names_func, get_identify_votes_msgs_func, get_code_votes_msgs_func)\n",
    "#     print(f'File {i} - {identified}')\n",
    "#     gpt_results.append({'identified': identified, 'updated_code': updated_code})\n",
    "\n",
    "# # save the results to a file\n",
    "# with open(GPT_SAVED_FILE_NAME, 'w') as f:\n",
    "#     f.write(str(gpt_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in gpt result from file\n",
    "with open(GPT_SAVED_FILE_NAME, 'r') as f:\n",
    "    gpt_results = eval(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results to a variable\n",
    "gpt_issues = [var['identified'] for var in gpt_results]\n",
    "gpt_new_code = [var['updated_code'] for var in gpt_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all to new folder\n",
    "import os\n",
    "if not os.path.exists(GPT_SAVED_FOLDER_NAME):\n",
    "    os.makedirs(GPT_SAVED_FOLDER_NAME)\n",
    "for i, code in enumerate(gpt_new_code):\n",
    "    with open(f'{GPT_SAVED_FOLDER_NAME}/{i}.py', 'w') as f:\n",
    "        if gpt_new_code[i] is None or gpt_issues[i] is None:\n",
    "            f.write(random_cells[i])\n",
    "        else:\n",
    "            f.write(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "from common import pycodestyle, group_by_error, print_num_reductions, print_percentage_difference, IGNORE_TYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total before: 3062\n"
     ]
    }
   ],
   "source": [
    "# store error counts in a hash\n",
    "error_counts_before = pycodestyle(FOLDER_NAME, NUM_FILES, IGNORE_TYPES)\n",
    "\n",
    "# print the error counts\n",
    "total_errors_before = sum(error_counts_before.values())\n",
    "print(f'Total before: {total_errors_before}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total after: 1437\n"
     ]
    }
   ],
   "source": [
    "# store error counts in a hash\n",
    "error_counts_after = pycodestyle(GPT_SAVED_FOLDER_NAME, NUM_FILES, IGNORE_TYPES)\n",
    "\n",
    "# print the error counts\n",
    "total_errors_after = sum(error_counts_after.values())\n",
    "print(f'Total after: {total_errors_after}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'E501': 447,\n",
       " 'E226': 181,\n",
       " 'E231': 592,\n",
       " 'E266': 80,\n",
       " 'E303': 8,\n",
       " 'W293': 213,\n",
       " 'E251': 359,\n",
       " 'E265': 130,\n",
       " 'W291': 142,\n",
       " 'E202': 29,\n",
       " 'E203': 47,\n",
       " 'E241': 16,\n",
       " 'E225': 154,\n",
       " 'E117': 2,\n",
       " 'E128': 33,\n",
       " 'E302': 48,\n",
       " 'E401': 2,\n",
       " 'E703': 52,\n",
       " 'E221': 76,\n",
       " 'E305': 27,\n",
       " 'E228': 5,\n",
       " 'E402': 32,\n",
       " 'E111': 141,\n",
       " 'E114': 22,\n",
       " 'E261': 46,\n",
       " 'E722': 2,\n",
       " 'E201': 29,\n",
       " 'E275': 9,\n",
       " 'E126': 4,\n",
       " 'E127': 3,\n",
       " 'E211': 13,\n",
       " 'E271': 2,\n",
       " 'E262': 27,\n",
       " 'E113': 2,\n",
       " 'E116': 8,\n",
       " 'W504': 6,\n",
       " 'E123': 2,\n",
       " 'E101': 1,\n",
       " 'W191': 2,\n",
       " 'E701': 3,\n",
       " 'E121': 33,\n",
       " 'E131': 3,\n",
       " 'E702': 9,\n",
       " 'E741': 2,\n",
       " 'E115': 3,\n",
       " 'E124': 1,\n",
       " 'E222': 8,\n",
       " 'E301': 2,\n",
       " 'E712': 1,\n",
       " 'E122': 3}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_counts_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'E501': 437,\n",
       " 'W293': 129,\n",
       " 'E251': 43,\n",
       " 'E226': 74,\n",
       " 'E231': 162,\n",
       " 'E265': 50,\n",
       " 'W291': 67,\n",
       " 'E225': 82,\n",
       " 'E266': 30,\n",
       " 'E302': 33,\n",
       " 'E128': 8,\n",
       " 'E305': 18,\n",
       " 'E228': 1,\n",
       " 'E722': 1,\n",
       " 'E202': 6,\n",
       " 'E201': 9,\n",
       " 'E275': 6,\n",
       " 'E401': 1,\n",
       " 'E203': 6,\n",
       " 'E113': 1,\n",
       " 'E271': 1,\n",
       " 'E261': 19,\n",
       " 'E402': 11,\n",
       " 'W504': 9,\n",
       " 'E303': 5,\n",
       " 'E111': 106,\n",
       " 'E123': 1,\n",
       " 'E126': 2,\n",
       " 'E124': 3,\n",
       " 'E703': 20,\n",
       " 'E101': 1,\n",
       " 'W191': 2,\n",
       " 'E701': 3,\n",
       " 'E221': 16,\n",
       " 'E741': 1,\n",
       " 'E121': 31,\n",
       " 'E241': 3,\n",
       " 'E262': 3,\n",
       " 'E114': 20,\n",
       " 'E116': 4,\n",
       " 'E222': 3,\n",
       " 'E301': 2,\n",
       " 'E712': 1,\n",
       " 'E127': 6}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_counts_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total percentage difference: -53.06988896146309%\n"
     ]
    }
   ],
   "source": [
    "# List percentage difference between before and after for total\n",
    "print(f'Total percentage difference: {(total_errors_after - total_errors_before) / total_errors_before * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'E1': 261,\n",
       " 'E2': 1803,\n",
       " 'E3': 85,\n",
       " 'E4': 34,\n",
       " 'E5': 447,\n",
       " 'E7': 69,\n",
       " 'E9': 0,\n",
       " 'W1': 2,\n",
       " 'W2': 355,\n",
       " 'W3': 0,\n",
       " 'W5': 6,\n",
       " 'W6': 0}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_counts_grouped_before = group_by_error(error_counts_before)\n",
    "error_counts_grouped_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'E1': 183,\n",
       " 'E2': 514,\n",
       " 'E3': 58,\n",
       " 'E4': 12,\n",
       " 'E5': 437,\n",
       " 'E7': 26,\n",
       " 'E9': 0,\n",
       " 'W1': 2,\n",
       " 'W2': 196,\n",
       " 'W3': 0,\n",
       " 'W5': 9,\n",
       " 'W6': 0}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_counts_grouped_after = group_by_error(error_counts_after)\n",
    "error_counts_grouped_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('E1', 'Indentation'): 261 -> 183\n",
      "('E2', 'Whitespace'): 1803 -> 514\n",
      "('E3', 'Blank line'): 85 -> 58\n",
      "('E4', 'Import'): 34 -> 12\n",
      "('E5', 'Line length'): 447 -> 437\n",
      "('E7', 'Statement'): 69 -> 26\n",
      "('E9', 'Runtime'): 0 -> 0\n",
      "('W1', 'Indentation warning'): 2 -> 2\n",
      "('W2', 'Whitespace warning'): 355 -> 196\n",
      "('W3', 'Blank line warning'): 0 -> 0\n",
      "('W5', 'Line break warning'): 6 -> 9\n",
      "('W6', 'Deprecation warning'): 0 -> 0\n"
     ]
    }
   ],
   "source": [
    "print_num_reductions(error_counts_grouped_before, error_counts_grouped_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('E1', 'Indentation'): -29.89%\n",
      "('E2', 'Whitespace'): -71.49%\n",
      "('E3', 'Blank line'): -31.76%\n",
      "('E4', 'Import'): -64.71%\n",
      "('E5', 'Line length'): -2.24%\n",
      "('E7', 'Statement'): -62.32%\n",
      "('E9', 'Runtime'): Undefined\n",
      "('W1', 'Indentation warning'): 0.0%\n",
      "('W2', 'Whitespace warning'): -44.79%\n",
      "('W3', 'Blank line warning'): Undefined\n",
      "('W5', 'Line break warning'): 50.0%\n",
      "('W6', 'Deprecation warning'): Undefined\n"
     ]
    }
   ],
   "source": [
    "print_percentage_difference(error_counts_grouped_before, error_counts_grouped_after)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
