[{'reason': 'stop', 'result': '```python\n_, _ = plt.subplots(1,2, figsize=(10,4))\n_[0].imshow(img_advi)\n_[0].set_title("segmented image (ADVI)")\n_[1].hist(y, bins=K);\n_[1].set_title("cluster assignments (ADVI)")\nplt.tight_layout()```'}, {'reason': 'stop', 'result': '```python\n(_, score_vgg16_seq) = VGG16Seq.evaluate(arr_X_test, arr_y_test, verbose=True)\n\nscore_vgg16_seq```'}, {'reason': 'stop', 'result': "```python\n#set up lists containing calculated rations for plotting \n\nearningsgrowth10k = [earnings for earnings in df0_10k_grouped['earnings_growth_y6_y10']]\n\nearningsgrowth10k_18k = [earnings for earnings in df10_18k_grouped['earnings_growth_y6_y10']]\n\nearningsgrowth18k_32k = [earnings for earnings in df18_32_grouped['earnings_growth_y6_y10']]\n\nearningsgrowth32kk = [earnings for earnings in df32_grouped['earnings_growth_y6_y10']]```"}, {'reason': 'stop', 'result': "```python\n# Load the clip file\n_ = VideoFileClip('challenge.mp4')```"}, {'reason': 'stop', 'result': '```python\nforecast_lstm(lstm_model, 1, X)```'}, {'reason': 'stop', 'result': '```python\n#call pandas describe method on dataframe\ndata.describe(include = "all")\n\n#transpose\ndescribe_transposed = describe.T\n\n#reset_index, moving the column names into a new series\ndescribe_transposed.reset_index()```'}, {'reason': 'stop', 'result': '```python\n```'}, {'reason': 'stop', 'result': "```python\n# Create the mfusg headfile object\nheadfile = os.path.join(modelpth, '{0}.hds'.format(modelname))\nheadobj = flopy.utils.HeadFile(headfile)\ntimes = headobj.get_times()```"}, {'reason': 'stop', 'result': '```python\nplt.subplots(figsize=(16,8))\ndfBabies.boxplot(column="weight", by="smoke", ax=ax, return_type="dict")\n\nfor _ in bp:\n    for box in _[\'boxes\']:\n        box.set(color=\'steelblue\', linewidth=2)\n    \n    for whisker in _[\'whiskers\']:\n        whisker.set(color=\'gray\', linewidth=2)\n\n    for cap in _[\'caps\']:\n        cap.set(color=\'gray\', linewidth=2)\n\n    for cap in _[\'medians\']:\n        cap.set(color=\'green\', linewidth=2, alpha=0.5)\n\n    for cap in _[\'fliers\']:\n        cap.set(markerfacecolor=\'steelblue\', linewidth=2, marker=\'s\', markersize=6, alpha=0.5)\n\nplt.title(\'Weight of Smoker\\\'s Babies vs Non-Smoker\\\'s Babies\', fontsize=18)\nplt.ylabel("Weight (in Ounces)", fontsize=16)\n\nplt.xticks(range(1,len(_)+1),_, rotation=90, fontsize=16)\n\nplt.suptitle("")\nplt.xlabel("")\n\nplt.grid(alpha=0.25)```'}, {'reason': 'stop', 'result': '```python\ndata = Table.read(cadencepath, format = "ascii.commented_header")\nnp.logical_or(data["filter"] == "LSST_g", data["filter"] == "LSST_r")\n\ndata["MJD"].data\nconvert_column_string_encoding(data["filter"]).data```'}, {'reason': 'length', 'result': '```python\nimport math\n\ndef grayscale(img):\n    """Applies the Grayscale transform\n    This will return an image with only one color channel\n    but NOTE: to see the returned image as grayscale\n    you should call plt.imshow(gray, cmap=\'gray\')"""\n    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n    # Or use BGR2GRAY if you read an image with cv2.imread()\n    # return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    \ndef canny(img, low_threshold, high_threshold):\n    """Applies the Canny transform"""\n    return cv2.Canny(img, low_threshold, high_threshold)\n\ndef gaussian_blur(img, kernel_size):\n    """Applies a Gaussian Noise kernel"""\n    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n\ndef region_of_interest(img, vertices):\n    """\n    Applies an image mask.\n    \n    Only keeps the region of the image defined by the polygon\n    formed from `vertices`. The rest of the image is set to black.\n    """\n    #defining a blank mask to start with\n    mask = np.zeros_like(img)   \n    \n    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n    if len(img.shape) > 2:\n        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n        ignore_mask_color = (255,) * channel_count\n    else:\n        ignore_mask_color = 255\n        \n    #filling pixels inside the polygon defined by "vertices" with the fill color    \n    cv2.fillPoly(mask, vertices, ignore_mask_color)\n    \n    #returning the image only where mask pixels are nonzero\n    masked_image = cv2.bitwise_and(img, mask)\n    return masked_image\n\n\'\'\' Calculate filtered results \'\'\'\ndef filterFn(alpha, prev, new):\n    return alpha * new + (1 - alpha) * prev\n\n\'\'\' Clear global previous between videos \'\'\'\ndef clearUnjitter():\n    global previous\n    previous = {\n        "right": [0, 0, 0, 0], # x1, y1, x2, y2\n        "left": [0, 0, 0, 0]\n    }\n\n\'\'\'\nUnjitter it as tipped by Vivek Jadav in the following topic:\nhttps://carnd-forums.udacity.com/display/CAR/questions/22086201/p1-how-to-avoid-jittery-lines\n\'\'\'\ndef unjitter(side, value):\n    global previous\n    alpha = 0.6\n    # destructure value\n    x1 = value[0]\n    y1 = value[1]\n    x2 = value[2]\n    y2 = value[3]\n    # set start value on first frame\n    if previous[side][0] == 0:\n        previous[side][0] = x1\n    if previous[side][1] == 0:\n        previous[side][1] = y1\n    if previous[side][2] == 0:\n        previous[side][2] = x2\n    if previous[side][3] == 0:\n        previous[side][3] = y2\n    # calculate filtered results\n    x1 = filterFn(alpha, previous[side][0], x1)\n    y1 = filterFn(alpha, previous[side][1], y1)\n    x2 = filterFn(alpha, previous[side][2], x2)\n    y2 = filterFn(alpha, previous[side][3], y2)\n    # set new values to previous\n    previous[side][0] = x1\n    previous[side][1] = y1\n    previous[side][2] = x2\n    previous[side][3] = y2\n    return [x1, y1, x2, y2]\n\ndef draw_lines(img, lines, color=[255, 0, 0], thickness=5):\n    global previous\n    """\n    NOTE: this is the function you might want to use as a starting point once you want to \n    average/extrapolate the line segments you detect to map out the full\n    extent of the lane (going from the result shown in raw-lines-example.mp4\n    to that shown in P1_example.mp4).  \n    \n    Think about things like separating line segments by their \n    slope ((y2-y1)/(x2-x1)) to decide which segments are part of the left\n    line vs. the right line.  Then, you can average the position of each of \n    the lines and extrapolate to the top and bottom of the lane.\n    \n    This function draws `lines` with `color` and `thickness`.    \n    Lines are drawn on the image inplace (mutates the image).\n    If you want to make the lines semi-transparent, think about combining\n    this function with the weighted_img() function below\n    """\n    sides = {\n        "left": [],\n        "right": []\n    }\n    yMin = img.shape[0]\n    xHalf = img.shape[1] / 2\n    yMax = 315\n    if lines != None:\n        for line in lines:\n            for x1,y1,x2,y2 in line:\n                slope = ((y2 - y1) / (x2 - x1))\n                if slope > 0.50 and slope < 0.8: # Right line, because of positive slope (y-reversed)\n                    sides["right"].append([x1,y1,x2,y2]) \n                elif slope < -0.50 and slope > -0.8: # Left line because of negative slope\n                    sides["left"].append([x1,y1,x2,y2])\n    yHalf = None\n    for side in sides:\n        avgSlope = None\n        totalSlope = 0\n        totalWeight = 0\n        xAvg = None\n        yAvg = None\n        for x1,y1,x2,y2 in sides[side]:\n            slope = (y2 - y1) / (x2 - x1)\n            length = math.sqrt(abs(x2-x1)^2+abs(y2 - y1)^2)\n            if xAvg == None:\n                #avgSlope = slope\n                xAvg = (x1 + x2) / 2\n                yAvg = (y1 + y2) / 2\n            else:\n                #avgSlope = (avgSlope + slope) / 2\n                xAvg = (xAvg + ((x1 + x2) / 2)) / 2\n                yAvg = (yAvg + ((y1 + y2) / 2)) / 2\n            totalSlope += slope * length\n            totalWeight += length\n        if totalWeight > 0:\n            avgSlope = totalSlope / totalWeight\n        if avgSlope != None and xAvg != None and yAvg != None:\n            yIntercept = -(avgSlope * xAvg) + yAvg\n            xMax = (yMax - yIntercept) / avgSlope\n            xMin = (yMin - yIntercept) / avgSlope\n            if side == "right":\n                offset = 20\n            else:\n                offset = -20\n            _yHalf = avgSlope * (xHalf + offset) + yIntercept \n            if yHalf == None:\n                yHalf = _yHalf\n            else:\n                xHalf'}, {'reason': 'skipped', 'result': 'def highlight_column_matches(data, column=\'\', color=\'yellow\'):\n    \'\'\'\n    highlight the maximum in a Series or DataFrame\n    \'\'\'\n    attr = \'background-color: {}\'.format(color)\n    if data.ndim == 1:  # Series from .apply(axis=0) or axis=1\n        is_mixed = data == data[column]\n        return [attr if v else \'\' for v in is_mixed]\n    else:  # from .apply(axis=None)\n        is_mixed = data == data[column]\n        return pd.DataFrame(np.where(is_mixed, attr, \'\'), index=data.index, columns=data.columns)\n\ndef plot_stats(csv_filename, columns=[\'total_reward\'], **kwargs):\n    """Plot specified columns from CSV file."""\n    df_stats = pd.read_csv(csv_filename)\n    df_stats[columns].plot(**kwargs)\n\ndef save_rnn_layers(hidden_layers, output_layers):\n    for i, layer in hidden_layers.items():\n        np.save(os.path.join(vsig.out_dir, \'valid_hidden_layer_\' + i + \'_output\'), hidden_layers[i][\'output\'])\n        np.save(os.path.join(vsig.out_dir, \'valid_hidden_layer_\' + i + \'_state\'), hidden_layers[i][\'state\'])\n#     np.save(os.path.join(vsig.out_dir, \'valid_hidden_layer_2_output\'), hidden_layers[\'2\'][\'output\'])\n#     np.save(os.path.join(vsig.out_dir, \'valid_hidden_layer_2_state\'), hidden_layers[\'2\'][\'state\'])\n    np.save(os.path.join(vsig.out_dir, \'valid_output_layer\'), output_layers)\n    \ndef save_mlp_layers(hidden_layers, output_layers):\n    for i, layer in hidden_layers.items():\n        np.save(os.path.join(vsig.out_dir, \'valid_hidden_layer_\' + i + \'_output\'), layer)\n    np.save(os.path.join(vsig.out_dir, \'valid_output_layer\'), output_layers)\n    \ndef glance_at_tensor(tensor):\n    if len(tensor.shape) == 3:\n        print(tensor[:10, 0, 0])\n        print(tensor[0, :10, 0])\n        print(tensor[0, 0, :10])\n        print(\'\')\n        print(tensor[-10:, -1, -1])\n        print(tensor[-1, -10:, -1])\n        print(tensor[-1, -1, -10:])\n    elif len(tensor.shape) == 4:\n        print(tensor[:10, 0, 0, 0])\n        print(tensor[0, :10, 0, 0])\n        print(tensor[0, 0, :10, 0])\n        print(tensor[0, 0, 0, :10])\n        print(\'\')\n        print(tensor[-10:, -1, -1, -1])\n        print(tensor[-1, -10:, -1, -1])\n        print(tensor[-1, -1, -10:, -1])\n        print(tensor[-1, -1, -1, -10:])\n        \nclassifier_activation = {\'binary\': \'sigmoid\', \'categorical\': \'softmax\'}'}, {'reason': 'skipped', 'result': 'def error_line_trace(x_values, y_values, m, b, x):\n    pass'}, {'reason': 'stop', 'result': '```python\nbeta = sp.stats.beta.rvs(1, alpha, size=(N, K))\nw = np.empty_like(beta)\nw[:, 0] = beta[:, 0]\nw[:, 1:] = beta[:, 1:] * (1 - beta[:, :-1]).cumprod(axis=1)\n\nomega = P0.rvs(size=(N, K))```'}, {'reason': 'stop', 'result': '```python\ndef insert_and_time_filter_bloom_filter(capacity, percent_fill=0.9):\n    b_filter = CountingBloomFilter(capacity)\n    for i in range(int(percent_fill*capacity)):\n        b_filter.add(str(i))\n    return b_filter```'}, {'reason': 'skipped', 'result': "targets = np.array(['Vessel underway (stern)',\n                    'Power-driven vessel underway (>50m in length) (starboard)',\n                    'Power-driven vessel underway (>50m in length) (port)',\n                    'Power-driven vessel underway (>50m in length) (bow)',\n                    'Power-driven vessel underway (<50m in length) (starboard)',\n                    'Power-driven vessel underway (<50m in length) (port)',\n                    'Power-driven vessel underway (<50m in length) (bow)'], dtype=np.dtype('unicode_'))"}, {'reason': 'stop', 'result': '```python\nplt.show()```'}, {'reason': 'stop', 'result': "```python\nfor (_, _) in ('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf):\n    _.fit(X_train, y_train)```"}, {'reason': 'stop', 'result': '```python\n#include the observations, which are Bernoulli\nwith model:\n    obs = pm.Bernoulli("obs", p, observed=occurrences)\n    # To be explained in chapter 3\n    step = pm.Metropolis()\n    trace = pm.sample(18000, step=step)```'}, {'reason': 'stop', 'result': '```python\n# Action Directions\nnorth = (0, 1)\nsouth = (0,-1)\nwest = (-1, 0)\neast = (1, 0)```'}]