{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nShot and decomposed prompting: decompose into identify then remove\\n\\nIdentify: 4-shot\\nRemove: 4-shot\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Shot and decomposed prompting: decompose into identify then remove\n",
    "\n",
    "Identify: 4-shot\n",
    "Remove: 4-shot\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "from run_process import get_unused_data\n",
    "sys.path.append('../../../')\n",
    "from utils import print_check_gpt_results, stats_results_unused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables\n",
    "NUM_FILES = 305\n",
    "SAMPLES_FOLDER_NAME = '../random_samples_variables'\n",
    "GPT_SAVED_FILE_NAME = 'unused_variables_gpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in files from folder random_cells\n",
    "random_cells = []\n",
    "\n",
    "for i in range(NUM_FILES):\n",
    "    file_name = f'{SAMPLES_FOLDER_NAME}/{i}.py'\n",
    "    with open(file_name, 'r') as f:\n",
    "        random_cells.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1 = \"A variable is unused if it is assigned using an equals operator but is not referenced after being defined. Identify unused variables in the code delimited by triple backticks. Ignore unused functions, imports, or classes. Output this as a list of variables names.\"\n",
    "\n",
    "task1_ex1_input = \"\"\"```python\n",
    "time = 5\n",
    "d = 5\n",
    "print(d)\n",
    "\n",
    "def calc():\n",
    "    a = 5\n",
    "    b = 4\n",
    "    return a + b\n",
    "```\"\"\"\n",
    "\n",
    "task1_ex1_output = \"\"\"[\"time\"]\"\"\"\n",
    "\n",
    "task1_ex2_input = \"\"\"```python\n",
    "val1 = 'hello'\n",
    "val2 = 'world'\n",
    "```\"\"\"\n",
    "\n",
    "task1_ex2_output = \"\"\"['val1', 'val2']\"\"\"\n",
    "\n",
    "task1_ex3_input = \"\"\"```python\n",
    "z = [1, 2, 3]\n",
    "a, b, c = z\n",
    "print(a + b)\n",
    "```\"\"\"\n",
    "\n",
    "task1_ex3_output = \"\"\"['c']\"\"\"\n",
    "\n",
    "task1_ex4_input = \"\"\"```python\n",
    "def associate():\n",
    "    return center.path()\n",
    "\n",
    "path = associate()\n",
    "```\"\"\"\n",
    "\n",
    "task1_ex4_output = \"\"\"['path']\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # identify unused\n",
    "# import openai\n",
    "# openai.api_key = my_key\n",
    "\n",
    "# # GPT\n",
    "# def identify_unused(cell_src):\n",
    "#     while True:\n",
    "#         try:\n",
    "#             completion = openai.ChatCompletion.create(\n",
    "#                 model=\"gpt-3.5-turbo\",\n",
    "#                 temperature=0,\n",
    "#                 messages = [\n",
    "#                 {\"role\": \"user\", \"content\": task1},\n",
    "#                 {\"role\": \"user\", \"content\": task1_ex1_input},\n",
    "#                 {\"role\": \"assistant\", \"content\": task1_ex1_output},\n",
    "#                 {\"role\": \"user\", \"content\": task1_ex2_input},\n",
    "#                 {\"role\": \"assistant\", \"content\": task1_ex2_output},\n",
    "#                 {\"role\": \"user\", \"content\": task1_ex3_input},\n",
    "#                 {\"role\": \"assistant\", \"content\": task1_ex3_output},\n",
    "#                 {\"role\": \"user\", \"content\": task1_ex4_input},\n",
    "#                 {\"role\": \"assistant\", \"content\": task1_ex4_output},\n",
    "#                 {\"role\": \"user\", \"content\": f\"```python\\n{cell_src}\\n```\"}\n",
    "#             ]\n",
    "#             )\n",
    "#         except Exception as e:\n",
    "#             if 'maximum context length' in str(e):\n",
    "#                 print('...Error.. too long...' + str(e))\n",
    "#                 return 'length', None\n",
    "#             else:\n",
    "#                 print('...Error.. trying again...' + str(e))\n",
    "#         else:\n",
    "#             break\n",
    "#     return completion.choices[0].finish_reason, completion.choices[0].message[\"content\"]\n",
    "\n",
    "# gpt_results = []\n",
    "# for i, cell_src in enumerate(random_cells):\n",
    "#     print(f'Processing file {i}')\n",
    "#     finish_reason, result = identify_unused(cell_src)\n",
    "#     print(f'File {i} - {finish_reason}')\n",
    "#     gpt_results.append({'reason': finish_reason, 'result': result})\n",
    "\n",
    "# # save the results to a file\n",
    "# with open(GPT_SAVED_FILE_NAME, 'w') as f:\n",
    "#     f.write(str(gpt_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in gpt result from file\n",
    "with open(GPT_SAVED_FILE_NAME, 'r') as f:\n",
    "    gpt_results = eval(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop: 305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_check_gpt_results(gpt_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results to a variable\n",
    "gpt_unused_names = []\n",
    "for var in gpt_results:\n",
    "    if var['reason'] == 'stop':\n",
    "        try:\n",
    "            res = eval(var['result'])\n",
    "        except:\n",
    "            gpt_unused_names.append(None)\n",
    "        else:\n",
    "            if res == []:\n",
    "                gpt_unused_names.append(None)\n",
    "            else:\n",
    "                gpt_unused_names.append(res)\n",
    "    else:\n",
    "        gpt_unused_names.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "task2 = \"\"\"Remove the variables specified from the code snippet enclosed by triple backticks. Do not add, modify, or remove anything else. If removing variables that are in an unpacking statement, change it to an underscore. Output the updated code with the specified variables removed.\"\"\"\n",
    "\n",
    "task2_ex1_input = \"\"\"Code:\n",
    "```python\n",
    "time = 5\n",
    "d = 5\n",
    "print(d)\n",
    "\n",
    "def calc():\n",
    "    a = 5\n",
    "    b = 4\n",
    "    return a + b\n",
    "```\n",
    "\n",
    "Variables to remove:\n",
    "['time']\"\"\"\n",
    "\n",
    "task2_ex1_output = \"\"\"```python\n",
    "d = 5\n",
    "print(d)\n",
    "\n",
    "def calc():\n",
    "    a = 5\n",
    "    b = 4\n",
    "    return a + b\n",
    "```\"\"\"\n",
    "\n",
    "task2_ex2_input = \"\"\"Code:\n",
    "```python\n",
    "val1 = 'hello'\n",
    "val2 = 'world'\n",
    "```\n",
    "\n",
    "Variables to remove:\n",
    "['val1', 'val2']\"\"\"\n",
    "\n",
    "task2_ex2_output = \"\"\"```python\n",
    "```\"\"\"\n",
    "\n",
    "task2_ex3_input = \"\"\"Code:\n",
    "```python\n",
    "z = [1, 2, 3]\n",
    "a, b, c = z\n",
    "print(a + b)\n",
    "```\n",
    "\n",
    "Variables to remove:\n",
    "['c']\"\"\"\n",
    "\n",
    "task2_ex3_output = \"\"\"```python\n",
    "z = [1, 2, 3]\n",
    "a, b, _ = z\n",
    "print(a + b)\n",
    "```\"\"\"\n",
    "\n",
    "task2_ex4_input = \"\"\"\"Code:\n",
    "```python\n",
    "def associate():\n",
    "    return center.path()\n",
    "\n",
    "path = associate()\n",
    "```\n",
    "\n",
    "Variables to remove:\n",
    "['path']\"\"\"\n",
    "\n",
    "task2_ex4_output = \"\"\"```python\n",
    "def associate():\n",
    "    return center.path()\n",
    "```\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.455434"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimate cost\n",
    "import sys\n",
    "sys.path.append(\"../../..\")\n",
    "import utils\n",
    "\n",
    "def estimate_tokens():\n",
    "    in_tok = ''\n",
    "    out_tok = ''\n",
    "    for i, cell_src in enumerate(random_cells):\n",
    "        # estimate prompt\n",
    "        in_tok += task1 + task1_ex1_input + task1_ex1_output + task1_ex2_input + task1_ex2_output + task1_ex3_input + task1_ex3_output + task1_ex4_input + task1_ex4_output\n",
    "        in_tok += f\"```python\\n{cell_src}\\n```\"\n",
    "        in_tok += task2 + task2_ex1_input + task2_ex1_output + task2_ex2_input + task2_ex2_output + task2_ex3_input + task2_ex3_output + task2_ex4_input + task2_ex4_output\n",
    "        in_tok += f\"Code:\\n```python\\n{cell_src}\\n```\\n\\nVariables to remove:\\n['test1', 'test2']\"\n",
    "        # estimate response\n",
    "        out_tok += \"The new name is so much better because it is amazing now and so cool wow yes very beautiful and pretty.\"\n",
    "        out_tok += cell_src\n",
    "    return in_tok, out_tok\n",
    "\n",
    "in_tok, out_tok = estimate_tokens()\n",
    "\n",
    "utils.gpt_35_turbo_token_dollar_cost(in_tok, out_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove unused\n",
    "# import openai\n",
    "# openai.api_key = my_key\n",
    "\n",
    "# # GPT\n",
    "# def remove_unused(cell_src, function_names):\n",
    "#     while True:\n",
    "#         try:\n",
    "#             completion = openai.ChatCompletion.create(\n",
    "#                 model=\"gpt-3.5-turbo\",\n",
    "#                 temperature=0,\n",
    "#                 messages = [\n",
    "#                 {\"role\": \"user\", \"content\": task2},\n",
    "#                 {\"role\": \"user\", \"content\": task2_ex1_input},\n",
    "#                 {\"role\": \"assistant\", \"content\": task2_ex1_output},\n",
    "#                 {\"role\": \"user\", \"content\": task2_ex2_input},\n",
    "#                 {\"role\": \"assistant\", \"content\": task2_ex2_output},\n",
    "#                 {\"role\": \"user\", \"content\": task2_ex3_input},\n",
    "#                 {\"role\": \"assistant\", \"content\": task2_ex3_output},\n",
    "#                 {\"role\": \"user\", \"content\": task2_ex4_input},\n",
    "#                 {\"role\": \"assistant\", \"content\": task2_ex4_output},\n",
    "#                 {\"role\": \"user\", \"content\": f\"Code:\\n```python\\n{cell_src}\\n```\\n\\nVariables to remove:\\n{function_names}\"}\n",
    "#             ]\n",
    "#             )\n",
    "#         except Exception as e:\n",
    "#             if 'maximum context length' in str(e):\n",
    "#                 print('...Error.. too long...' + str(e))\n",
    "#                 return 'length', None\n",
    "#             else:\n",
    "#                 print('...Error.. trying again...' + str(e))\n",
    "#         else:\n",
    "#             break\n",
    "#     return completion.choices[0].finish_reason, completion.choices[0].message[\"content\"]\n",
    "\n",
    "# gpt_results_code = []\n",
    "# for i, cell_src in enumerate(random_cells):\n",
    "#     print(f'Processing file {i}')\n",
    "#     if gpt_unused_names[i] is None:\n",
    "#         finish_reason = 'skipped'\n",
    "#         result = None\n",
    "#         print('...skipping due to failed identified...')\n",
    "#     else:\n",
    "#         finish_reason, result = remove_unused(cell_src, gpt_unused_names[i])\n",
    "#     print(f'File {i} - {finish_reason}')\n",
    "#     gpt_results_code.append({'reason': finish_reason, 'result': result})\n",
    "\n",
    "# # save the results to a file\n",
    "# with open(GPT_SAVED_FILE_NAME + \"_code\", 'w') as f:\n",
    "#     f.write(str(gpt_results_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in gpt result from file\n",
    "with open(GPT_SAVED_FILE_NAME + \"_code\", 'r') as f:\n",
    "    gpt_results_code = eval(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop: 279\n",
      "skipped: 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " 6,\n",
       " 30,\n",
       " 44,\n",
       " 50,\n",
       " 76,\n",
       " 99,\n",
       " 117,\n",
       " 129,\n",
       " 143,\n",
       " 144,\n",
       " 147,\n",
       " 150,\n",
       " 163,\n",
       " 179,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 196,\n",
       " 198,\n",
       " 222,\n",
       " 266,\n",
       " 283,\n",
       " 290,\n",
       " 293,\n",
       " 300]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_check_gpt_results(gpt_results_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the updated code to files\n",
    "gpt_code = []\n",
    "\n",
    "# get all the code from the results\n",
    "for i, result in enumerate(gpt_results_code):\n",
    "    if result['reason'] == 'stop':\n",
    "        new = result['result'].split(\"```\")\n",
    "        if len(new) == 1:\n",
    "            new = None\n",
    "        else:\n",
    "            new = new[1]\n",
    "            if new.startswith('python'):\n",
    "                new = new[6:].strip(\"\\n\")\n",
    "        gpt_code.append(new)\n",
    "    else:\n",
    "        gpt_code.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the updated code to files\n",
    "import os\n",
    "if not os.path.exists('gpt_code'):\n",
    "    os.makedirs('gpt_code')\n",
    "for i, code in enumerate(gpt_code):\n",
    "    with open(f'gpt_code/{i}.py', 'w') as f:\n",
    "        if gpt_unused_names[i] is None or gpt_code[i] is None:\n",
    "            f.write(random_cells[i])\n",
    "        else:\n",
    "            f.write(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total before: 586\n"
     ]
    }
   ],
   "source": [
    "before = get_unused_data(NUM_FILES, SAMPLES_FOLDER_NAME, 'variable')\n",
    "\n",
    "total_before = sum(len(item) for item in before)\n",
    "print(f'Total before: {total_before}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total after: 205\n"
     ]
    }
   ],
   "source": [
    "after = get_unused_data(NUM_FILES, 'gpt_code', 'variable')\n",
    "\n",
    "total_after = sum(len(item) for item in after)\n",
    "print(f'Total after: {total_after}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total percentage difference: -65.01706484641639%\n"
     ]
    }
   ],
   "source": [
    "# List percentage difference between before and after for total\n",
    "print(f'Total percentage difference: {(total_after - total_before) / total_before * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT before count: 804\n",
      "Vulture before count: 586\n",
      "------------\n",
      "True positives: 424\n",
      "False positives: 380\n",
      "False negatives: 141\n",
      "------------\n",
      "Files with at least one false positive (and no false negatives)\n",
      "2: 3 false positives\n",
      "3: 2 false positives\n",
      "4: 2 false positives\n",
      "11: 3 false positives\n",
      "18: 1 false positives\n",
      "22: 3 false positives\n",
      "32: 1 false positives\n",
      "33: 4 false positives\n",
      "35: 1 false positives\n",
      "42: 1 false positives\n",
      "56: 1 false positives\n",
      "61: 9 false positives\n",
      "67: 1 false positives\n",
      "71: 2 false positives\n",
      "78: 1 false positives\n",
      "79: 2 false positives\n",
      "82: 1 false positives\n",
      "91: 3 false positives\n",
      "109: 5 false positives\n",
      "111: 2 false positives\n",
      "113: 2 false positives\n",
      "118: 1 false positives\n",
      "121: 2 false positives\n",
      "123: 6 false positives\n",
      "131: 4 false positives\n",
      "132: 1 false positives\n",
      "134: 11 false positives\n",
      "135: 1 false positives\n",
      "136: 2 false positives\n",
      "146: 9 false positives\n",
      "151: 10 false positives\n",
      "152: 3 false positives\n",
      "155: 1 false positives\n",
      "158: 4 false positives\n",
      "160: 4 false positives\n",
      "166: 5 false positives\n",
      "191: 1 false positives\n",
      "194: 12 false positives\n",
      "195: 8 false positives\n",
      "207: 2 false positives\n",
      "217: 4 false positives\n",
      "228: 6 false positives\n",
      "232: 7 false positives\n",
      "236: 6 false positives\n",
      "239: 1 false positives\n",
      "243: 1 false positives\n",
      "246: 6 false positives\n",
      "247: 2 false positives\n",
      "255: 4 false positives\n",
      "262: 1 false positives\n",
      "268: 1 false positives\n",
      "270: 1 false positives\n",
      "276: 5 false positives\n",
      "279: 2 false positives\n",
      "286: 3 false positives\n",
      "287: 11 false positives\n",
      "289: 1 false positives\n",
      "------------\n",
      "Files with at least one false negative (and no false positives)\n",
      "5: 1 false negatives\n",
      "6: 7 false negatives\n",
      "12: 2 false negatives\n",
      "30: 3 false negatives\n",
      "44: 3 false negatives\n",
      "50: 8 false negatives\n",
      "51: 2 false negatives\n",
      "54: 1 false negatives\n",
      "76: 6 false negatives\n",
      "83: 1 false negatives\n",
      "89: 1 false negatives\n",
      "99: 3 false negatives\n",
      "105: 1 false negatives\n",
      "107: 3 false negatives\n",
      "117: 3 false negatives\n",
      "129: 1 false negatives\n",
      "130: 2 false negatives\n",
      "143: 1 false negatives\n",
      "144: 1 false negatives\n",
      "145: 3 false negatives\n",
      "147: 2 false negatives\n",
      "150: 1 false negatives\n",
      "163: 2 false negatives\n",
      "178: 1 false negatives\n",
      "179: 2 false negatives\n",
      "184: 1 false negatives\n",
      "185: 2 false negatives\n",
      "186: 2 false negatives\n",
      "189: 2 false negatives\n",
      "192: 1 false negatives\n",
      "196: 1 false negatives\n",
      "198: 2 false negatives\n",
      "220: 2 false negatives\n",
      "222: 5 false negatives\n",
      "266: 2 false negatives\n",
      "275: 1 false negatives\n",
      "282: 1 false negatives\n",
      "283: 1 false negatives\n",
      "290: 2 false negatives\n",
      "291: 2 false negatives\n",
      "293: 3 false negatives\n",
      "300: 3 false negatives\n",
      "304: 1 false negatives\n"
     ]
    }
   ],
   "source": [
    "stats_results_unused(gpt_unused_names, before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Haringey\n",
      "# find steady state based on 2012 data\n",
      "\n",
      "cov_2012 = 0.267007002375\n",
      "adpc_2012 = 0.0346976493046\n",
      "[incsol, scrsol] = fsolve(\n",
      "    lambda x: [test_diag_fun(x)[0] - cov_2012, test_diag_fun(x)[1] - adpc_2012], \n",
      "    [0.09, 0.25] \n",
      "    )\n",
      "\n",
      "U_2012 = U_fun(\n",
      "    incsol*p_asymp, sc + scrsol*p_true_pos, incsol*(1-p_asymp), scrsol*p_true_pos + att_symp*p_true_pos\n",
      "    )\n",
      "A_2012 = A_fun(\n",
      "    incsol*p_asymp, sc + scrsol*p_true_pos, incsol*(1-p_asymp), scrsol*p_true_pos + att_symp*p_true_pos\n",
      "    )\n",
      "S_2012 = S_fun(\n",
      "    incsol*p_asymp, sc + scrsol*p_true_pos, incsol*(1-p_asymp), scrsol*p_true_pos + att_symp*p_true_pos\n",
      "    )\n",
      "\n",
      "\n",
      "# find incidence and screening based on 2013 data\n",
      "cov_2013 = 0.190544970144\n",
      "adpc_2013 = 0.0184872060681\n",
      "[incsol, scrsol] = fsolve(\n",
      "    lambda x: [test_diag_fun(x)[0] - cov_2013, test_diag_fun(x)[1] - adpc_2013], \n",
      "    [0.09, 0.25] \n",
      "    )\n",
      "\n",
      "# solve, 2012-2013\n",
      "inc = incsol\n",
      "scr = scrsol\n",
      "parms = \\\n",
      "    [incsol*p_asymp, sc + scrsol*p_true_pos, incsol*(1-p_asymp), scrsol*p_true_pos + att_symp*p_true_pos]\n",
      "\n",
      "sol_haringey = odeint(dydt, \n",
      "       [U_2012,A_2012,S_2012], \n",
      "       linspace(0,10,1000), \n",
      "       args = (parms,)\n",
      "      )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(random_cells[51])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Haringey\n",
      "# find steady state based on 2012 data\n",
      "\n",
      "cov_2012 = 0.267007002375\n",
      "adpc_2012 = 0.0346976493046\n",
      "[incsol, scrsol] = fsolve(\n",
      "    lambda x: [test_diag_fun(x)[0] - cov_2012, test_diag_fun(x)[1] - adpc_2012], \n",
      "    [0.09, 0.25] \n",
      "    )\n",
      "\n",
      "U_2012 = U_fun(\n",
      "    incsol*p_asymp, sc + scrsol*p_true_pos, incsol*(1-p_asymp), scrsol*p_true_pos + att_symp*p_true_pos\n",
      "    )\n",
      "A_2012 = A_fun(\n",
      "    incsol*p_asymp, sc + scrsol*p_true_pos, incsol*(1-p_asymp), scrsol*p_true_pos + att_symp*p_true_pos\n",
      "    )\n",
      "S_2012 = S_fun(\n",
      "    incsol*p_asymp, sc + scrsol*p_true_pos, incsol*(1-p_asymp), scrsol*p_true_pos + att_symp*p_true_pos\n",
      "    )\n",
      "\n",
      "\n",
      "# find incidence and screening based on 2013 data\n",
      "cov_2013 = 0.190544970144\n",
      "adpc_2013 = 0.0184872060681\n",
      "[incsol, scrsol] = fsolve(\n",
      "    lambda x: [test_diag_fun(x)[0] - cov_2013, test_diag_fun(x)[1] - adpc_2013], \n",
      "    [0.09, 0.25] \n",
      "    )\n",
      "\n",
      "# solve, 2012-2013\n",
      "inc = incsol\n",
      "scr = scrsol\n",
      "parms = \\\n",
      "    [incsol*p_asymp, sc + scrsol*p_true_pos, incsol*(1-p_asymp), scrsol*p_true_pos + att_symp*p_true_pos]\n",
      "\n",
      "odeint(dydt, \n",
      "       [U_2012,A_2012,S_2012], \n",
      "       linspace(0,10,1000), \n",
      "       args = (parms,)\n",
      "      )\n"
     ]
    }
   ],
   "source": [
    "print(gpt_code[51])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inc', 'scr', 'sol_haringey']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before[51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inc', 'scr']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after[51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sol_haringey']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_unused_names[51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete 'gpt_code' folder\n",
    "!rm -rf gpt_code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
