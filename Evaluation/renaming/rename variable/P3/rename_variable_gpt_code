[{'reason': 'stop', 'result': '```python\nnum_nodes = 64\ngraph = tf.Graph()\nwith graph.as_default():\n    ix = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n    im = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n    ib = tf.Variable(tf.zeros([1, num_nodes]))\n    fx = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n    fm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n    fb = tf.Variable(tf.zeros([1, num_nodes]))\n    cx = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n    cm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n    cb = tf.Variable(tf.zeros([1, num_nodes]))\n    ox = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n    om = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n    ob = tf.Variable(tf.zeros([1, num_nodes]))\n    saved_output = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False)\n    saved_state = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False)\n    w = tf.Variable(tf.truncated_normal([num_nodes, vocabulary_size], -0.1, 0.1))\n    b = tf.Variable(tf.zeros([vocabulary_size]))\n\n    def lstm_cell(i, o, state):\n        """Create a LSTM cell. See e.g.: http://arxiv.org/pdf/1402.1128v1.pdf\n    Note that in this formulation, we omit the various connections between the\n    previous state and the gates."""\n        input_gate = tf.sigmoid(tf.matmul(i, ix) + tf.matmul(o, im) + ib)\n        forget_gate = tf.sigmoid(tf.matmul(i, fx) + tf.matmul(o, fm) + fb)\n        update = tf.matmul(i, cx) + tf.matmul(o, cm) + cb\n        state = forget_gate * state + input_gate * tf.tanh(update)\n        output_gate = tf.sigmoid(tf.matmul(i, ox) + tf.matmul(o, om) + ob)\n        return (output_gate * tf.tanh(state), state)\n    train_data = list()\n    for _ in range(num_unrollings + 1):\n        train_data.append(tf.placeholder(tf.float32, shape=[batch_size, vocabulary_size]))\n    train_inputs = train_data[:num_unrollings]\n    train_labels = train_data[1:]\n    outputs = list()\n    output = saved_output\n    state = saved_state\n    for i in train_inputs:\n        output, state = lstm_cell(i, output, state)\n        outputs.append(output)\n    with tf.control_dependencies([saved_output.assign(output), saved_state.assign(state)]):\n        logits = tf.nn.xw_plus_b(tf.concat(outputs, 0), w, b)\n        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf.concat(train_labels, 0), logits=logits))\n    global_step = tf.Variable(0)\n    learning_rate = tf.train.exponential_decay(10.0, global_step, 5000, 0.1, staircase=True)\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n    gradients, v = zip(*optimizer.compute_gradients(loss))\n    gradients, _ = tf.clip_by_global_norm(gradients, 1.25)\n    optimizer = optimizer.apply_gradients(zip(gradients, v), global_step=global_step)\n    train_prediction = tf.nn.softmax(logits)\n    sample_input = tf.placeholder(tf.float32, shape=[1, vocabulary_size])\n    saved_sample_output = tf.Variable(tf.zeros([1, num_nodes]))\n    saved_sample_state = tf.Variable(tf.zeros([1, num_nodes]))\n    lstm_variable_definition = tf.group(saved_sample_output.assign(tf.zeros([1, num_nodes])), saved_sample_state.assign(tf.zeros([1, num_nodes])))\n    sample_output, sample_state = lstm_cell(sample_input, saved_sample_output, saved_sample_state)\n    with tf.control_dependencies([saved_sample_output.assign(sample_output), saved_sample_state.assign(sample_state)]):\n        sample_prediction = tf.nn.softmax(tf.nn.xw_plus_b(sample_output, w, b))\n```'}, {'reason': 'stop', 'result': "```python\nbottleneck_features = np.load('bottleneck_features/DogVGG16Data.npz')\ntrain_VGG16 = bottleneck_features['train']\nvalid_VGG16 = bottleneck_features['valid']\ntest_bottleneck_features = bottleneck_features['test']\n```"}, {'reason': 'stop', 'result': "```python\nnum_steps = 7001\nsummary_frequency = 100\nwith tf.Session(graph=graph) as session:\n    tf.global_variables_initializer().run()\n    print('Initialized')\n    mean_loss = 0\n    for step in range(num_steps):\n        batches = train_batches.next()\n        feed_dict = dict()\n        for i in range(num_unrollings + 1):\n            feed_dict[train_data[i]] = batches[i]\n        _, l, predictions, lr = session.run([optimizer, loss, train_prediction, learning_rate], feed_dict=feed_dict)\n        mean_loss += l\n        if step % summary_frequency == 0:\n            if step > 0:\n                mean_loss = mean_loss / summary_frequency\n            print('Average loss at step %d: %f learning rate: %f' % (step, mean_loss, lr))\n            mean_loss = 0\n            minibatch_data = np.concatenate(list(batches)[1:])\n            print('Minibatch perplexity: %.2f' % float(np.exp(logprob(predictions, minibatch_data))))\n            if step % (summary_frequency * 10) == 0:\n                print('=' * 80)\n                for _ in range(5):\n                    feed = sample(random_distribution())\n                    sentence = characters(feed)[0]\n                    reset_sample_state.run()\n                    for _ in range(79):\n                        prediction = sample_prediction.eval({sample_input: feed})\n                        feed = sample(prediction)\n                        sentence += characters(feed)[0]\n                    print(sentence)\n                print('=' * 80)\n            reset_sample_state.run()\n            valid_logprob = 0\n            for _ in range(valid_size):\n                b = valid_batches.next()\n                predictions = sample_prediction.eval({sample_input: b[0]})\n                valid_logprob = valid_logprob + logprob(predictions, b[1])\n            print('Validation set perplexity: %.2f' % float(np.exp(valid_logprob / valid_size)))\n```"}, {'reason': 'stop', 'result': "```python\ndef get_model_params():\n    global_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n    return {gvar.op.name: value for gvar, value in zip(global_variables, tf.get_default_session().run(global_variables))}\n\ndef restore_model_params(model_params):\n    gvar_names = list(model_params.keys())\n    assign_ops = {gvar_name: tf.get_default_graph().get_operation_by_name(gvar_name + '/Assign') for gvar_name in gvar_names}\n    init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}\n    feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n    tf.get_default_session().run(assign_ops, feed_dict=feed_dict)\n```"}, {'reason': 'stop', 'result': "```python\nvariable_definition = Variable(name='X', num_states=2)\nX_prior = Factor(name='p(X)', f=np.array([0.95, 0.05]), neighbours=[variable_definition])\nZ = Variable(name='Z', num_states=2)\nZ_prior = Factor(name='p(Z)', f=np.array([0.8, 0.2]), neighbours=[Z])\nY = Variable(name='Y', num_states=2)\nf_Y_cond = [[[0.9999, 0.3], [0.1, 0.01]], [[0.0001, 0.7], [0.9, 0.99]]]\nY_cond = Factor(name='p(Y |X, Z)', f=np.array(f_Y_cond), neighbours=[Y, variable_definition, Z])\n```"}, {'reason': 'stop', 'result': "```python\nimport pyprind\nimport pandas as pd\nimport os\nbasepath = 'aclImdb'\nlabels = {'pos': 1, 'neg': 0}\nprogress_bar = pyprind.ProgBar(50000)\ndf = pd.DataFrame()\nfor s in ('test', 'train'):\n    for l in ('pos', 'neg'):\n        path = os.path.join(basepath, s, l)\n        for file in sorted(os.listdir(path)):\n            with open(os.path.join(path, file), 'r', encoding='utf-8') as infile:\n                txt = infile.read()\n            df = df.append([[txt, labels[l]]], ignore_index=True)\n            progress_bar.update()\ndf.columns = ['review', 'sentiment']\n```"}, {'reason': 'stop', 'result': "```python\ndef LeNet6(x, n_classes):\n    mu = 0\n    sigma = 0.1\n    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6), mean=mu, stddev=sigma))\n    conv1_b = tf.Variable(tf.zeros(6))\n    conv1 = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n    conv1 = tf.nn.relu(conv1)\n    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean=mu, stddev=sigma))\n    conv2_b = tf.Variable(tf.zeros(16))\n    conv2 = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n    conv2 = tf.nn.relu(conv2)\n    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n    fc0 = flatten(conv2)\n    fc1_W = tf.Variable(tf.truncated_normal(shape=(400, 252), mean=mu, stddev=sigma))\n    fc1_b = tf.Variable(tf.zeros(252))\n    fc1 = tf.matmul(fc0, fc1_W) + fc1_b\n    fc1 = tf.nn.relu(fc1)\n    fc1 = tf.nn.dropout(fc1, keep_prob)\n    fc2_W = tf.Variable(tf.truncated_normal(shape=(252, 168), mean=mu, stddev=sigma))\n    fc2_b = tf.Variable(tf.zeros(168))\n    fc2 = tf.matmul(fc1, fc2_W) + fc2_b\n    fc2 = tf.nn.relu(fc2)\n    fc2 = tf.nn.dropout(fc2, keep_prob)\n    fc3_W = tf.Variable(tf.truncated_normal(shape=(168, 84), mean=mu, stddev=sigma))\n    fc3_b = tf.Variable(tf.zeros(84))\n    fc3 = tf.matmul(fc2, fc3_W) + fc3_b\n    fc3 = tf.nn.relu(fc3)\n    fc3 = tf.nn.dropout(fc3, keep_prob)\n    classification_weights = tf.Variable(tf.truncated_normal(shape=(84, n_classes), mean=mu, stddev=sigma))\n    fc4_b = tf.Variable(tf.zeros(n_classes))\n    logits = tf.matmul(fc3, classification_weights) + fc4_b\n    return logits\n```"}, {'reason': 'stop', 'result': '```python\nlearning_rate = 0.02\n```'}, {'reason': 'stop', 'result': '```python\nimage_size = 28\npixel_depth = 255.0\n\ndef load_letter(folder, min_num_images):\n    """Load the data for a single letter label."""\n    image_files = os.listdir(folder)\n    dataset = np.ndarray(shape=(len(image_files), image_size, image_size), dtype=np.float32)\n    print(folder)\n    num_images = 0\n    for image in image_files:\n        image_file = os.path.join(folder, image)\n        try:\n            image_data = (ndimage.imread(image_file).astype(float) - pixel_depth / 2) / pixel_depth\n            if image_data.shape != (image_size, image_size):\n                raise Exception(\'Unexpected image shape: %s\' % str(image_data.shape))\n            dataset[num_images, :, :] = image_data\n            num_images = num_images + 1\n        except IOError as e:\n            print(\'Could not read:\', image_file, \':\', e, "- it\'s ok, skipping.")\n    dataset = dataset[0:num_images, :, :]\n    if num_images < min_num_images:\n        raise Exception(\'Many fewer images than expected: %d < %d\' % (num_images, min_num_images))\n    print(\'Full dataset tensor:\', dataset.shape)\n    print(\'Mean:\', np.mean(dataset))\n    print(\'Standard deviation:\', np.std(dataset))\n    return dataset\n\ndef maybe_pickle(data_folders, min_num_images_per_class, force=False):\n    dataset_names = []\n    for folder in data_folders:\n        set_filename = folder + \'.pickle\'\n        dataset_names.append(set_filename)\n        if os.path.exists(set_filename) and (not force):\n            print(\'%s already present - Skipping pickling.\' % set_filename)\n        else:\n            print(\'Pickling %s.\' % set_filename)\n            dataset = load_letter(folder, min_num_images_per_class)\n            try:\n                with open(set_filename, \'wb\') as f:\n                    pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n            except Exception as e:\n                print(\'Unable to save data to\', set_filename, \':\', e)\n    return dataset_names\ntrain_datasets = maybe_pickle(train_folders, 45000)\ntest_datasets = maybe_pickle(test_folders, 1800)\n```'}, {'reason': 'stop', 'result': "```python\nimport pickle\ntraining_file = '../traffic-signs-data/train.p'\nvalidation_file = '../traffic-signs-data/valid.p'\ntesting_file = '../traffic-signs-data/test.p'\nwith open(training_file, mode='rb') as f:\n    train = pickle.load(f)\nwith open(validation_file, mode='rb') as f:\n    valid = pickle.load(f)\nwith open(testing_file, mode='rb') as f:\n    test_data = pickle.load(f)\nX_train, y_train = (train['features'], train['labels'])\nX_valid, y_valid = (valid['features'], valid['labels'])\nX_test, y_test = (test_data['features'], test_data['labels'])\n```"}, {'reason': 'stop', 'result': "```python\nfrom my_model_selectors import SelectorDIC\ntraining = asl.build_training(features_ground)\nsequences = training.get_all_sequences()\nXlengths = training.get_all_Xlengths()\nfor word in words_to_train:\n    training_time = timeit.default_timer()\n    model = SelectorDIC(sequences, Xlengths, word, min_n_components=2, max_n_components=15, random_state=14).select()\n    end = timeit.default_timer() - training_time\n    if model is not None:\n        print('Training complete for {} with {} states with time {} seconds'.format(word, model.n_components, end))\n    else:\n        print('Training failed for {}'.format(word))\n```"}, {'reason': 'stop', 'result': "```python\noptimizer = tf.train.GradientDescentOptimizer(0.0001)\nmodel = two_layer_nn(output_size=1, loss_type='regression')\nnum_epochs_training = 300\nmodel.fit(X, y, optimizer, num_epochs=num_epochs_training, track_accuracy=False)\n```"}, {'reason': 'stop', 'result': '```python\nfrom sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n\ndef nparray_to_list(nparray):\n    return [x for x in nparray]\n\ndef cv_split(X, y):\n    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.05)\n    X_np = np.asarray(X)\n    y_np = np.asarray(y)\n    for train_index, valid_index in sss.split(X_np, y_np):\n        X_train, X_valid = (nparray_to_list(X_np[train_index]), nparray_to_list(X_np[valid_index]))\n        target_labels, y_valid = (nparray_to_list(y_np[train_index]), nparray_to_list(y_np[valid_index]))\n    train = (X_train, target_labels)\n    valid = (X_valid, y_valid)\n    return (train, valid)\n```'}, {'reason': 'stop', 'result': "```python\nsoftmax_logits = tf.nn.softmax(logits)\ntop_k = tf.nn.top_k(softmax_logits, k=3)\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    saver = tf.train.import_meta_graph('./lenet.meta')\n    saver.restore(sess, './lenet')\n    batch_x = np.expand_dims(my_images_normalized, axis=3)\n    sample_softmax_logits = sess.run(softmax_logits, feed_dict={x: batch_x, keep_prob: 1.0})\n    my_top_k = sess.run(top_k, feed_dict={x: batch_x, keep_prob: 1.0})\n    figure_axes, axs = plt.subplots(len(my_images), 1, figsize=(20, 25))\n    figure_axes.subplots_adjust(hspace=1.0, wspace=0.6)\n    axs = axs.ravel()\n    for i, image in enumerate(my_images):\n        axs[i].axis('off')\n        axs[i].imshow(cv.cvtColor(image, cv.COLOR_BGR2RGB))\n        guess1 = my_top_k[1][i][0]\n        index1 = np.argwhere(y_valid == guess1)[0]\n        guess2 = my_top_k[1][i][1]\n        index2 = np.argwhere(y_valid == guess2)[0]\n        guess3 = my_top_k[1][i][2]\n        index3 = np.argwhere(y_valid == guess3)[0]\n        title = ''\n        title += 'guess 1: class ' + sign_dict[str(guess1)] + ', probability: ' + str(100 * my_top_k[0][i][0]) + '\\n'\n        title += 'guess 2: class ' + sign_dict[str(guess2)] + ', probability: ' + str(100 * my_top_k[0][i][1]) + '\\n'\n        title += 'guess 3: class ' + sign_dict[str(guess3)] + ', probability: ' + str(100 * my_top_k[0][i][2])\n        axs[i].set_title(title)\n```"}, {'reason': 'stop', 'result': "```python\nbatch_size = 128\nembedding_size = 128\nskip_window = 1\nnum_skips = 2\nvalid_size = 16\nvalid_window = 100\nvalid_examples = np.array(random.sample(range(valid_window), valid_size))\nnum_sampled = 64\ngraph = tf.Graph()\nwith graph.as_default(), tf.device('/cpu:0'):\n    train_dataset = tf.placeholder(tf.int32, shape=[batch_size])\n    train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n    valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n    embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n    softmax_weights = tf.Variable(tf.truncated_normal([vocabulary_size, embedding_size], stddev=1.0 / math.sqrt(embedding_size)))\n    softmax_biases = tf.Variable(tf.zeros([vocabulary_size]))\n    embed = tf.nn.embedding_lookup(embeddings, train_dataset)\n    loss = tf.reduce_mean(tf.nn.sampled_softmax_loss(weights=softmax_weights, biases=softmax_biases, inputs=embed, labels=train_labels, num_sampled=num_sampled, num_classes=vocabulary_size))\n    optimizer_operation = tf.train.AdagradOptimizer(1.0).minimize(loss)\n    norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n    normalized_embeddings = embeddings / norm\n    valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings, valid_dataset)\n    similarity = tf.matmul(valid_embeddings, tf.transpose(normalized_embeddings))\n```"}, {'reason': 'stop', 'result': "```python\ndream_within_a_dream_poem = 'Take this kiss upon the brow!\\nAnd, in parting from you now,\\nThus much let me avow —\\nYou are not wrong, who deem\\nThat my days have been a dream;\\nYet if hope has flown away\\nIn a night, or in a day,\\nIn a vision, or in none,\\nIs it therefore the less gone?  \\nAll that we see or seem\\nIs but a dream within a dream.\\n\\nI stand amid the roar\\nOf a surf-tormented shore,\\nAnd I hold within my hand\\nGrains of the golden sand —\\nHow few! yet how they creep\\nThrough my fingers to the deep,\\nWhile I weep — while I weep!\\nO God! Can I not grasp \\nThem with a tighter clasp?\\nO God! can I not save\\nOne from the pitiless wave?\\nIs all that we see or seem\\nBut a dream within a dream?'\n```"}, {'reason': 'stop', 'result': "```python\nfiles = os.listdir('challenge/')\nk_size = 7\nvertex_ratio_h = 0.45\ncanny_edge_detection_threshold = 0.6\nlow_thresh = 60\nhigh_thresh = 100\nL2gradient = False\nrho = 2\ntheta = 1 * np.pi / 180.0\nmin_votes = 15\nmin_line_len = 20\nmax_line_gap = 20\nangle = 3 * np.pi / 16\nangle_thresh = np.pi / 8\ndebug = True\nfor file in files:\n    frame = mpimg.imread('challenge/' + file)\n    fig = plt.figure(figsize=(15, 10))\n    fig.text(0.1, 1, file)\n    result = process_image_3_channels(frame, k_size=k_size, low_thresh=low_thresh, high_thresh=high_thresh, L2gradient=L2gradient, rho=rho, theta=theta, min_votes=min_votes, min_line_len=min_line_len, max_line_gap=max_line_gap, angle=angle, angle_thresh=angle_threshold, debug=debug)\n```"}, {'reason': 'stop', 'result': "```python\nimg[...] = 0\nnormalized_x_coordinate = (x - 400) / 30\nY = -(y - 300) / 30\nR = np.sqrt(normalized_x_coordinate ** 2 + Y ** 2)\nt = np.arctan2(Y, normalized_x_coordinate)\nimg[R < 5] = (1, 0, 0)\nimg[(t > 0) & (t < 3.14 / 4)] = (0, 0, 1)\nplt.imshow(img, interpolation='bilinear')\n```"}, {'reason': 'stop', 'result': "```python\ndef temporal_layer(x, n_neurons, dilation_rate, conv1d_kwargs, normalize=False, dropout=0):\n    h = Conv1D(n_neurons, dilation_rate=dilation_rate, **conv1d_kwargs)(x)\n    if normalize:\n        h = BatchNormalization()(h)\n    h = Activation('relu')(h)\n    if dropout:\n        h = Dropout(dropout)(h)\n    return h\n\ndef temporal_block(h0, n_neurons, dilation_rate, conv1d_kwargs, normalize=False, dropout=0):\n    h1 = temporal_layer(h0, n_neurons, dilation_rate, conv1d_kwargs, normalize=normalize, dropout=dropout)\n    h2 = temporal_layer(h1, n_neurons, dilation_rate, conv1d_kwargs, normalize=normalize, dropout=dropout)\n    res = Conv1D(n_neurons, kernel_size=1)(h0) if h0.shape != h2.shape else h0\n    block = Add()([res, h2])\n    return Activation('relu')(block)\nprint(input_shape, 2 ** n_hidden)\nloss = msig.classification_type + '_crossentropy'\nclassifier_activation_type = classifier_activation[msig.classification_type]\nout_neurons = 1 if msig.classification_type == 'binary' else n_classes\nconv1d_kwargs = dict(kernel_size=kernel_size, padding='causal')\ncompile_kwargs = dict(loss=loss, optimizer='adam', metrics=['accuracy'])\nx = Input(shape=input_shape)\nh = temporal_block(x, n_neurons, 1, conv1d_kwargs, normalize=False)\nfor d in range(1, n_hidden):\n    h = temporal_block(h, n_neurons, 2 ** d, conv1d_kwargs, normalize=False)\nz = Dense(out_neurons, activation=classifier_activation_type)(h)\nmodel = Model(inputs=[x], outputs=[z])\nmodel.compile(**compile_kwargs)\nmodel.summary()\n```"}, {'reason': 'stop', 'result': "```python\nfor i in range(len(data)):\n    species_diversity_index = 0.0\n    for x in range(len(data.iloc[0]))[4:last]:\n        if data.iloc[i][x] > 0:\n            species_diversity_index += -(data.iloc[i][x] / sum(data.iloc[i][4:last][data.iloc[i][4:last] > 0])) * math.log(data.iloc[i][x] / sum(data.iloc[i][4:last][data.iloc[i][4:last] > 0]))\n    data.loc[i, 'SWI_e'] = species_diversity_index\n```"}, {'reason': 'stop', 'result': "```python\ndistance_matrix = pairwise_distances(tf_idf, tf_idf[0:3], metric='euclidean')\ncluster_assignment = np.argmin(distance_matrix, axis=1)\n```"}, {'reason': 'stop', 'result': "```python\nclass Dataset(object):\n    PAD = 0\n    SOS = 1\n    EOS = 2\n    UNK = 3\n    constants = ['PAD', 'SOS', 'EOS', 'UNK']\n    character_set = list('aábcdeéfghiíjklmnoóöőpqrstuúüűvwxyz-+._')\n\n    def __init__(self, fn, config, src_alphabet=None, tgt_alphabet=None):\n        self.config = config\n        self.create_tables(src_alphabet, tgt_alphabet)\n        self.load_and_preproc_dataset(fn)\n\n    def create_tables(self, src_alphabet, tgt_alphabet):\n        if src_alphabet is None:\n            self.src_vocab = Dataset.constants + Dataset.hu_alphabet\n        else:\n            self.src_vocab = Dataset.constants + alphabet\n        self.src_table = lookup_ops.index_table_from_tensor(tf.constant(self.src_vocab), default_value=Dataset.UNK)\n        if self.config.share_vocab:\n            self.tgt_vocab = self.src_vocab\n            self.tgt_table = self.src_table\n        else:\n            if tgt_alphabet is None:\n                self.tgt_vocab = Dataset.constants + Dataset.hu_alphabet\n            else:\n                self.tgt_vocab = Dataset.constants + alphabet\n            self.tgt_table = lookup_ops.index_table_from_tensor(tf.constant(self.tgt_vocab), default_value=Dataset.UNK)\n        self.src_vocab_size = len(self.src_vocab)\n        self.tgt_vocab_size = len(self.tgt_vocab)\n\n    def load_and_preproc_dataset(self, fn):\n        dataset = tf.contrib.data.TextLineDataset(fn)\n        dataset = dataset.repeat()\n        dataset = dataset.map(lambda s: tf.string_split([s], delimiter='\\t').values)\n        src = dataset.map(lambda s: s[0])\n        tgt = dataset.map(lambda s: s[1])\n        src = src.map(lambda s: tf.string_split([s], delimiter=' ').values)\n        src = src.map(lambda s: s[:self.config.src_maxlen])\n        tgt = tgt.map(lambda s: tf.string_split([s], delimiter=' ').values)\n        tgt = tgt.map(lambda s: s[:self.config.tgt_maxlen])\n        src = src.map(lambda words: self.src_table.lookup(words))\n        tgt = tgt.map(lambda words: self.tgt_table.lookup(words))\n        dataset = tf.contrib.data.Dataset.zip((src, tgt))\n        dataset = dataset.map(lambda src, tgt: (src, tf.concat(([Dataset.SOS], tgt), 0), tf.concat((tgt, [Dataset.EOS]), 0)))\n        dataset = dataset.map(lambda src, tgt_in, tgt_out: (src, tgt_in, tgt_out, tf.size(src), tf.size(tgt_in)))\n        batched = dataset.padded_batch(self.config.batch_size, padded_shapes=(tf.TensorShape([self.config.src_maxlen]), tf.TensorShape([self.config.tgt_maxlen + 2]), tf.TensorShape([None]), tf.TensorShape([]), tf.TensorShape([])))\n        self.batched_iter = batched.make_initializable_iterator()\n        s = self.batched_iter.get_next()\n        self.src_ids = s[0]\n        self.tgt_in_ids = s[1]\n        self.tgt_out_ids = s[2]\n        self.src_size = s[3]\n        self.tgt_size = s[4]\n\n    def run_initializers(self, session):\n        session.run(tf.tables_initializer())\n        session.run(self.batched_iter.initializer)\n```"}, {'reason': 'stop', 'result': "```python\nTEST_IMAGE_DIR = 'images'\nimage_files = glob(TEST_IMAGE_DIR + '/*')\nimage_files\n```"}, {'reason': 'stop', 'result': "```python\nN = Ngenres * Nclips * Nframes * 2\nsizeX = N * n / 2.0 ** 20\nvariable_size_Z = N * m / 2.0 ** 20\nsizeD = n * m / 2.0 ** 10\nsizeE = m * n / 2.0 ** 10\nprint('Size X: {:.1f} M --> {:.1f} MiB'.format(sizeX, sizeX * 4))\nprint('Size Z: {:.1f} M --> {:.1f} MiB'.format(variable_size_Z, variable_size_Z * 4))\nprint('Size D: {:.1f} k --> {:.1f} kiB'.format(sizeD, sizeD * 4))\nprint('Size E: {:.1f} k --> {:.1f} kiB'.format(sizeE, sizeE * 4))\n```"}, {'reason': 'stop', 'result': "```python\nif msig.sequence_type == 'many2many':\n    y_score_mean = y_score.sum(axis=1) / y_score.shape[1]\n    wave_data = np.zeros((msig.n_timestamps, msig.window_size))\n    for i in range(msig.window_size):\n        wave_data[i:i + msig.n_samples, i] = y_score[:, i]\n    y_score_unshifted_clipped = wave_data[msig.window_size - 1:]\n    y_score_unshifted_clipped_mean = y_score_unshifted_clipped.sum(axis=1) / y_score.shape[1]\nelse:\n    y_score_mean = y_score.sum(axis=1) / y_score.shape[1]\n    wave_data = np.zeros((msig.n_timestamps, msig.window_size))\n    for i in range(msig.window_size):\n        wave_data[i:i + msig.n_samples, i] = y_score[:, i]\n    y_score_unshifted_clipped = wave_data[msig.window_size - 1:]\n    y_score_unshifted_clipped_mean = y_score_unshifted_clipped.sum(axis=1) / y_score.shape[1]\n```"}, {'reason': 'stop', 'result': "```python\ncounty = df_county_data['County Name']\npoverty_rate_data = df_county_data['Poverty Rate']\nx_axis = np.arange(len(poverty_rate_data))\ntick_locations = [value for value in x_axis]\nplt.bar(x_axis, poverty_rate_data, color='r', align='center')\nplt.title('County Poverty Rates')\nplt.xlabel('Counties')\nplt.ylabel('Poverty Rates')\nplt.text(140, 30, 'Note:\\nPoverty Rates for all counties in NJ, NY, & PA.')\nplt.savefig('Images/County_Poverty_Rates.png', bbox_inches='tight')\nplt.show()\n```"}, {'reason': 'stop', 'result': "```python\nunique_hotels_names = most_checkins['Hotel Name'].unique()\nunique_checkins = most_checkins['Checkin Date'].unique()\nnew_hotel_checkin_combinations = [1, 2, 3, 4]\nimport itertools\nimport sys\ncombs = []\nfor x in unique_hotels_names:\n    for y in unique_checkins:\n        for z in new_hotel_checkin_combinations:\n            combs.append([x, y, z, sys.maxsize])\nnew_df = DataFrame.from_records(combs, columns=['Hotel Name', 'Checkin Date', 'Discount Code', 'Discount Price'])\nmost_checkins = most_checkins.append(new_df)\n```"}, {'reason': 'stop', 'result': '```python\na = 840\ndoubled_a = 2 * a\nc = 12\nd = c * doubled_a\nd\n```'}, {'reason': 'stop', 'result': "```python\nprobas_patches_msr = np.reshape(get_acc_net_msr(y_pred_te).flatten(), np.shape(data_test.gt_patches))\nprobas_patches_msr -= np.min(probas_patches_msr)\nprobas_patches_msr /= np.max(probas_patches_msr)\nprobas_patches_margin = np.reshape((1 - get_acc_net_max_margin(y_pred_te)).flatten(), np.shape(data_test.gt_patches))\nprobas_patches_margin -= np.min(probas_patches_margin)\nprobas_patches_margin /= np.max(probas_patches_margin)\nentropy_error_detection = np.reshape((1 - get_acc_net_entropy(y_pred_te)).flatten(), np.shape(data_test.gt_patches))\nentropy_error_detection -= np.min(entropy_error_detection)\nentropy_error_detection /= np.max(entropy_error_detection)\nprobas_patches_msr = np.reshape(get_acc_net_msr(y_pred_te).flatten(), np.shape(data_test.gt_patches))\nprobas_patches_msr -= np.min(probas_patches_msr)\nprobas_patches_msr /= np.max(probas_patches_msr)\nprobas_patches_margin = np.reshape((1 - get_acc_net_max_margin(y_pred_te)).flatten(), np.shape(data_test.gt_patches))\nprobas_patches_margin -= np.min(probas_patches_margin)\nprobas_patches_margin /= np.max(probas_patches_margin)\nentropy_error_detection = np.reshape((1 - get_acc_net_entropy(y_pred_te)).flatten(), np.shape(data_test.gt_patches))\nentropy_error_detection -= np.min(entropy_error_detection)\nentropy_error_detection /= np.max(entropy_error_detection)\nacc_im_msr = convert_patches_to_image(data_test.imgs, probas_patches_msr[..., np.newaxis], 64, 64)\nacc_im_margin = convert_patches_to_image(data_test.imgs, probas_patches_margin[..., np.newaxis], 64, 64)\nacc_im_entropy = convert_patches_to_image(data_test.imgs, entropy_error_detection[..., np.newaxis], 64, 64)\nfor img_idx in range(5):\n    plt.figure(figsize=(8, 8))\n    plt.imshow(acc_im_msr[img_idx], cmap='RdYlGn')\n    plt.axis('off')\n    plt.gca().xaxis.set_major_locator(plt.NullLocator())\n    plt.gca().yaxis.set_major_locator(plt.NullLocator())\n    plt.savefig('../Figures/Zurich/Im_cert/ED/net_msr_im_' + str(img_idx) + '.pdf', bbox_inches='tight', pad_inches=0)\n    plt.close()\n    plt.figure(figsize=(8, 8))\n    plt.imshow(acc_im_margin[img_idx], cmap='RdYlGn')\n    plt.axis('off')\n    plt.gca().xaxis.set_major_locator(plt.NullLocator())\n    plt.gca().yaxis.set_major_locator(plt.NullLocator())\n    plt.savefig('../Figures/Zurich/Im_cert/ED/net_margin_im_' + str(img_idx) + '.pdf', bbox_inches='tight', pad_inches=0)\n    plt.close()\n    plt.figure(figsize=(8, 8))\n    plt.imshow(acc_im_entropy[img_idx], cmap='RdYlGn')\n    plt.axis('off')\n    plt.gca().xaxis.set_major_locator(plt.NullLocator())\n    plt.gca().yaxis.set_major_locator(plt.NullLocator())\n    plt.savefig('../Figures/Zurich/Im_cert/ED/net_entropy_im_' + str(img_idx) + '.pdf', bbox_inches='tight', pad_inches=0)\n    plt.close()\n```"}, {'reason': 'stop', 'result': '```python\ndef friction(vi, vf, F0):\n    """\n    Returns the friction of the bottom plate against blocks moving at a specific velocity\n    \n    Arguments:  vi - initial velocity of the block\n                vf - final velocity of the block\n                F0 - the static friction force\n    \n    Returned: The force due to friction\n    \n    Examples:\n    \n    >>> friction (0, 1, 20)\n    -20.0\n    \n    >>> friction (1, 1, 20)\n    -10.0\n    """\n    if vi == 0:\n        sign_change = 1\n    else:\n        sign_change = vi / abs(vi)\n    force = -(F0 * sign_change / (1 + abs(vi / vf)))\n    return force\n```'}, {'reason': 'stop', 'result': '```python\nnumber_of_students = 840\nb = 2 * number_of_students\nc = 12\nd = c * b\nd\n```'}, {'reason': 'stop', 'result': '```python\ncolors = [\'b\', \'g\', \'r\', \'k\', \'c\', \'m\', \'y\']\nindex = 0\nfor segment in segments:\n    segment_data = data.loc[data[\'RiverSeg\'] == segment]\n    segment_data = segment_data[segment_data["lam\'"] > 0]\n    segment_data = segment_data.sort_values(\'Year\')\n    x = segment_data[\'Year\']\n    y = segment_data["N10\'"]\n    y.name = segment\n    plt.plot(x, y, colors[index])\n    plt.legend(loc=(1.05, 0.2))\n    index += 1\nplt.title("Hill N10\', " + river + \' River Segments\')\nplt.xlabel(\'Year\')\nplt.ylabel("N10\'")\nplt.xticks(np.arange(min(x), max(x) + 1, 1.0))\nplt.xticks(rotation=90)\nplt.savefig(output + \'\\\\\' + river + "_Hill_N10\'.png", bbox_inches=\'tight\', dpi=300, size=(2000, 2000))\nplt.show()\n```'}, {'reason': 'stop', 'result': "```python\ndef basic_stock_features(input_df, mnemonic, new_time_index, inplace=False):\n    stock = input_df.loc[mnemonic]\n    if not inplace:\n        stock = input_df.loc[mnemonic].copy()\n    stock = stock.reindex(new_time_index)\n    stock_features = ['MinPrice', 'MaxPrice', 'EndPrice', 'StartPrice']\n    for f in stock_features:\n        stock[f] = stock[f].fillna(method='ffill')\n    stock_features = ['TradedVolume', 'NumberOfTrades']\n    for f in stock_features:\n        stock[f] = stock[f].fillna(0.0)\n    stock['HourOfDay'] = stock.index.hour\n    stock['MinOfHour'] = stock.index.minute\n    stock['MinOfDay'] = stock.index.hour * 60 + stock.index.minute\n    stock['DayOfWeek'] = stock.index.dayofweek\n    stock['DayOfYear'] = stock.index.dayofyear\n    stock['MonthOfYear'] = stock.index.month\n    stock['WeekOfYear'] = stock.index.weekofyear\n    stock['Mnemonic'] = mnemonic\n    unwanted_features = ['ISIN', 'SecurityDesc', 'SecurityType', 'Currency', 'SecurityID', 'Date', 'Time', 'CalcTime']\n    return stock.drop(unwanted_features, axis=1)\n```"}, {'reason': 'stop', 'result': "```python\nmy_testword = 'CHOCOLATE'\nmodel, log_likelihood = train_a_word(my_testword, 3, features_ground)\nshow_model_stats(my_testword, model)\nprint('logL = {}'.format(log_likelihood))\n```"}, {'reason': 'stop', 'result': '```python\nZ1 = X.loc[:, X.dtypes == np.float64]\nZ2 = X.loc[:, X.dtypes == np.int64]\nnumeric_features = pd.concat([Z1, Z2], axis=1)\n```'}, {'reason': 'stop', 'result': "```python\nfrom sklearn.datasets import load_files\nfrom keras.utils import np_utils\nimport numpy as np\nfrom glob import glob\n\ndef load_dataset(path):\n    data = load_files(path)\n    dog_files = np.array(data['filenames'])\n    one_hot_encoded_labels = np_utils.to_categorical(np.array(data['target']), 133)\n    return (dog_files, one_hot_encoded_labels)\ntrain_files, train_targets = load_dataset('dogImages/train')\nvalid_files, valid_targets = load_dataset('dogImages/valid')\ntest_files, test_targets = load_dataset('dogImages/test')\ndog_names = [item[20:-1] for item in sorted(glob('dogImages/train/*/'))]\nprint('There are %d total dog categories.' % len(dog_names))\nprint('There are %s total dog images.\\n' % len(np.hstack([train_files, valid_files, test_files])))\nprint('There are %d training dog images.' % len(train_files))\nprint('There are %d validation dog images.' % len(valid_files))\nprint('There are %d test dog images.' % len(test_files))\n```"}, {'reason': 'stop', 'result': '```python\nnum_nodes = 64\ngraph = tf.Graph()\nwith graph.as_default():\n    ix = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n    im = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n    ib = tf.Variable(tf.zeros([1, num_nodes]))\n    fx = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n    fm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n    fb = tf.Variable(tf.zeros([1, num_nodes]))\n    cx = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n    cm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n    cb = tf.Variable(tf.zeros([1, num_nodes]))\n    ox = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n    om = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n    ob = tf.Variable(tf.zeros([1, num_nodes]))\n    saved_output = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False)\n    saved_state = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False)\n    w = tf.Variable(tf.truncated_normal([num_nodes, vocabulary_size], -0.1, 0.1))\n    b = tf.Variable(tf.zeros([vocabulary_size]))\n\n    def lstm_cell(i, o, state):\n        """Create a LSTM cell. See e.g.: http://arxiv.org/pdf/1402.1128v1.pdf\n    Note that in this formulation, we omit the various connections between the\n    previous state and the gates."""\n        input_gate = tf.sigmoid(tf.matmul(i, ix) + tf.matmul(o, im) + ib)\n        forget_gate = tf.sigmoid(tf.matmul(i, fx) + tf.matmul(o, fm) + fb)\n        update = tf.matmul(i, cx) + tf.matmul(o, cm) + cb\n        state = forget_gate * state + input_gate * tf.tanh(update)\n        output_gate = tf.sigmoid(tf.matmul(i, ox) + tf.matmul(o, om) + ob)\n        return (output_gate * tf.tanh(state), state)\n    train_data = list()\n    for _ in range(num_unrollings + 1):\n        train_data.append(tf.placeholder(tf.float32, shape=[batch_size, vocabulary_size]))\n    train_inputs = train_data[:num_unrollings]\n    train_labels = train_data[1:]\n    outputs = list()\n    output = saved_output\n    state = saved_state\n    for i in train_inputs:\n        output, state = lstm_cell(i, output, state)\n        outputs.append(output)\n    with tf.control_dependencies([saved_output.assign(output), saved_state.assign(state)]):\n        logits = tf.nn.xw_plus_b(tf.concat(outputs, 0), w, b)\n        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf.concat(train_labels, 0), logits=logits))\n    global_step = tf.Variable(0)\n    learning_rate = tf.train.exponential_decay(10.0, global_step, 5000, 0.1, staircase=True)\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n    gradients, v = zip(*optimizer.compute_gradients(loss))\n    gradients, _ = tf.clip_by_global_norm(gradients, 1.25)\n    optimizer = optimizer.apply_gradients(zip(gradients, v), global_step=global_step)\n    train_prediction = tf.nn.softmax(logits)\n    sample_input = tf.placeholder(tf.float32, shape=[1, vocabulary_size])\n    saved_sample_output = tf.Variable(tf.zeros([1, num_nodes]))\n    lstm_cell_state = tf.Variable(tf.zeros([1, num_nodes]))\n    reset_sample_state = tf.group(saved_sample_output.assign(tf.zeros([1, num_nodes])), lstm_cell_state.assign(tf.zeros([1, num_nodes])))\n    sample_output, sample_state = lstm_cell(sample_input, saved_sample_output, lstm_cell_state)\n    with tf.control_dependencies([saved_sample_output.assign(sample_output), lstm_cell_state.assign(sample_state)]):\n        sample_prediction = tf.nn.softmax(tf.nn.xw_plus_b(sample_output, w, b))\n```'}, {'reason': 'stop', 'result': "```python\nseed_input = 'http://www.google.com/search?q=fuzzing'\nmax_test_cases = 50\n```"}, {'reason': 'stop', 'result': '```python\nproject_description = None\npca_samples = None\npca_results = vs.pca_results(good_data, project_description)\n```'}, {'reason': 'stop', 'result': "```python\npattern_reversed = B12_a[:, -1::-1]\nHoM = hit_or_miss(X, pattern_reversed)\nplt.figure(figsize=[10, 10])\nplt.subplot(1, 2, 1)\nplt.imshow(X, interpolation='nearest')\nplt.subplot(1, 2, 2)\nplt.imshow(X, interpolation='nearest', alpha=0.8)\nplt.imshow(HoM, interpolation='nearest', alpha=0.5)\n```"}, {'reason': 'stop', 'result': "```python\nnodes = [ST, F, C, W, f_I, f_ST, f_F, f_C, f_W, I, B, f_B, S, f_S]\nfor n in nodes:\n    n.reset()\nC.pending.add(f_C)\nW.pending.add(f_W)\nf_I.pending.add(I)\nf_S.pending.add(S)\nST.pending.add(f_ST)\nF.pending.add(f_F)\nmax_sum(nodes)\nI_ulm = I.unnormalized_log_marginal()\nS_ulm = S.unnormalized_log_marginal()\nST_ulm = ST.unnormalized_log_marginal()\nF_ulm = F.unnormalized_log_marginal()\nbelief_B = B.unnormalized_log_marginal()\nC_ulm = C.unnormalized_log_marginal()\nW_ulm = W.unnormalized_log_marginal()\nprint('I', I_ulm)\nprint('S', S_ulm)\nprint('ST', ST_ulm)\nprint('F', F_ulm)\nprint('B', belief_B)\nprint('C', C_ulm)\nprint('W', W_ulm)\n```"}, {'reason': 'stop', 'result': "```python\nimg = np.zeros((800, 800, 3))\ny, x = np.indices(img.shape[:2])\ncx, center_y_coordinate = (300, 300)\ncircle1 = (x - cx) ** 2 + (y - center_y_coordinate) ** 2 < 200 ** 2\ncx, center_y_coordinate = (500, 500)\ncircle2 = (x - cx) ** 2 + (y - center_y_coordinate) ** 2 < 200 ** 2\ncx, center_y_coordinate = (300, 500)\ncircle3 = (x - cx) ** 2 + (y - center_y_coordinate) ** 2 < 200 ** 2\ncx, center_y_coordinate = (500, 300)\ncircle4 = (x - cx) ** 2 + (y - center_y_coordinate) ** 2 < 200 ** 2\nimg[circle1] += (0.2, 0, 0)\nimg[circle2] += (0.2, 0, 0)\nimg[circle3] += (0.2, 0, 0)\nimg[circle4] += (0.2, 0, 0)\nimg[circle1 & circle2 & circle3 & circle4] = (0, 0, 1)\nplt.imshow(img, interpolation='bilinear')\n```"}, {'reason': 'stop', 'result': "```python\nfeature_histograms = []\nresult_train = []\ntot = 0\nfor string in ['share', 'comment', 'zan', 'content_len', '链接', '//@', '@', '#', '【', '《', '\\\\[']:\n    temp = []\n    for i in test[string + '_histogram']:\n        if isinstance(i, int):\n            temp.append(np.zeros(shape=8))\n            tot += 1\n        else:\n            temp.append(i[0])\n    feature_histograms.append(np.asarray(temp))\n    temp = []\n    for i in train[string + '_histogram']:\n        temp.append(i[0])\n    result_train.append(np.asarray(temp))\n    train.drop(string + '_histogram', axis=1, inplace=True)\n    test.drop(string + '_histogram', axis=1, inplace=True)\ntrain.drop(['pid', 'uid'], inplace=True, axis=1)\ntest.drop(['pid', 'uid'], inplace=True, axis=1)\ntrain_y = train[['share', 'comment', 'zan']].values\ntrain.drop(['share', 'comme·nt', 'zan'], axis=1, inplace=True)\ntrain_x = train.values\ntest_x = test.values\nfor i in result_train:\n    train_x = np.c_[train_x, i]\nfor i in feature_histograms:\n    test_x = np.c_[test_x, i]\nnp.save('processed_data/train3_np', train_x)\nnp.save('processed_data/test3_np', test_x)\nnp.save('processed_data/target3_np', train_y)\n```"}, {'reason': 'stop', 'result': '```python\nnum_nodes = 64\ngraph = tf.Graph()\nwith graph.as_default():\n    ix = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n    im = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n    ib = tf.Variable(tf.zeros([1, num_nodes]))\n    fx = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n    fm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n    fb = tf.Variable(tf.zeros([1, num_nodes]))\n    cx = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n    cm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n    cb = tf.Variable(tf.zeros([1, num_nodes]))\n    ox = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n    om = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n    ob = tf.Variable(tf.zeros([1, num_nodes]))\n    saved_output = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False)\n    saved_state = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False)\n    w = tf.Variable(tf.truncated_normal([num_nodes, vocabulary_size], -0.1, 0.1))\n    b = tf.Variable(tf.zeros([vocabulary_size]))\n\n    def lstm_cell(i, o, state):\n        """Create a LSTM cell. See e.g.: http://arxiv.org/pdf/1402.1128v1.pdf\n    Note that in this formulation, we omit the various connections between the\n    previous state and the gates."""\n        input_gate = tf.sigmoid(tf.matmul(i, ix) + tf.matmul(o, im) + ib)\n        forget_gate = tf.sigmoid(tf.matmul(i, fx) + tf.matmul(o, fm) + fb)\n        update = tf.matmul(i, cx) + tf.matmul(o, cm) + cb\n        state = forget_gate * state + input_gate * tf.tanh(update)\n        output_gate = tf.sigmoid(tf.matmul(i, ox) + tf.matmul(o, om) + ob)\n        return (output_gate * tf.tanh(state), state)\n    train_data = list()\n    for _ in range(num_unrollings + 1):\n        train_data.append(tf.placeholder(tf.float32, shape=[batch_size, vocabulary_size]))\n    train_inputs = train_data[:num_unrollings]\n    train_labels = train_data[1:]\n    outputs = list()\n    output = saved_output\n    state = saved_state\n    for i in train_inputs:\n        output, state = lstm_cell(i, output, state)\n        outputs.append(output)\n    with tf.control_dependencies([saved_output.assign(output), saved_state.assign(state)]):\n        logits = tf.nn.xw_plus_b(tf.concat(outputs, 0), w, b)\n        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf.concat(train_labels, 0), logits=logits))\n    global_step = tf.Variable(0)\n    learning_rate = tf.train.exponential_decay(10.0, global_step, 5000, 0.1, staircase=True)\n    gradient_descent_optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n    gradients, v = zip(*gradient_descent_optimizer.compute_gradients(loss))\n    gradients, _ = tf.clip_by_global_norm(gradients, 1.25)\n    gradient_descent_optimizer = gradient_descent_optimizer.apply_gradients(zip(gradients, v), global_step=global_step)\n    train_prediction = tf.nn.softmax(logits)\n    sample_input = tf.placeholder(tf.float32, shape=[1, vocabulary_size])\n    saved_sample_output = tf.Variable(tf.zeros([1, num_nodes]))\n    saved_sample_state = tf.Variable(tf.zeros([1, num_nodes]))\n    reset_sample_state = tf.group(saved_sample_output.assign(tf.zeros([1, num_nodes])), saved_sample_state.assign(tf.zeros([1, num_nodes])))\n    sample_output, sample_state = lstm_cell(sample_input, saved_sample_output, saved_sample_state)\n    with tf.control_dependencies([saved_sample_output.assign(sample_output), saved_sample_state.assign(sample_state)]):\n        sample_prediction = tf.nn.softmax(tf.nn.xw_plus_b(sample_output, w, b))\n```'}, {'reason': 'stop', 'result': "```python\nncomponents = 2\npca = decomp.PCA(n_components=ncomponents)\nraw_pca = pca.fit(np.array(x_train.iloc[:, first_egemaps_feature:]).astype(np.float))\nx_pca = raw_pca.transform(x_train.iloc[:, first_egemaps_feature:])\ngroups = x_train['pos']\nshort_pos = {'nouns': 'nn', 'verbs': 'vrb', 'other': 'oth', 'function_words': 'fct', 'adjectives': 'adj'}\ngroup_values = [short_pos[i] for i in groups.unique()]\nposIDs = groups.factorize()[0]\nlabels = np.array(x_train['word'])\nfig = plt.figure()\nax = fig.add_subplot(111)\nax.set_xlabel('PC 1')\nax.set_ylabel('PC 2')\ncolormap = plt.get_cmap('gnuplot', len(group_values))\npc1 = x_pca[:, 0]\npc2 = x_pca[:, 1]\np = ax.scatter(pc1, pc2, c=posIDs, cmap=colormap, s=10)\ncolorbar = plt.colorbar(p)\nloc = np.arange(0, max(posIDs), max(posIDs) / float(len(group_values)))\ncolorbar.set_ticks(loc)\ncolorbar.set_ticklabels(group_values)\nfor label, x, y in zip(labels, pc1, pc2):\n    if y == np.amax(y) or x == np.amax(x):\n        plt.annotate(label, fontsize=2, xy=(x, y), xytext=(0, 1), textcoords='offset points', ha='right', va='bottom')\nif pos_filter == None:\n    axins = zoomed_inset_axes(ax, 2.5, loc=2)\n    x1, x2, y1, y2 = (-3.1, 2.5, 6.3, 9.8)\n    axins.set_xlim(x1, x2)\n    axins.set_ylim(y1, y2)\n    axins.scatter(pc1, pc2, c=posIDs, cmap=colormap)\n    plt.yticks(visible=False)\n    plt.xticks(visible=False)\n    mark_inset(ax, axins, loc1=2, loc2=4, fc='none', ec='0.5')\n    for label, x, y in zip(labels, pc1, pc2):\n        if y == np.amax(y) or x == np.amax(x):\n            plt.annotate(label, fontsize=8, xy=(x, y), xytext=(0, 1), textcoords='offset points', ha='right', va='bottom')\n    axins2 = zoomed_inset_axes(ax, 2.5, loc=4)\n    x1, x2, y1, y2 = (-4, 0.5, -8.5, -6.5)\n    axins2.set_xlim(x1, x2)\n    axins2.set_ylim(y1, y2)\n    axins2.scatter(pc1, pc2, c=posIDs, cmap=colormap)\n    plt.yticks(visible=False)\n    plt.xticks(visible=False)\n    mark_inset(ax, axins2, loc1=2, loc2=4, fc='none', ec='0.5')\n    for label, x, y in zip(labels, pc1, pc2):\n        if y == np.amax(y) or x == np.amax(x):\n            plt.annotate(label, fontsize=8, xy=(x, y), xytext=(0, 1), textcoords='offset points', ha='right', va='bottom')\nfilename = corpus + '_full_zoom.pdf'\nif pos_filter != None and len(pos_filter) == 1:\n    filename = corpus + '_pca_' + pos_filter[0][1] + '_' + pos_filter[0][2] + '.pdf'\nplt.savefig(filename, bbox_inches='tight')\n```"}, {'reason': 'stop', 'result': "```python\nnum_flower_classes = len(flower_classes)\nwith tf.name_scope('new_output_layer'):\n    flower_logits = tf.layers.dense(prelogits, num_flower_classes, name='flower_logits')\n    Y_proba = tf.nn.softmax(flower_logits, name='Y_proba')\n```"}, {'reason': 'stop', 'result': "```python\nfrom tensorflow.contrib.layers import flatten\n\ndef LeNet(x):\n    mu = 0\n    sigma = 0.1\n    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 3, 6), mean=mu, stddev=sigma))\n    conv1_b = tf.Variable(tf.zeros(6))\n    conv1 = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n    conv1 = tf.nn.relu(conv1)\n    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean=mu, stddev=sigma))\n    conv2_b = tf.Variable(tf.zeros(16))\n    conv2 = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n    conv2 = tf.nn.relu(conv2)\n    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n    fc0 = flatten(conv2)\n    fc1_W = tf.Variable(tf.truncated_normal(shape=(400, 120), mean=mu, stddev=sigma))\n    fc1_b = tf.Variable(tf.zeros(120))\n    fc1 = tf.matmul(fc0, fc1_W) + fc1_b\n    fc1 = tf.nn.relu(fc1)\n    fc2_W = tf.Variable(tf.truncated_normal(shape=(120, 84), mean=mu, stddev=sigma))\n    fc2_b = tf.Variable(tf.zeros(84))\n    fc2 = tf.matmul(fc1, fc2_W) + fc2_b\n    fc2 = tf.nn.relu(fc2)\n    fc3_W = tf.Variable(tf.truncated_normal(shape=(84, 43), mean=mu, stddev=sigma))\n    fc3_b = tf.Variable(tf.zeros(43))\n    logits = tf.matmul(fc2, fc3_W) + fc3_b\n    return logits\n\ndef model_arc(x):\n    mu = 0\n    sigma = 0.1\n    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 3, 9), mean=mu, stddev=sigma))\n    conv1_b = tf.Variable(tf.zeros(9))\n    conv1 = tf.nn.bias_add(tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID'), conv1_b)\n    conv1 = tf.nn.relu(conv1)\n    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n    conv2_W = tf.Variable(tf.truncated_normal(shape=(3, 3, 9, 27), mean=mu, stddev=sigma))\n    conv2_b = tf.Variable(tf.zeros(27))\n    conv2 = tf.nn.bias_add(tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID'), conv2_b)\n    conv2 = tf.nn.relu(conv2)\n    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n    conv3_W = tf.Variable(tf.truncated_normal(shape=(1, 1, 27, 81), mean=mu, stddev=sigma))\n    conv3_b = tf.Variable(tf.zeros(81))\n    conv3 = tf.nn.bias_add(tf.nn.conv2d(conv2, conv3_W, strides=[1, 1, 1, 1], padding='VALID'), conv3_b)\n    conv3 = tf.nn.relu(conv3)\n    conv3 = tf.nn.dropout(conv3, keep_prob=0.5)\n    conv3 = tf.nn.relu(conv3)\n    fc0 = flatten(conv3)\n    fc1_W = tf.Variable(tf.truncated_normal(shape=(2916, 972), mean=mu, stddev=sigma))\n    fc1_b = tf.Variable(tf.zeros(972))\n    fc1 = tf.nn.xw_plus_b(fc0, fc1_W, fc1_b)\n    fc1 = tf.nn.relu(fc1)\n    fc2_W = tf.Variable(tf.truncated_normal(shape=(972, 324), mean=mu, stddev=sigma))\n    fc2_b = tf.Variable(tf.zeros(324))\n    fc2 = tf.nn.xw_plus_b(fc1, fc2_W, fc2_b)\n    fc2 = tf.nn.relu(fc2)\n    fc3_W = tf.Variable(tf.truncated_normal(shape=(324, 108), mean=mu, stddev=sigma))\n    fc3_b = tf.Variable(tf.zeros(108))\n    final_layer_output = tf.nn.xw_plus_b(fc2, fc3_W, fc3_b)\n    final_layer_output = tf.nn.relu(final_layer_output)\n    fc4_W = tf.Variable(tf.truncated_normal(shape=(108, 43), mean=mu, stddev=sigma))\n    fc4_b = tf.Variable(tf.zeros(43))\n    logits = tf.nn.xw_plus_b(final_layer_output, fc4_W, fc4_b)\n    return logits\n```"}, {'reason': 'stop', 'result': '```python\ninitial_value = 56\ndegree = 7\nsplit_ratio = 0.5\nridge_regression_demo(x, y, degree, split_ratio, initial_value)\n```'}, {'reason': 'stop', 'result': '```python\ncube_orientation = P.mycarta.CubeYF_7\ncube_orientation.show_as_blocks()\n```'}, {'reason': 'stop', 'result': "```python\nnovelty_detection_scores = -probas_gmm\nprecision_gmm, recall_gmm, _ = metrics.precision_recall_curve(y_true, novelty_detection_scores)\npr_auc_gmm = metrics.auc(recall_gmm, precision_gmm)\nfpr_gmm, tpr_gmm, _ = metrics.roc_curve(y_true, novelty_detection_scores)\nauroc_gmm = metrics.roc_auc_score(y_true, novelty_detection_scores)\nprint('AUROC: %.2f, PR AUC: %.2f' % (auroc_gmm, pr_auc_gmm))\n```"}, {'reason': 'stop', 'result': '```python\nif visualize_dataset == True and round_values == True:\n    heatmap_filepath = exportpath + timestamp + \'heatmap.png\'\n    correlation_dataframe = data_no_nulls.corr()\n    mask = numpy.zeros_like(correlation_dataframe)\n    mask[numpy.triu_indices_from(mask)] = True\n    seaborn.heatmap(data=correlation_dataframe, cmap=[\'#b2182b\', \'#ef8a62\', \'#fddbc7\', \'#f7f7f7\', \'#d1e5f0\', \'#67a9cf\', \'#2166ac\'], center=0, square=True, linewidth=1, mask=mask, annot=True).get_figure().savefig(heatmap_filepath)\n    print("Heatmap saved to \'{}\'".format(heatmap_filepath))\nelse:\n    print(\'No heatmap was produced. Dataset contains no numeric features or visualize_dataset variable was set to False.\')\n```'}, {'reason': 'stop', 'result': "```python\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, income_labels = train_test_split(features_final, income, test_size=0.2, random_state=0)\nprint('Training set has {} samples.'.format(X_train.shape[0]))\nprint('Testing set has {} samples.'.format(X_test.shape[0]))\n```"}, {'reason': 'stop', 'result': "```python\nbatch_size = 128\nembedding_size = 128\nskip_window = 1\nnum_skips = 2\nvalid_size = 16\nvalid_window = 100\nvalid_examples = np.array(random.sample(range(valid_window), valid_size))\nnum_sampled = 64\ngraph_def = tf.Graph()\nwith graph_def.as_default(), tf.device('/cpu:0'):\n    train_dataset = tf.placeholder(tf.int32, shape=[batch_size])\n    train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n    valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n    embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n    softmax_weights = tf.Variable(tf.truncated_normal([vocabulary_size, embedding_size], stddev=1.0 / math.sqrt(embedding_size)))\n    softmax_biases = tf.Variable(tf.zeros([vocabulary_size]))\n    embed = tf.nn.embedding_lookup(embeddings, train_dataset)\n    loss = tf.reduce_mean(tf.nn.sampled_softmax_loss(weights=softmax_weights, biases=softmax_biases, inputs=embed, labels=train_labels, num_sampled=num_sampled, num_classes=vocabulary_size))\n    optimizer = tf.train.AdagradOptimizer(1.0).minimize(loss)\n    norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n    normalized_embeddings = embeddings / norm\n    valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings, valid_dataset)\n    similarity = tf.matmul(valid_embeddings, tf.transpose(normalized_embeddings))\n```"}, {'reason': 'stop', 'result': "```python\nrevenue_lineplot = sns.lineplot(df.index.year, df['Revenue'], color='#2ecc71', label='Revenue')\n```"}, {'reason': 'stop', 'result': "```python\nfrom matplotlib.ticker import MultipleLocator\nfilters = ['LSST_g']\nalpha = 1.0\nxminorticks = 10\npcc.utils.setup_plot_defaults()\nfig = plt.figure(figsize=[8, 4])\nfig.subplots_adjust(left=0.1, bottom=0.13, top=0.93, right=0.91, hspace=0, wspace=0)\nxaxis_label_string = '$\\\\textnormal{Time, MJD (days)}$'\nyaxis_label_string = '$\\\\textnormal{Flux, erg s}^{-1}\\\\textnormal{\\\\AA}^{-1}\\\\textnormal{cm}^{-2}$'\nax1 = fig.add_subplot(111)\naxes_list = [ax1]\nfor filter_key in filters:\n    plot_label_string = '$\\\\rm{' + sn.phot.data_filters['BessellV'].filter_name.replace('_', '\\\\_') + '}$'\n    plot_label_string_fake = '$\\\\rm{' + sn_fake.phot.data_filters[filter_key].filter_name.replace('_', '\\\\_') + ', simulated}$'\n    ax1.errorbar(sn.phot.data['BessellV']['MJD'], sn.phot.data['BessellV']['flux'], yerr=sn.phot.data['BessellV']['flux_err'], capsize=0, fmt='x', color=sn.phot.data_filters['BessellV']._plot_colour, label=plot_label_string, ecolor=pcc.hex['batman'], mec=pcc.hex['batman'], alpha=alpha)\n    ax1.fill_between(sn.lcfit.data['BessellV']['MJD'], sn.lcfit.data['BessellV']['flux_upper'], sn.lcfit.data['BessellV']['flux_lower'], color=pcc.hex['batman'], alpha=0.8, zorder=0)\n    ax1.errorbar(sn_fake.phot.data[filter_key]['MJD'], sn_fake.phot.data[filter_key]['flux'], yerr=sn_fake.phot.data[filter_key]['flux_err'], capsize=0, fmt='o', color=pcc.hex['LSST_g'], label=plot_label_string_fake, ecolor=pcc.hex['batman'], mec=pcc.hex['batman'], alpha=alpha)\nxminorLocator = MultipleLocator(xminorticks)\nax1.spines['top'].set_visible(True)\nax1.xaxis.set_minor_locator(xminorLocator)\nlegend_ax = ax1.legend(loc='upper right', scatterpoints=1, markerfirst=False, numpoints=1, frameon=False, bbox_to_anchor=(1.0, 1.0), fontsize=12.0)\nax1.set_ylabel(yaxis_label_string)\nax1.set_xlabel(xaxis_label_string)\nprint(ax1.get_xlim())\noutpath = '/Users/berto/projects/LSST/cadence/SN2007uy_consistency_check_BessellV_LSSTg'\n```"}, {'reason': 'stop', 'result': "```python\ndef LeNet6(x, n_classes):\n    mu = 0\n    sigma = 0.1\n    conv1_filter_weights = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6), mean=mu, stddev=sigma))\n    conv1_b = tf.Variable(tf.zeros(6))\n    conv1 = tf.nn.conv2d(x, conv1_filter_weights, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n    conv1 = tf.nn.relu(conv1)\n    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean=mu, stddev=sigma))\n    conv2_b = tf.Variable(tf.zeros(16))\n    conv2 = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n    conv2 = tf.nn.relu(conv2)\n    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n    fc0 = flatten(conv2)\n    fc1_W = tf.Variable(tf.truncated_normal(shape=(400, 252), mean=mu, stddev=sigma))\n    fc1_b = tf.Variable(tf.zeros(252))\n    fc1 = tf.matmul(fc0, fc1_W) + fc1_b\n    fc1 = tf.nn.relu(fc1)\n    fc1 = tf.nn.dropout(fc1, keep_prob)\n    fc2_W = tf.Variable(tf.truncated_normal(shape=(252, 168), mean=mu, stddev=sigma))\n    fc2_b = tf.Variable(tf.zeros(168))\n    fc2 = tf.matmul(fc1, fc2_W) + fc2_b\n    fc2 = tf.nn.relu(fc2)\n    fc2 = tf.nn.dropout(fc2, keep_prob)\n    fc3_W = tf.Variable(tf.truncated_normal(shape=(168, 84), mean=mu, stddev=sigma))\n    fc3_b = tf.Variable(tf.zeros(84))\n    fc3 = tf.matmul(fc2, fc3_W) + fc3_b\n    fc3 = tf.nn.relu(fc3)\n    fc3 = tf.nn.dropout(fc3, keep_prob)\n    fc4_W = tf.Variable(tf.truncated_normal(shape=(84, n_classes), mean=mu, stddev=sigma))\n    fc4_b = tf.Variable(tf.zeros(n_classes))\n    logits = tf.matmul(fc3, fc4_W) + fc4_b\n    return logits\n```"}, {'reason': 'stop', 'result': '```python\nfrom asl_test_model_selectors import TestSelectors\ntest_selectors = unittest.TestLoader().loadTestsFromModule(TestSelectors())\nunittest.TextTestRunner().run(test_selectors)\n```'}, {'reason': 'stop', 'result': "```python\ncov = X.T @ X / (X.shape[0] - 1)\nval, vec = np.linalg.eigh(cov)\nidx = np.argsort(val)[::-1]\nval = val[idx]\nvec = vec[:, idx]\nproject_X = X @ vec\nproject_V = vec.T @ vec\ninversed_vec = np.linalg.inv(vec)\ninversed_vec = inversed_vec - inversed_vec.mean(1)\nrevert_X = project_X @ inversed_vec\nrevertedV = project_V @ inversed_vec.T\n\ndef plot():\n    plt.figure(figsize=(15, 5))\n    plt.subplot(131)\n    plt.scatter(X[y == 0, 0], X[y == 0, 1], color='red', alpha=0.5)\n    plt.scatter(X[y == 1, 0], X[y == 1, 1], color='blue', alpha=0.5)\n    first_principal_component = plt.arrow(0, 0, *vec[:, 0] * val[0], head_width=0.05, head_length=0.05, color='Green', label='First PC')\n    pca12 = plt.arrow(0, 0, *vec[:, 1] * val[1], head_width=0.05, head_length=0.05, color='magenta', label='Second PC')\n    plt.grid(True)\n    plt.subplot(132)\n    plt.scatter(project_X[y == 0, 0], project_X[y == 0, 1], color='red', alpha=0.5)\n    plt.scatter(project_X[y == 1, 0], project_X[y == 1, 1], color='blue', alpha=0.5)\n    pca21 = plt.arrow(0, 0, *project_V[:, 0] * val_reduced[0], head_width=0.05, head_length=0.05, color='Green', label='First PC')\n    pca22 = plt.arrow(0, 0, *project_V[:, 1] * val_reduced[1], head_width=0.05, head_length=0.05, color='magenta', label='Second PC')\n    plt.grid(True)\n    plt.subplot(133)\n    plt.scatter(revert_X[y == 0, 0], revert_X[y == 0, 1], color='red', alpha=0.5)\n    plt.scatter(revert_X[y == 1, 0], revert_X[y == 1, 1], color='blue', alpha=0.5)\n    pca21 = plt.arrow(0, 0, *revertedV[:, 0] * val[0], head_width=0.05, head_length=0.05, color='Green', label='First PC')\n    pca22 = plt.arrow(0, 0, *revertedV[:, 1] * val[1], head_width=0.05, head_length=0.05, color='magenta', label='Second PC')\n    plt.grid(True)\n    plt.show()\nplot()\n```"}, {'reason': 'stop', 'result': "```python\nprint(input_shape, 2 ** n_hidden)\nloss = msig.classification_type + '_crossentropy'\nclassification_activation = classifier_activation[msig.classification_type]\nout_neurons = 1 if msig.classification_type == 'binary' else n_classes\nconv1d_kwargs = dict(kernel_size=kernel_size, padding='causal', activation='relu')\ncompile_kwargs = dict(loss=loss, optimizer='adam', metrics=['accuracy'])\nmodel = Sequential()\nmodel.add(Conv1D(n_neurons, dilation_rate=1, input_shape=input_shape, **conv1d_kwargs))\nfor d in range(1, n_hidden):\n    model.add(Conv1D(n_neurons, dilation_rate=2 ** d, **conv1d_kwargs))\nmodel.add(Dense(out_neurons, activation=classification_activation))\nmodel.compile(**compile_kwargs)\nmodel.summary()\n```"}, {'reason': 'stop', 'result': "```python\npredictions = list()\nfor i in range(len(test_scaled)):\n    test_data, y = (test_scaled[i, 0:-1], test_scaled[i, -1])\n    yhat = forecast_lstm(lstm_model, 1, test_data)\n    yhat = invert_scale(scaler, test_data, yhat)\n    yhat = inverse_difference(raw_values, yhat, len(test_scaled) + 1 - i)\n    predictions.append(yhat)\n    expected = raw_values[len(train) + i + 1]\n    print('Month=%d, Predicted=%f, Expected=%f' % (i + 1, yhat, expected))\nrmse = sqrt(mean_squared_error(raw_values[-12:], predictions))\nprint('Test RMSE: %.3f' % rmse)\npyplot.plot(raw_values[-12:])\npyplot.plot(predictions)\npyplot.show()\n```"}, {'reason': 'stop', 'result': '```python\nimage_data_array = np.array(lista1)\nstats.describe(image_data_array)\n```'}, {'reason': 'stop', 'result': "```python\nbatch_size = 16\npatch_size = 5\ndepth = 16\nnum_hidden = 64\ngraph = tf.Graph()\nwith graph.as_default():\n    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n    tf_valid_dataset = tf.constant(valid_dataset)\n    tf_test_dataset = tf.constant(test_dataset)\n    layer1_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, num_channels, depth], stddev=0.1))\n    layer1_biases = tf.Variable(tf.zeros([depth]))\n    layer2_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth, depth], stddev=0.1))\n    layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n    fully_connected_weights = tf.Variable(tf.truncated_normal([image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n    layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n    layer4_weights = tf.Variable(tf.truncated_normal([num_hidden, num_labels], stddev=0.1))\n    layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n\n    def model(data):\n        conv = tf.nn.conv2d(data, layer1_weights, [1, 2, 2, 1], padding='SAME')\n        hidden = tf.nn.relu(conv + layer1_biases)\n        conv = tf.nn.conv2d(hidden, layer2_weights, [1, 2, 2, 1], padding='SAME')\n        hidden = tf.nn.relu(conv + layer2_biases)\n        shape = hidden.get_shape().as_list()\n        reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n        hidden = tf.nn.relu(tf.matmul(reshape, fully_connected_weights) + layer3_biases)\n        return tf.matmul(hidden, layer4_weights) + layer4_biases\n    logits = model(tf_train_dataset)\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n    optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n    train_prediction = tf.nn.softmax(logits)\n    valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n    test_prediction = tf.nn.softmax(model(tf_test_dataset))\n```"}, {'reason': 'stop', 'result': "```python\ncounty = df_county_data['County Name']\nhouse_size = df_county_data['Speak a language other than English']\ncounty_language_index = np.arange(len(house_size))\ntick_locations = [value for value in county_language_index]\nplt.bar(county_language_index, house_size, color='r', align='center')\nplt.title('County ESL')\nplt.xlabel('Counties')\nplt.ylabel('Speak a language other than English')\nplt.text(140, 40, 'Note:\\nSpoken languages beside English for all counties in NJ, NY, & PA.')\nplt.savefig('Images/County_Speak a language other than English.png', bbox_inches='tight')\nplt.show()\n```"}, {'reason': 'stop', 'result': "```python\nDEBUG = False\nJPEG_EXTENSIONS = ('.jpeg', '.JPEG', '.jpg', '.JPG')\nimage_dir = '../data/images'\ntest_images_dir = '../data/test_images'\nstored_images_resized = '../data/images_resized'\nstored_bottlenecks = '../data/bottlenecks'\ntmp_dir = '/tmp'\nbottleneck_dir = os.path.join(tmp_dir, 'bottlenecks')\nimages_resized_dir = os.path.join(tmp_dir, 'images_resized')\nsummaries_dir = os.path.join(tmp_dir, 'retrain_logs')\nmodel_dir = os.path.join(tmp_dir, 'inception')\nmodel_url = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'\noutput_graph_orig = 'output_graph_orig.pb'\noutput_graph = 'output_graph.pb'\noutput_labels = 'output_labels.txt'\narchitecture = 'inception_v3'\nfinal_tensor_name = 'final_result'\nhow_many_training_steps = 500\nlearning_rate = 0.01\ntesting_percentage = 10\nvalidation_percentage = 10\neval_step_interval = 10\ntrain_batch_size = 100\ntest_batch_size = -1\nvalidation_batch_size = 100\nprint_misclassified_test_images = False\nflip_left_right = False\nrandom_crop = 0\nrandom_scale = 0\nrandom_brightness = 0\nforce_inception_download = False\nFLAGS = type('FlagsObject', (object,), {'architecture': architecture, 'model_dir': model_dir, 'intermediate_store_frequency': 0, 'summaries_dir': summaries_dir, 'learning_rate': learning_rate, 'image_dir': images_resized_dir, 'testing_percentage': testing_percentage, 'validation_percentage': validation_percentage, 'random_scale': random_scale, 'random_crop': random_crop, 'flip_left_right': flip_left_right, 'random_brightness': random_brightness, 'bottleneck_dir': bottleneck_dir, 'final_tensor_name': final_tensor_name, 'how_many_training_steps': how_many_training_steps, 'train_batch_size': train_batch_size, 'test_batch_size': test_batch_size, 'eval_step_interval': eval_step_interval, 'validation_batch_size': validation_batch_size, 'print_misclassified_test_images': print_misclassified_test_images, 'output_graph': output_graph, 'output_labels': output_labels})\nretrain.FLAGS = FLAGS\n```"}, {'reason': 'stop', 'result': '```python\ncov_2012 = 0.100807801953\nadpc_2012 = 0.0111652211547\n[incsol, scrsol] = fsolve(lambda x: [test_diag_fun(x)[0] - cov_2012, test_diag_fun(x)[1] - adpc_2012], [0.09, 0.25])\nU_2012 = U_fun(incsol * p_asymp, sc + scrsol * p_true_pos, incsol * (1 - p_asymp), scrsol * p_true_pos + att_symp * p_true_pos)\nA_2012 = A_fun(incsol * p_asymp, sc + scrsol * p_true_pos, incsol * (1 - p_asymp), scrsol * p_true_pos + att_symp * p_true_pos)\nS_2012 = S_fun(incsol * p_asymp, sc + scrsol * p_true_pos, incsol * (1 - p_asymp), scrsol * p_true_pos + att_symp * p_true_pos)\ncov_2013 = 0.173269822929\nadpc_2013 = 0.0216211803756\n[incsol, scrsol] = fsolve(lambda x: [test_diag_fun(x)[0] - cov_2013, test_diag_fun(x)[1] - adpc_2013], [0.09, 0.25])\ninc = incsol\nscr = scrsol\nparms = [incsol * p_asymp, sc + scrsol * p_true_pos, incsol * (1 - p_asymp), scrsol * p_true_pos + att_symp * p_true_pos]\nchlamydia_simulation_results = odeint(dydt, [U_2012, A_2012, S_2012], linspace(0, 10, 1000), args=(parms,))\n```'}, {'reason': 'stop', 'result': "```python\nimport sys\nimport tarfile\nfrom six.moves import urllib\nTF_MODELS_URL = 'http://download.tensorflow.org/models'\nINCEPTION_V3_URL = TF_MODELS_URL + '/inception_v3_2016_08_28.tar.gz'\nINCEPTION_PATH = os.path.join('datasets', 'inception')\nINCEPTION_V3_CHECKPOINT_PATH = os.path.join(INCEPTION_PATH, 'inception_v3.ckpt')\n\ndef download_progress(count, block_size, total_size):\n    percent = count * block_size * 100 // total_size\n    sys.stdout.write('\\rDownloading: {}%'.format(percent))\n    sys.stdout.flush()\n\ndef fetch_pretrained_inception_v3(url=INCEPTION_V3_URL, path=INCEPTION_PATH):\n    if os.path.exists(INCEPTION_V3_CHECKPOINT_PATH):\n        return\n    os.makedirs(path, exist_ok=True)\n    inception_v3_tar_path = os.path.join(path, 'inception_v3.tgz')\n    urllib.request.urlretrieve(url, inception_v3_tar_path, reporthook=download_progress)\n    inception_tgz = tarfile.open(inception_v3_tar_path)\n    inception_tgz.extractall(path=path)\n    inception_tgz.close()\n    os.remove(inception_v3_tar_path)\n```"}, {'reason': 'stop', 'result': "```python\npollution_data = pd.melt(stats.reset_index(), id_vars='time', var_name='LSOA').dropna()\n```"}, {'reason': 'stop', 'result': "```python\nimport random\nrandom.seed(8675309)\nhuman_images = np.array(glob('lfw/*/*'))\nrandom.shuffle(human_images)\nprint('There are %d total human images.' % len(human_images))\n```"}, {'reason': 'stop', 'result': "```python\nwith tf.variable_scope('train'):\n    if is_time_major:\n        logits = tf.transpose(logits, [1, 0, 2])\n        crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=dataset.tgt_out_ids, logits=logits)\n        target_weights = tf.sequence_mask(dataset.tgt_size, tf.shape(logits)[1], tf.float32)\n    else:\n        crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=dataset.tgt_out_ids, logits=logits)\n        target_weights = tf.sequence_mask(dataset.tgt_size, tf.shape(logits)[1], tf.float32)\n    loss = tf.reduce_sum(crossent * target_weights) / tf.to_float(batch_size)\n    tf.summary.scalar('loss', loss)\n    learning_rate = tf.placeholder(dtype=tf.float32, name='learning_rate')\n    max_global_norm = tf.placeholder(dtype=tf.float32, name='max_global_norm')\n    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=0.5)\n    params = tf.trainable_variables()\n    gradients = tf.gradients(loss, params)\n    for grad, var in zip(gradients, params):\n        tf.summary.histogram(var.op.name + '/gradient', grad)\n    gradients, _ = tf.clip_by_global_norm(gradients, max_global_norm)\n    for grad, var in zip(gradients, params):\n        tf.summary.histogram(var.op.name + '/clipped_gradient', grad)\n    update = optimizer.apply_gradients(zip(gradients, params))\n```"}, {'reason': 'stop', 'result': '```python\nvalid_size = 1000\nvalid_text = text[:valid_size]\ntrain_text = text[valid_size:]\ntraining_text_length = len(train_text)\nprint(training_text_length, train_text[:64])\nprint(valid_size, valid_text[:64])\n```'}, {'reason': 'stop', 'result': '```python\n"""Function to read the blank-spaced column data into a Pandas data frame (table)"""\n\ndef read_table(file_name):\n    """\n    Read table data into a `pandas` data frame (table).  \n    \n    Parameters\n    ----------\n    file_name: str, required\n        File name and its path relative to this notebook.\n    \n    Returns\n    -------\n    table_data: pandas.df\n        `Pandas` data frame (table).\n\n    Examples\n    --------\n    """\n    import pandas as pd\n    table_data = pd.read_csv(file_name, skiprows=6, delim_whitespace=True)\n    for c in table_data.columns:\n        if c == \'Y(NO-DIM)\':\n            continue\n        table_data = table_data.astype({c: float}, copy=False)\n    return table_data\n```'}, {'reason': 'stop', 'result': "```python\nn_epochs = 10\nbatch_size = 40\nn_iterations_per_epoch = len(flower_paths_and_classes_train) // batch_size\nwith tf.Session() as sess:\n    init.run()\n    inception_saver.restore(sess, INCEPTION_V3_CHECKPOINT_PATH)\n    for epoch in range(n_epochs):\n        print('Epoch', epoch, end='')\n        for iteration in range(n_iterations_per_epoch):\n            print('.', end='')\n            batch_images, y_batch = prepare_batch(flower_paths_and_classes_train, batch_size)\n            sess.run(training_op, feed_dict={X: batch_images, y: y_batch, training: True})\n        acc_train = accuracy.eval(feed_dict={X: batch_images, y: y_batch})\n        print('  Train accuracy:', acc_train)\n        save_path = saver.save(sess, './my_flowers_model')\n```"}, {'reason': 'stop', 'result': "```python\nsamples_cluster_comparison = (np.abs(samples - true_centers.iloc[0]) < np.abs(samples - true_centers.iloc[1])).applymap(lambda x: 0 if x else 1)\ndf_preds = pd.concat([samples_cluster_comparison, pd.Series(sample_preds, name='PREDICTION')], axis=1)\nsns.heatmap(df_preds, annot=True, cbar=False, yticklabels=['sample 0', 'sample 1', 'sample 2'], linewidth=0.1, square=True)\nplt.title('Samples closer to\\ncluster 0 or 1?')\nplt.xticks(rotation=45, ha='center')\nplt.yticks(rotation=0)\n```"}, {'reason': 'stop', 'result': "```python\nX, Annotations = marconi['Soccer']\nfig = plt.figure(figsize=(16, 4))\n\ndef get_annot_img(ax, camera, frame):\n    ax.set_title('Camera ' + str(camera) + ' at frame ' + str(frame))\n    frame_image = X[camera, frame]\n    ax.imshow(frame_image)\n    Annotations_for_cam = Annotations[camera]\n    Annot_on_frame_cam = Annotations_for_cam[frame]\n    COLORS = ['red', 'yellow']\n    for i, ((tl, br), joints) in enumerate(Annot_on_frame_cam):\n        head_x, head_y = utils.tl_br_to_plt_plot(tl[1], tl[0], br[1], br[0])\n        ax.plot(head_x, head_y, color=COLORS[i])\n        for jx, jy, visible in joints:\n            ax.scatter(jx, jy, color=COLORS[i], alpha=1 if visible == 1 else 0.4)\nget_annot_img(fig.add_subplot(121), 0, 0)\nget_annot_img(fig.add_subplot(122), 1, 0)\nplt.axis('off')\nplt.show()\nPs, Ks, Rts = marconi.get_calibration('Soccer', split_intrinsic_extrinsic=True)\n```"}, {'reason': 'stop', 'result': "```python\nfrom skimage.io import imread\nfrom skimage import feature\nimage_array = imread('https://upload.wikimedia.org/wikipedia/commons/5/5f/MRI_EGC_sagittal.png')[-1::-1, :, :]\ncanny = feature.canny(image_array[:, :, 0], low_threshold=0.1 * 255, high_threshold=0.4 * 255) * 255\nplt.figure(figsize=[10, 10])\nplt.imshow(canny[-1::-1, :])\n```"}, {'reason': 'stop', 'result': "```python\nimport tensorflow as tf\nheight = 28\nwidth = 28\nchannels = 1\nn_inputs = height * width\nconv1_fmaps = 32\nconv1_ksize = 3\nconv1_stride = 1\nconv1_pad = 'SAME'\nconv2_fmaps = 64\nconv2_ksize = 3\nconv2_stride = 1\nconv2_pad = 'SAME'\nconv2_dropout_rate = 0.25\npool3_fmaps = conv2_fmaps\nn_fc1 = 128\nfc1_dropout_rate = 0.5\nn_outputs = 10\nreset_graph()\nwith tf.name_scope('inputs'):\n    input_data = tf.placeholder(tf.float32, shape=[None, n_inputs], name='X')\n    X_reshaped = tf.reshape(input_data, shape=[-1, height, width, channels])\n    y = tf.placeholder(tf.int32, shape=[None], name='y')\n    training = tf.placeholder_with_default(False, shape=[], name='training')\nconv1 = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps, kernel_size=conv1_ksize, strides=conv1_stride, padding=conv1_pad, activation=tf.nn.relu, name='conv1')\nconv2 = tf.layers.conv2d(conv1, filters=conv2_fmaps, kernel_size=conv2_ksize, strides=conv2_stride, padding=conv2_pad, activation=tf.nn.relu, name='conv2')\nwith tf.name_scope('pool3'):\n    pool3 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n    pool3_flat = tf.reshape(pool3, shape=[-1, pool3_fmaps * 14 * 14])\n    pool3_flat_drop = tf.layers.dropout(pool3_flat, conv2_dropout_rate, training=training)\nwith tf.name_scope('fc1'):\n    fc1 = tf.layers.dense(pool3_flat_drop, n_fc1, activation=tf.nn.relu, name='fc1')\n    fc1_drop = tf.layers.dropout(fc1, fc1_dropout_rate, training=training)\nwith tf.name_scope('output'):\n    logits = tf.layers.dense(fc1, n_outputs, name='output')\n    Y_proba = tf.nn.softmax(logits, name='Y_proba')\nwith tf.name_scope('train'):\n    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n    loss = tf.reduce_mean(xentropy)\n    optimizer = tf.train.AdamOptimizer()\n    training_op = optimizer.minimize(loss)\nwith tf.name_scope('eval'):\n    correct = tf.nn.in_top_k(logits, y, 1)\n    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\nwith tf.name_scope('init_and_save'):\n    init = tf.global_variables_initializer()\n    saver = tf.train.Saver()\n```"}, {'reason': 'stop', 'result': "```python\ninvalid_mean_run2 = ACCrunanalysis.loc[ACCrunanalysis['Run'] == 2].Invalid.mean()\nsms.DescrStatsW(ACCrunanalysis.loc[ACCrunanalysis['Run'] == 2].Invalid).tconfint_mean()\n```"}, {'reason': 'stop', 'result': '```python\ndiscretized_extinction = ext_pnicer.discretize()\ndiscretized_extinction.extinction\n```'}, {'reason': 'stop', 'result': '```python\n"""Plot function for nuclides half-life"""\n\ndef plot_nuclides(nuclides):\n    from matplotlib import pyplot as plt\n    fig, ax = plt.subplots(figsize=(18, 7))\n    ax.plot([nc.Z for nc in nuclides.values()], [nc.half_life / 3600 / 24 / 365 for nc in nuclides.values()], \' \', color=\'black\', marker=\'x\', markersize=10)\n    min_z = min([nc.Z for nc in nuclides.values()])\n    max_z = max([nc.Z for nc in nuclides.values()])\n    ax.xaxis.set_ticks(range(min_z, max_z + 1, 2))\n    ax.set_xlim((min_z - 1, max_z + 1))\n    plt.xlabel(\'Nuclide Z Number\', fontsize=18)\n    plt.ylabel(\'$T_{1/2} [a]$\', fontsize=18)\n    plt.xticks(fontsize=14)\n    plt.yticks(fontsize=16)\n    ay1 = ax.twiny()\n    ay1.set_xlim(ax.get_xlim())\n    ay1.set_xticks([])\n    from mendeleev import element\n    ay1.set_xticks(range(min_z, max_z + 1), [element(z).symbol for z in range(min_z, max_z + 1)])\n    ay1.set_xticklabels([element(z).symbol for z in range(min_z, max_z + 1)], minor=True, fontsize=12)\n    min_a = min([nc.A for nc in nuclides.values()])\n    max_atomic_mass = max([nc.A for nc in nuclides.values()])\n    plt.title(\'%i Nuclides: $%i \\\\leq A \\\\leq %i$ \' % (len(nuclides), min_a, max_atomic_mass), fontsize=22)\n    ax.grid(True)\n    plt.yscale(\'log\')\n    plt.show()\n    return\n```'}, {'reason': 'stop', 'result': '```python\ndef encode_io_pairs(text, window_size, step_size):\n    unique_characters = sorted(list(set(text)))\n    num_chars = len(unique_characters)\n    inputs, outputs = window_transform_text(text, window_size, step_size)\n    X = np.zeros((len(inputs), window_size, num_chars), dtype=np.bool)\n    y = np.zeros((len(inputs), num_chars), dtype=np.bool)\n    for i, sentence in enumerate(inputs):\n        for t, char in enumerate(sentence):\n            X[i, t, chars_to_indices[char]] = 1\n        y[i, chars_to_indices[outputs[i]]] = 1\n    return (X, y)\n```'}, {'reason': 'stop', 'result': "```python\ncounty = df_county_data['County Name']\nlanguage_spoken_count = df_county_data['Speak a language other than English']\nx_axis = np.arange(len(language_spoken_count))\ntick_locations = [value for value in x_axis]\nplt.bar(x_axis, language_spoken_count, color='r', align='center')\nplt.title('County ESL')\nplt.xlabel('Counties')\nplt.ylabel('Speak a language other than English')\nplt.text(140, 40, 'Note:\\nSpoken languages beside English for all counties in NJ, NY, & PA.')\nplt.savefig('Images/County_Speak a language other than English.png', bbox_inches='tight')\nplt.show()\n```"}, {'reason': 'stop', 'result': '```python\nimport sys\nimport platform\nfrom importlib.util import find_spec, module_from_spec\n\ndef check_newer_version(version_inst, version_nec):\n    version_inst_split = version_inst.split(\'.\')\n    version_nec_split = version_nec.split(\'.\')\n    for i in range(min(len(version_inst_split), len(version_nec_split))):\n        if int(version_nec_split[i]) > int(version_inst_split[i]):\n            return False\n        elif int(version_nec_split[i]) < int(version_inst_split[i]):\n            return True\n    return True\nmodule_list = [(\'jupyter\', \'1.0.0\'), (\'matplotlib\', \'2.0.2\'), (\'numpy\', \'1.13.1\'), (\'python\', \'3.6.2\'), (\'sklearn\', \'0.19.0\'), (\'scipy\', \'0.19.1\'), (\'nb_conda\', \'2.2.1\')]\npackages_correct = True\npackage_errors = []\nfor module_name, version in module_list:\n    if module_name == \'scikit-learn\':\n        module_name = \'sklearn\'\n    if module_name == \'pyyaml\':\n        module_name = \'yaml\'\n    if \'python\' in module_name:\n        python_version = platform.python_version()\n        if not check_newer_version(python_version, version):\n            packages_correct = False\n            error = f\'Update {module_name} to version {version}. Current version is {python_version}.\'\n            package_errors.append(error)\n            print(error)\n    else:\n        spec = find_spec(module_name)\n        if spec is None:\n            packages_correct = False\n            error = f\'Install {module_name} with version {version} or newer, it is required for this assignment!\'\n            package_errors.append(error)\n            print(error)\n        else:\n            x = __import__(module_name)\n            if hasattr(x, \'__version__\') and (not check_newer_version(x.__version__, version)):\n                packages_correct = False\n                error = f\'Update {module_name} to version {version}. Current version is {x.__version__}.\'\n                package_errors.append(error)\n                print(error)\ntry:\n    from google.colab import drive\n    packages_correct = False\n    error = "Please, don\'t use google colab!\\nIt will make it much more complicated for us to check your homework as it merges all the cells into one."\n    package_errors.append(error)\n    print(error)\nexcept:\n    pass\npackage_errors = \'\\n\'.join(package_errors)\n```'}, {'reason': 'stop', 'result': '```python\nforward_output, _, _ = solver.forward(vp=model0.vp)\n```'}, {'reason': 'stop', 'result': "```python\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\ntrain_tensors = paths_to_tensor(train_files).astype('float32') / 255\nvalidation_tensors = paths_to_tensor(valid_files).astype('float32') / 255\ntest_tensors = paths_to_tensor(test_files).astype('float32') / 255\n```"}, {'reason': 'stop', 'result': '```python\ndef sgd_iter(x_train, t_train, W, b):\n    random_indices = np.arange(len(x_train))\n    np.random.shuffle(random_indices)\n    lr = 0.0001\n    logp = np.zeros(len(x_train))\n    for i in random_indices:\n        x = x_train[i:i + 1]\n        t = t_train[i]\n        logp[i], grad_w, grad_b = logreg_gradient(x, t, W, b)\n        W = W + lr * grad_w\n        b = b + lr * grad_b\n    logp_train = logp.mean()\n    return (logp_train, W, b)\n```'}, {'reason': 'stop', 'result': "```python\nimport tensorflow as tf\nheight = 28\nwidth = 28\nchannels = 1\nn_inputs = height * width\nconv1_fmaps = 32\nconv1_ksize = 3\nconv1_stride = 1\nconv1_pad = 'SAME'\nconv2_fmaps = 64\nconv2_ksize = 3\nconv2_stride = 1\nconv2_pad = 'SAME'\nconv2_dropout_rate = 0.25\npool3_fmaps = conv2_fmaps\nn_fc1 = 128\nfc1_dropout_rate = 0.5\nn_outputs = 10\nreset_graph()\nwith tf.name_scope('inputs'):\n    X = tf.placeholder(tf.float32, shape=[None, n_inputs], name='X')\n    X_reshaped = tf.reshape(X, shape=[-1, height, width, channels])\n    y = tf.placeholder(tf.int32, shape=[None], name='y')\n    training = tf.placeholder_with_default(False, shape=[], name='training')\nconv1 = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps, kernel_size=conv1_ksize, strides=conv1_stride, padding=conv1_pad, activation=tf.nn.relu, name='conv1')\nconv2 = tf.layers.conv2d(conv1, filters=conv2_fmaps, kernel_size=conv2_ksize, strides=conv2_stride, padding=conv2_pad, activation=tf.nn.relu, name='conv2')\nwith tf.name_scope('pool3'):\n    pool3 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n    pool3_flat = tf.reshape(pool3, shape=[-1, pool3_fmaps * 14 * 14])\n    pool3_flat_drop = tf.layers.dropout(pool3_flat, conv2_dropout_rate, training=training)\nwith tf.name_scope('fc1'):\n    fc1 = tf.layers.dense(pool3_flat_drop, n_fc1, activation=tf.nn.relu, name='fc1')\n    fc1_drop = tf.layers.dropout(fc1, fc1_dropout_rate, training=training)\nwith tf.name_scope('output'):\n    output_layer = tf.layers.dense(fc1, n_outputs, name='output')\n    Y_proba = tf.nn.softmax(output_layer, name='Y_proba')\nwith tf.name_scope('train'):\n    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=output_layer, labels=y)\n    loss = tf.reduce_mean(xentropy)\n    optimizer = tf.train.AdamOptimizer()\n    training_op = optimizer.minimize(loss)\nwith tf.name_scope('eval'):\n    correct = tf.nn.in_top_k(output_layer, y, 1)\n    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\nwith tf.name_scope('init_and_save'):\n    init = tf.global_variables_initializer()\n    saver = tf.train.Saver()\n```"}, {'reason': 'stop', 'result': "```python\nn_epochs = 10\nbatch_size = 100\nwith tf.Session() as sess:\n    init.run()\n    for epoch in range(n_epochs):\n        for iteration in range(mnist.train.num_examples // batch_size):\n            X_batch, y_batch = mnist.train.next_batch(batch_size)\n            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n        acc_test = accuracy.eval(feed_dict={X: mnist.test.images, y: mnist.test.labels})\n        print(epoch, 'Train accuracy:', acc_train, 'Test accuracy:', acc_test)\n        model_checkpoint_path = saver.save(sess, './my_mnist_model')\n```"}, {'reason': 'stop', 'result': "```python\nsign_class_frequencies = get_frequencies(y_train_augmented, sign_dict)\nfig, ax = plt.subplots(figsize=(15, 10))\nclasses = list(sign_dict.values())\nind = np.arange(len(classes))\nwidth = 0.8\nrects = ax.bar(ind, sign_class_frequencies.values(), width, align='edge', alpha=0.5)\nax.set_ylabel('Frequency')\nax.set_title('Traffic Sign Classes')\nax.set_xticks(ind + width / 2)\nax.set_xticklabels(sign_class_frequencies.keys(), rotation=90)\nplt.show()\n```"}, {'reason': 'stop', 'result': "```python\ndef build_index(non_empty_days, from_time, to_time):\n    date_ranges = []\n    for date in non_empty_days:\n        yyyy, mm, day = date.split('-')\n        from_hour, from_min = from_time.split(':')\n        to_hour, to_min = to_time.split(':')\n        t1 = datetime(int(yyyy), int(mm), int(day), int(from_hour), int(from_min), 0)\n        t2 = datetime(int(yyyy), int(mm), int(day), int(to_hour), int(to_min), 0)\n        date_ranges.append(pd.DataFrame({'OrganizedDateTime': pd.date_range(t1, t2, freq='1Min').values}))\n    agg = pd.concat(date_ranges, axis=0)\n    agg.index = agg['OrganizedDateTime']\n    return agg\n```"}, {'reason': 'stop', 'result': "```python\nSMALL_SIZE = 10\nMEDIUM_SIZE = 12\nBIGGER_SIZE = 16\nfont_size = 20\nplt.rc('font', size=font_size)\nplt.rc('axes', titlesize=font_size)\nplt.rc('axes', labelsize=font_size)\nplt.rc('xtick', labelsize=BIGGER_SIZE)\nplt.rc('ytick', labelsize=BIGGER_SIZE)\nplt.rc('legend', fontsize=MEDIUM_SIZE)\nplt.rc('figure', titlesize=font_size)\n```"}, {'reason': 'stop', 'result': "```python\nnum_steps = 100001\nwith tf.Session(graph=graph) as session:\n    tf.global_variables_initializer().run()\n    print('Initialized')\n    average_loss = 0\n    for step in range(num_steps):\n        batch_data, batch_labels = generate_batch(batch_size, num_skips, skip_window)\n        feed_dict = {train_dataset: batch_data, train_labels: batch_labels}\n        _, l = session.run([optimizer, loss], feed_dict=feed_dict)\n        average_loss += l\n        if step % 2000 == 0:\n            if step > 0:\n                average_loss = average_loss / 2000\n            print('Average loss at step %d: %f' % (step, average_loss))\n            average_loss = 0\n        if step % 10000 == 0:\n            sim = similarity.eval()\n            for i in range(valid_size):\n                valid_word = reverse_dictionary[valid_examples[i]]\n                top_k = 8\n                nearest = (-sim[i, :]).argsort()[1:top_k + 1]\n                log = 'Nearest to %s:' % valid_word\n                for k in range(top_k):\n                    close_word = reverse_dictionary[nearest[k]]\n                    log = '%s %s,' % (log, close_word)\n                print(log)\n    final_embeddings = normalized_embeddings.eval()\n```"}, {'reason': 'stop', 'result': '```python\ndef featurize_state(state):\n    """\n    Returns the featurized representation for a state.\n    """\n    scaled = scaler.transform([state])\n    featurized_state = featurizer.transform(scaled)\n    return featurized_state[0]\n```'}, {'reason': 'stop', 'result': "```python\nACCrunanalysis = pd.DataFrame()\nnew_acclists = [[] for list in range(0, 5)]\nfor ID in range(10, 86):\n    sub = adat[adat.subject == ID]\n    for runID in range(0, 4):\n        subject_run_data = sub[sub.RunCounter == runID]\n        new_acclists[0].append(ID)\n        new_acclists[1].append(runID)\n        validACC_trials = subject_run_data[subject_run_data.TrialType == 'Valid'].Accuracy.mean()\n        invalidACC_trials = subject_run_data[subject_run_data.TrialType == 'Invalid'].Accuracy.mean()\n        new_acclists[2].append(validACC_trials)\n        new_acclists[3].append(invalidACC_trials)\nACCrunanalysis['SubjectID'] = new_acclists[0]\nACCrunanalysis['Run'] = new_acclists[1]\nACCrunanalysis['Valid'] = new_acclists[2]\nACCrunanalysis['Invalid'] = new_acclists[3]\n```"}, {'reason': 'stop', 'result': "```python\nfrom tensorflow.python.framework import ops\nops.reset_default_graph()\nbatch_size = 16\npatch_size = 5\ndepth = 16\nnum_hidden_full_1 = 96\nnum_hidden_full_2 = 96\ngraph = tf.Graph()\nwith graph.as_default():\n    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n    tf_valid_dataset = tf.constant(valid_dataset)\n    tf_test_dataset = tf.constant(test_dataset)\n    layer3_weights = init_weights([image_size * image_size * 64, num_hidden_full_1])\n    layer3_biases = init_weights([num_hidden_full_1], method='ones')\n    keep3 = tf.placeholder('float')\n    layer4_weights = init_weights([num_hidden_full_1, num_hidden_full_2])\n    layer4_biases = init_weights([num_hidden_full_2], method='ones')\n    keep4 = tf.placeholder('float')\n    layer5_weights = init_weights([num_hidden_full_2, num_labels])\n    layer5_biases = init_weights([num_labels], method='ones')\n    inception_1x1_weights = tf.Variable(tf.truncated_normal([1, 1, num_channels, depth], stddev=0.1))\n    inception_1x1_biases = tf.Variable(tf.zeros([depth]))\n    pre_inception_1x1_weights = tf.Variable(tf.truncated_normal([1, 1, num_channels, depth], stddev=0.1))\n    pre_inception_1x1_biases = tf.Variable(tf.zeros([depth]))\n    inception_1x1_pool_weights = tf.Variable(tf.truncated_normal([1, 1, num_channels, depth], stddev=0.1))\n    inception_1x1_pool_biases = tf.Variable(tf.zeros([depth]))\n    inception_3x3_weights = tf.Variable(tf.truncated_normal([3, 3, depth, depth], stddev=0.1))\n    inception_3x3_biases = tf.Variable(tf.zeros([depth]))\n    inception_5x5_weights = tf.Variable(tf.truncated_normal([5, 5, depth, depth], stddev=0.1))\n    inception_5x5_biases = tf.Variable(tf.zeros([depth]))\n\n    def inception_layer(data):\n        inception_conv1x1 = tf.nn.conv2d(data, inception_1x1_weights, [1, 1, 1, 1], padding='SAME')\n        inception_conv1x1 = tf.nn.relu(inception_conv1x1 + inception_1x1_biases)\n        print('1x1', inception_conv1x1.get_shape())\n        conv_pre = tf.nn.conv2d(data, pre_inception_1x1_weights, [1, 1, 1, 1], padding='SAME')\n        conv_pre = tf.nn.relu(conv_pre + pre_inception_1x1_biases)\n        conv_pool = tf.nn.avg_pool(data, [1, 3, 3, 1], [1, 1, 1, 1], padding='SAME')\n        conv_pool = tf.nn.conv2d(conv_pool, inception_1x1_pool_weights, [1, 1, 1, 1], padding='SAME')\n        conv_pool = tf.nn.relu(conv_pool + inception_1x1_pool_biases)\n        print('pool', conv_pool.get_shape())\n        conv_3x3 = tf.nn.conv2d(conv_pre, inception_3x3_weights, [1, 1, 1, 1], padding='SAME')\n        conv_3x3 = tf.nn.relu(conv_3x3 + inception_3x3_biases)\n        print('3x3', conv_3x3.get_shape())\n        conv_5x5 = tf.nn.conv2d(conv_pre, inception_5x5_weights, [1, 1, 1, 1], padding='SAME')\n        conv_5x5 = tf.nn.relu(conv_5x5 + inception_5x5_biases)\n        print('5x5', conv_5x5.get_shape())\n        inception_result = tf.concat(3, [inception_conv1x1, conv_3x3, conv_5x5, conv_pool])\n        print(inception_result.get_shape())\n        return inception_result\n\n    def model(data):\n        hidden = inception_layer(data)\n        shape = hidden.get_shape().as_list()\n        reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n        hidden = tf.nn.elu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n        hidden = tf.nn.dropout(hidden, keep3)\n        hidden = tf.nn.elu(tf.matmul(hidden, layer4_weights) + layer4_biases)\n        hidden = tf.nn.dropout(hidden, keep4)\n        output = tf.matmul(hidden, layer5_weights) + layer5_biases\n        return output\n    logits = model(tf_train_dataset)\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n    optimizer = tf.train.AdamOptimizer(0.0001).minimize(loss)\n    train_prediction = tf.nn.softmax(logits)\n    valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n    test_prediction = tf.nn.softmax(model(tf_test_dataset))\n```"}, {'reason': 'stop', 'result': '```python\ncolors = [\'b\', \'g\', \'r\', \'k\', \'c\', \'m\', \'y\']\nindex = 0\nfor segment in segments:\n    segDF = data.loc[data[\'RiverSeg\'] == segment]\n    segDF = segDF[segDF["lam\'"] > 0]\n    segDF = segDF.sort_values(\'Year\')\n    x = segDF[\'Year\']\n    fish_population_data = segDF[\'N21\']\n    fish_population_data.name = segment\n    plt.plot(x, fish_population_data, colors[index])\n    plt.legend(loc=(1.05, 0.2))\n    index += 1\nplt.title(\'Hill N21, \' + river + \' River Segments\')\nplt.xlabel(\'Year\')\nplt.ylabel(\'N21\')\nplt.xticks(np.arange(min(x), max(x) + 1, 1.0))\nplt.xticks(rotation=90)\nplt.savefig(output + \'\\\\\' + river + \'_Hill_N21.png\', bbox_inches=\'tight\', dpi=300, size=(2000, 2000))\nplt.show()\n```'}, {'reason': 'stop', 'result': "```python\ndef process_image(img):\n    warped, mask = perspect_transform(img, source, destination)\n    threshed = color_thresh(warped)\n    obs_map = np.absolute(np.float32(threshed) - 1) * mask\n    xpix, ypix = rover_coords(threshed)\n    image_height = data.worldmap.shape[0]\n    scale = 2 * dst_size\n    xpos = data.xpos[data.count]\n    ypos = data.ypos[data.count]\n    yaw = data.yaw[data.count]\n    x_world, y_world = pix_to_world(xpix, ypix, xpos, ypos, yaw, image_height, scale)\n    obsxpix, obsypix = rover_coords(obs_map)\n    obs_x_world, obs_y_world = pix_to_world(obsxpix, obsypix, xpos, ypos, yaw, image_height, scale)\n    data.worldmap[y_world, x_world, 2] = 255\n    data.worldmap[obs_y_world, obs_x_world, 0] = 255\n    nav_pix = data.worldmap[:, :, 2] > 0\n    data.worldmap[nav_pix, 0] = 0\n    rock_map = find_rocks(warped, levels=(110, 110, 50))\n    if rock_map.any():\n        rock_x, rock_y = rover_coords(rock_map)\n        rock_x_world, rock_y_world = pix_to_world(rock_x, rock_y, xpos, ypos, yaw, image_height, scale)\n        data.worldmap[rock_y_world, rock_x_world, :] = 255\n    output_image = np.zeros((img.shape[0] + data.worldmap.shape[0], img.shape[1] * 2, 3))\n    output_image[0:img.shape[0], 0:img.shape[1]] = img\n    output_image[0:img.shape[0], img.shape[1]:] = warped\n    map_add = cv2.addWeighted(data.worldmap, 1, data.ground_truth, 0.5, 0)\n    output_image[img.shape[0]:, 0:data.worldmap.shape[1]] = np.flipud(map_add)\n    cv2.putText(output_image, 'Populate this image with your analyses to make a video!', (20, 20), cv2.FONT_HERSHEY_COMPLEX, 0.4, (255, 255, 255), 1)\n    if data.count < len(data.images) - 1:\n        data.count += 1\n    return output_image\n```"}, {'reason': 'stop', 'result': '```python\ndef process_image(image):\n    gray = grayscale(image)\n    kernel_size = 5\n    blur_gray = gaussian_blur(gray, kernel_size)\n    low_threshold = 60\n    high_threshold = 100\n    edges = canny(blur_gray, low_threshold, high_threshold)\n    imshape = image.shape\n    lane_region = np.array([[(0, imshape[0]), (imshape[1] * 0.48, imshape[0] * 0.6), (imshape[1] * 0.52, imshape[0] * 0.6), (imshape[1], imshape[0])]], dtype=np.int32)\n    masked_edges = region_of_interest(edges, lane_region)\n    rho = 1\n    theta = np.pi / 180\n    threshold = 90\n    min_line_length = 30\n    max_line_gap = 30\n    line_image = np.copy(image) * 0\n    lines = hough_lines(masked_edges, rho, theta, threshold, min_line_length, max_line_gap, lane_region)\n    result = weighted_img(lines, image, α=0.8, β=1.0, λ=0.0)\n    return result\n```'}, {'reason': 'stop', 'result': "```python\nimport pickle\ntraining_file = '../traffic-signs-data/train.p'\nvalidation_file = '../traffic-signs-data/valid.p'\ntesting_file = '../traffic-signs-data/test.p'\nwith open(training_file, mode='rb') as f:\n    train = pickle.load(f)\nwith open(validation_file, mode='rb') as f:\n    valid = pickle.load(f)\nwith open(testing_file, mode='rb') as f:\n    test = pickle.load(f)\nX_train, y_train = (train['features'], train['labels'])\nX_valid, y_valid = (valid['features'], valid['labels'])\ntest_features_labels, y_test = (test['features'], test['labels'])\n```"}, {'reason': 'stop', 'result': '```python\ndef ridge_regression_demo(x, y, degree, ratio, seed):\n    """ridge regression demo."""\n    lambdas = np.logspace(-5, 0, 15)\n    raise NotImplementedError\n    raise NotImplementedError\n    ridge_regression_results = []\n    rmse_te = []\n    for ind, lambda_ in enumerate(lambdas):\n        print(\'proportion={p}, degree={d}, lambda={l:.3f}, Training RMSE={tr:.3f}, Testing RMSE={te:.3f}\'.format(p=ratio, d=degree, l=lambda_, tr=ridge_regression_results[ind], te=rmse_te[ind]))\n    plot_train_test(ridge_regression_results, rmse_te, lambdas, degree)\n    raise NotImplementedError\n```'}, {'reason': 'stop', 'result': "```python\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\ncv_description = CountVectorizer(token_pattern='(?u)\\\\b\\\\w+\\\\b', stop_words=None, ngram_range=(1, 1), analyzer='word')\ndt_mat_description = cv_description.fit_transform(playlist_df.playlist_description)\nplaylist_df['playlist_description_frequency'] = list(dt_mat_description.toarray())\nplaylist_name_vectorizer = CountVectorizer(token_pattern='(?u)\\\\b\\\\w+\\\\b', stop_words=None, ngram_range=(1, 1), analyzer='word')\ndt_mat_name = playlist_name_vectorizer.fit_transform(playlist_df.playlist_name)\nplaylist_df['playlist_name_frequency'] = list(dt_mat_name.toarray())\n```"}, {'reason': 'stop', 'result': '```python\nNUM_IN_CLASS = 800\n\ndef random_translate(img):\n    rows, cols, ch = img.shape\n    x = random.randint(-4, 4)\n    y = random.randint(-4, 4)\n    M = np.float32([[1, 0, x], [0, 1, y]])\n    return cv.warpAffine(img, M, (cols, rows))\n\ndef random_rotate(img):\n    rows, cols, ch = img.shape\n    degree = random.randint(-8, 8)\n    M = cv.getRotationMatrix2D((cols / 2, rows / 2), degree, 1)\n    return cv.warpAffine(img, M, (cols, rows))\n\ndef random_zoom(img):\n    x = random.randint(1, 5)\n    y = random.randint(26, 31)\n    pts1 = np.float32([[x, x], [y, x], [x, y], [y, y]])\n    pts2 = np.float32([[0, 0], [31, 0], [0, 31], [31, 31]])\n    M = cv.getPerspectiveTransform(pts1, pts2)\n    return cv.warpPerspective(img, M, (32, 32))\n\ndef random_transform_img(rand_img, transform_type_n=None):\n    """\n    transform_type_n:\n        0: random_translate\n        1: random_rotate\n        2: random_zoom\n    """\n    transform_funcs = [random_translate, random_rotate, random_zoom]\n    if transform_type_n:\n        transform = transform_funcs[transform_type_n]\n        return transform(rand_img)\n    transform = random.choice(transform_funcs)\n    return transform(rand_img)\n\ndef split_by_class(X_train, y_train):\n    """\n    Return data_by_classes, list of tuples, each tuple: (X_train_class_i, y_train_class_i)\n    Note: X_train_class_i is a list, y_train_class_i is a number\n    """\n    class_data_dict = {}\n    for i in range(len(y_train)):\n        if y_train[i] not in class_data_dict:\n            class_data_dict[y_train[i]] = [X_train[i]]\n        else:\n            class_data_dict[y_train[i]].append(X_train[i])\n    data_by_classes = [(X_train_class_i, y_train_class_i) for y_train_class_i, X_train_class_i in class_data_dict.items()]\n    return data_by_classes\n\ndef augment_by_class(training_data_tuple):\n    """\n    Augment the data by translating, rotating, zooming, until it has 1200 examples\n    training_data_tuple: (X_train_class_i, y_train_class_i), \n    X_train_class_i is a list, y_train_class_i is a number\n    """\n    X_train_by_class = training_data_tuple[0]\n    y_train_by_class = training_data_tuple[1]\n    if len(X_train_by_class) >= NUM_IN_CLASS:\n        return training_data_tuple\n    while len(X_train_by_class) < NUM_IN_CLASS:\n        rand_img = random.choice(X_train_by_class)\n        new_img = random_transform_img(rand_img)\n        X_train_by_class.append(new_img)\n    return (X_train_by_class, y_train_by_class)\n\ndef merge_and_shuffle(augmented_data_by_classes):\n    augmented_X_train = []\n    augmented_y_train = []\n    for augmented_tup in augmented_data_by_classes:\n        for X_train_i in augmented_tup[0]:\n            augmented_X_train.append(X_train_i)\n            augmented_y_train.append(augmented_tup[1])\n    X_train, y_train = shuffle(augmented_X_train, augmented_y_train)\n    return (X_train, y_train)\n\ndef augment_data(X_train, y_train):\n    """\n    Main function to augment training data\n    """\n    data_by_classes = split_by_class(X_train, y_train)\n    augmented_data_by_classes = []\n    for tup in data_by_classes:\n        augmented_tup = augment_by_class(tup)\n        assert len(tup[0]) >= NUM_IN_CLASS, \'Class {0} still has {0} examples\'.format(tup[1], len(tup[0]))\n        augmented_data_by_classes.append(augmented_tup)\n    return merge_and_shuffle(augmented_data_by_classes)\nrand_img = random.choice(X_train)\ntransformed_img = random_translate(rand_img)\n(plt.subplot(121), plt.imshow(rand_img), plt.title(\'Input\'))\n(plt.subplot(122), plt.imshow(transformed_img), plt.title(\'Output\'))\nplt.suptitle(\'Translation\')\nplt.show()\nrand_img = random.choice(X_train)\ntransformed_img = random_rotate(rand_img)\n(plt.subplot(121), plt.imshow(rand_img), plt.title(\'Input\'))\n(plt.subplot(122), plt.imshow(transformed_img), plt.title(\'Output\'))\nplt.suptitle(\'Rotation\')\nplt.show()\nrand_img = random.choice(X_train)\ntransformed_img = random_zoom(rand_img)\n(plt.subplot(121), plt.imshow(rand_img), plt.title(\'Input\'))\n(plt.subplot(122), plt.imshow(transformed_img), plt.title(\'Output\'))\nplt.suptitle(\'Zoom\')\nplt.show()\nX_train_augmented, y_train_augmented = augment_data(X_train, y_train)\n```'}, {'reason': 'stop', 'result': "```python\nphs_data_foil_activation = readFlu(heprowPath + faltwPHSName, delim_whitespace=True, names=['lowE', 'absPHS', 'absSigma'], skiprows=3)\nmeasPHSData = readFlu(heprowPath + measPHSName, delim_whitespace=True, names=['lowE', 'absPHS', 'absSigma'], skiprows=3)\nfaltwPHSHisto = Histogram()\nfaltwPHSHisto.build_histo(phs_data_foil_activation['lowE'].tolist(), bin_differentiation(phs_data_foil_activation['lowE'].tolist(), phs_data_foil_activation['absPHS'].tolist()), uncert=phs_data_foil_activation['absSigma'].tolist(), edgeLoc=heprowBinBounds, name='FALTW')\nmeasPHSHisto = Histogram()\nmeasPHSHisto.build_histo(measPHSData['lowE'].tolist(), bin_differentiation(measPHSData['lowE'].tolist(), measPHSData['absPHS'].tolist()), uncert=measPHSData['absSigma'].tolist(), edgeLoc=heprowBinBounds, name='Measured')\nfaltwPHSHisto.plot(measPHSHisto, logY=True, title='33MeV Deutrons on Ta', xLabel='Light Yield [MeVee]', yLabel='Counts per MeVee')\n```"}, {'reason': 'stop', 'result': "```python\nfrom tensorflow.python.framework import ops\nops.reset_default_graph()\nbatch_size = 16\npatch_size = 5\ndepth = 16\nnum_hidden_full_1 = 512\nnum_hidden_full_2 = 64\n\ndef init_weights(shape, method='xavier'):\n    if method == 'zeros':\n        return tf.Variable(tf.zeros(shape, dtype=tf.float32))\n    elif method == 'ones':\n        return tf.Variable(tf.ones(shape, dtype=tf.float32))\n    elif method == 'uniform':\n        return tf.Variable(tf.random_normal(shape, stddev=0.01, dtype=tf.float32))\n    elif method == 'altxavier':\n        low = -4 * np.sqrt(6.0 / (shape[0] + shape[1]))\n        high = 4 * np.sqrt(6.0 / (shape[0] + shape[1]))\n        return tf.Variable(tf.random_uniform(shape, minval=low, maxval=high, dtype=tf.float32))\n    elif method == 'xavier':\n        xavier_stddev = np.sqrt(3.0 / (shape[0] + shape[1]))\n        return tf.Variable(tf.truncated_normal(shape, stddev=xavier_stddev))\n    else:\n        variable_def = np.sqrt(2.0 / shape[0])\n        return tf.Variable(tf.truncated_normal(shape, stddev=variable_def))\ngraph = tf.Graph()\nwith graph.as_default():\n    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n    tf_valid_dataset = tf.constant(valid_dataset)\n    tf_test_dataset = tf.constant(test_dataset)\n    layer1_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, num_channels, depth], stddev=0.1))\n    layer1_biases = tf.Variable(tf.zeros([depth]))\n    layer2_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth, depth * 2], stddev=0.1))\n    layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth * 2]))\n    layer3_weights = init_weights([image_size // 4 * image_size // 4 * depth * 2, num_hidden_full_1])\n    layer3_biases = init_weights([num_hidden_full_1], method='ones')\n    keep3 = tf.placeholder('float')\n    layer4_weights = init_weights([num_hidden_full_1, num_hidden_full_2])\n    layer4_biases = init_weights([num_hidden_full_2], method='ones')\n    keep4 = tf.placeholder('float')\n    layer5_weights = init_weights([num_hidden_full_2, num_labels])\n    layer5_biases = init_weights([num_labels], method='ones')\n\n    def model(data):\n        conv = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')\n        conv = tf.nn.elu(conv + layer1_biases)\n        hidden = tf.nn.max_pool(conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n        conv = tf.nn.conv2d(hidden, layer2_weights, [1, 1, 1, 1], padding='SAME')\n        conv = tf.nn.elu(conv + layer2_biases)\n        hidden = tf.nn.max_pool(conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n        shape = hidden.get_shape().as_list()\n        reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n        hidden = tf.nn.elu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n        hidden = tf.nn.dropout(hidden, keep3)\n        hidden = tf.nn.elu(tf.matmul(hidden, layer4_weights) + layer4_biases)\n        hidden = tf.nn.dropout(hidden, keep4)\n        output = tf.matmul(hidden, layer5_weights) + layer5_biases\n        return output\n    logits = model(tf_train_dataset)\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n    optimizer = tf.train.AdamOptimizer(0.0001).minimize(loss)\n    train_prediction = tf.nn.softmax(logits)\n    valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n    test_prediction = tf.nn.softmax(model(tf_test_dataset))\n```"}, {'reason': 'stop', 'result': "```python\nheatmap_image = plt.imread(test_path + '61060_1/pdi_heat.jpg')\nplt.figure(figsize=(15, 15))\nplt.imshow(heatmap_image)\n```"}, {'reason': 'stop', 'result': "```python\npollution_data_day['day'] = pollution_data_day.time.dt.day\n```"}, {'reason': 'stop', 'result': '```python\ngROOT.ProcessLine(\'SimulationManipulation sm("{}",0)\'.format(rspPath))\ngROOT.ProcessLine(\'HistogramOperations ops\')\ngROOT.ProcessLine(\'HistogramWriter writer;\')\ngROOT.ProcessLine(\'lightTables.setBirksParams(1.0,6.90)\')\nrspEbins = np.arange(rspEmin, rspEmax, rspEwidth)\nrspEbins = np.append(rspEbins, rspEmax)\nrspLbins = np.arange(rspLmin, rspLmax, rspLwidth)\nrspLbins = np.append(rspLbins, rspLmax)\ngROOT.ProcessLine(\'const Int_t EBINS = {}; const Int_t LBINS = {};\'.format(len(rspEbins) - 1, len(rspLbins) - 1))\ngROOT.ProcessLine(\'Double_t eEdges[EBINS + 1] = {}{}{};\'.format(\'{\', \', \'.join((str(e) for e in rspEbins)), \'}\'))\ngROOT.ProcessLine(\'Double_t lEdges[LBINS + 1] = {}{}{};\'.format(\'{\', \', \'.join((str(e) for e in rspLbins)), \'}\'))\ngROOT.ProcessLine(\'axis1 = TAxis(EBINS,eEdges);\')\ngROOT.ProcessLine(\'axis2 = TAxis(LBINS,lEdges);\')\ngROOT.ProcessLine(\'TH2* matrix1=sm.getNormalizedResponseMatrix(axis1,axis2)\')\ngROOT.ProcessLine(\'writer.ResponseToHEPROW(matrix1,"EJ309_resp_03_1")\')\nfor detNum, detName in detNames.iteritems():\n    calibration_parameters = CalibParams(calPath + calNames[detNum])\n    gROOT.ProcessLine(\'TH2* smearMatrix{0} = ops.skewedGausSmearMatrix(matrix1, {1}, {2}, {3})\'.format(detNum, calibration_parameters.alpha, calibration_parameters.beta, calibration_parameters.gamma))\n    gROOT.ProcessLine(\'smearMatrix{0}->Draw("colz")\'.format(detNum))\n    gROOT.ProcessLine(\'writer.ResponseToHEPROW(smearMatrix{0},"{1}_smearedResp_03_1")\'.format(detNum, detName))\n    pause()\n```'}, {'reason': 'stop', 'result': '```python\ndef process_image(image):\n    """ Filter color """\n    color_select = np.copy(image)\n    rgb_threshold = [200, 150, 95]\n    thresholds = (image[:, :, 0] < rgb_threshold[0]) | (image[:, :, 1] < rgb_threshold[1]) | (image[:, :, 2] < rgb_threshold[2])\n    color_select[thresholds] = [0, 0, 0]\n    gray = grayscale(color_select)\n    blurred = gaussian_blur(gray, 3)\n    edges = canny(blurred, 50, 150)\n    xsize = image.shape[1]\n    ysize = image.shape[0]\n    lane_region = np.array([[(0, ysize), (xsize / 2, ysize / 1.71), (xsize / 2, ysize / 1.71), (xsize, ysize)]], dtype=np.int32)\n    regioned = region_of_interest(edges, lane_region)\n    hough = hough_lines(regioned, 1, np.pi / 180, 35, 35, 20)\n    result = weighted_img(hough, image)\n    return result\n```'}, {'reason': 'stop', 'result': '```python\nnull_percentage = null_count_series / totalcount\npercent_filled = filled_count_series / totalcount\n```'}, {'reason': 'stop', 'result': "```python\ncov = X.T @ X / (X.shape[0] - 1)\nval, vec = np.linalg.eigh(cov)\nidx = np.argsort(val)[::-1]\nval = val[idx]\nvec = vec[:, idx]\nproject_X = X @ vec\nproject_V = vec.T @ vec\nprojected_data = project_X @ np.linalg.inv(vec)\nrevertedV = project_V @ np.linalg.inv(vec).T\nplt.figure(figsize=(15, 5))\nplt.subplot(131)\nplt.scatter(X[y == 0, 0], X[y == 0, 1], color='red', alpha=0.5)\nplt.scatter(X[y == 1, 0], X[y == 1, 1], color='blue', alpha=0.5)\npca11 = plt.arrow(0, 0, *vec[:, 0] * val[0], head_width=0.05, head_length=0.05, color='Green', label='First PC')\npca12 = plt.arrow(0, 0, *vec[:, 1] * val[1], head_width=0.05, head_length=0.05, color='magenta', label='Second PC')\nplt.grid(True)\nplt.subplot(132)\nplt.scatter(project_X[y == 0, 0], project_X[y == 0, 1], color='red', alpha=0.5)\nplt.scatter(project_X[y == 1, 0], project_X[y == 1, 1], color='blue', alpha=0.5)\npca21 = plt.arrow(0, 0, *project_V[:, 0] * val[0], head_width=0.05, head_length=0.05, color='Green', label='First PC')\npca22 = plt.arrow(0, 0, *project_V[:, 1] * val[1], head_width=0.05, head_length=0.05, color='magenta', label='Second PC')\nplt.grid(True)\nplt.subplot(133)\nplt.scatter(projected_data[y == 0, 0], projected_data[y == 0, 1], color='red', alpha=0.5)\nplt.scatter(projected_data[y == 1, 0], projected_data[y == 1, 1], color='blue', alpha=0.5)\npca21 = plt.arrow(0, 0, *revertedV[:, 0] * val[0], head_width=0.05, head_length=0.05, color='Green', label='First PC')\npca22 = plt.arrow(0, 0, *revertedV[:, 1] * val[1], head_width=0.05, head_length=0.05, color='magenta', label='Second PC')\nplt.grid(True)\nplt.show()\n```"}, {'reason': 'stop', 'result': "```python\ncorr_pov = abs(df_county_data['Poverty Rate'].corr(grad_rate))\nhousehold_size_corr = abs(df_county_data['Household Size'].corr(grad_rate))\ncorr_job = abs(df_county_data['Unemployment Rate'].corr(grad_rate))\ncorr_inc = abs(df_county_data['Median Income'].corr(grad_rate))\ncorr_ESL = abs(df_county_data['Speak a language other than English'].corr(grad_rate))\nprint('Correlations')\nprint('Poverty:             ' + '{:.4f}'.format(corr_pov))\nprint('Median Income:       ' + '{:.4f}'.format(corr_inc))\nprint('Unemployment Rates:  ' + '{:.4f}'.format(corr_job))\nprint('Non-English at Home: ' + '{:.4f}'.format(corr_ESL))\nprint('Household Size:      ' + '{:.4f}'.format(household_size_corr))\n```"}, {'reason': 'stop', 'result': "```python\nI = Variable(name='I', num_states=2)\nS = Variable(name='S', num_states=2)\nST = Variable(name='ST', num_states=2)\nF = Variable(name='F', num_states=2)\nB = Variable(name='B', num_states=2)\nC = Variable(name='C', num_states=2)\nW = Variable(name='W', num_states=2)\nf_I = Factor(name='p(I)', f=np.array([0.95, 0.05]), neighbours=[I])\nf_S = Factor(name='p(S)', f=np.array([0.8, 0.2]), neighbours=[S])\nprob_ST = [[0.999, 0.7], [0.001, 0.3]]\nf_ST = Factor(name='p(ST |I)', f=np.array(prob_ST), neighbours=[ST, I])\nprob_F = [[0.95, 0.1], [0.05, 0.9]]\nf_F = Factor(name='p(F |I)', f=np.array(prob_F), neighbours=[F, I])\nprob_B = [[[0.9999, 0.3], [0.1, 0.01]], [[0.0001, 0.7], [0.9, 0.99]]]\nf_B = Factor(name='p(B |I, S)', f=np.array(prob_B), neighbours=[B, I, S])\nprob_C = [[0.93, 0.2], [0.07, 0.8]]\nf_C = Factor(name='p(C |B)', f=np.array(prob_C), neighbours=[C, B])\nprob_W = [[0.999, 0.4], [0.001, 0.6]]\nconditional_probability_W_B = Factor(name='p(W |B)', f=np.array(prob_W), neighbours=[W, B])\n```"}, {'reason': 'stop', 'result': '```python\nbasic_model = HiddenMarkovModel(name=\'base-hmm-tagger\')\ntags = (tag for i, (word, tag) in enumerate(data.training_set.stream()))\nwords = (word for i, (word, tag) in enumerate(data.training_set.stream()))\nemission_counts = pair_counts(tags, words)\nstates = {}\nfor tag, word_dict in emission_counts.items():\n    emission_dict = defaultdict(float)\n    for word in word_dict.keys():\n        emission_dict[word] = emission_counts[tag][word] / tag_unigrams[tag]\n    state_emission = DiscreteDistribution(dict(emission_dict))\n    states[tag] = State(state_emission, name=tag)\nbasic_model.add_states(list(states.values()))\nfor tag in data.training_set.tagset:\n    state = states[tag]\n    basic_model.add_transition(basic_model.start, state, tag_starts[tag] / len(data.training_set))\n    basic_model.add_transition(state, basic_model.end, tag_ends[tag] / tag_unigrams[tag])\n    for next_tag in data.training_set.tagset:\n        next_state = states[next_tag]\n        basic_model.add_transition(state, next_state, tag_bigrams[tag, next_tag] / tag_unigrams[tag])\nbasic_model.bake()\nassert all((tag in set((s.name for s in basic_model.states)) for tag in data.training_set.tagset)), \'Every state in your network should use the name of the associated tag, which must be one of the training set tags.\'\nassert basic_model.edge_count() == 168, \'Your network should have an edge from the start node to each state, one edge between every \' + \'pair of tags (states), and an edge from each state to the end node.\'\nHTML(\'<div class="alert alert-block alert-success">Your HMM network topology looks good!</div>\')\n```'}, {'reason': 'stop', 'result': '```python\nfiltered_data = subset\n```'}, {'reason': 'stop', 'result': '```python\ndef padRightDownCorner(img, stride, padValue):\n    h = img.shape[0]\n    w = img.shape[1]\n    pad = 4 * [None]\n    pad[0] = 0\n    pad[1] = 0\n    pad[2] = 0 if h % stride == 0 else stride - h % stride\n    pad[3] = 0 if w % stride == 0 else stride - w % stride\n    img_padded = img\n    padded_image = np.tile(img_padded[0:1, :, :] * 0 + padValue, (pad[0], 1, 1))\n    img_padded = np.concatenate((padded_image, img_padded), axis=0)\n    pad_left = np.tile(img_padded[:, 0:1, :] * 0 + padValue, (1, pad[1], 1))\n    img_padded = np.concatenate((pad_left, img_padded), axis=1)\n    pad_down = np.tile(img_padded[-2:-1, :, :] * 0 + padValue, (pad[2], 1, 1))\n    img_padded = np.concatenate((img_padded, pad_down), axis=0)\n    pad_right = np.tile(img_padded[:, -2:-1, :] * 0 + padValue, (1, pad[3], 1))\n    img_padded = np.concatenate((img_padded, pad_right), axis=1)\n    return (img_padded, pad)\n\nclass DataBatch(object):\n\n    def __init__(self, data, label, pad=0):\n        self.data = [data]\n        self.label = [label]\n        self.pad = pad\n```'}, {'reason': 'stop', 'result': "```python\nfor i in range(len(multiplier)):\n    scale = multiplier[i]\n    imageToTest = cv.resize(oriImg, (0, 0), fx=scale, fy=scale, interpolation=cv.INTER_CUBIC)\n    imageToTest_padded, pad = padRightDownCorner(imageToTest, 8, 128)\n    transposeImage = np.transpose(np.float32(imageToTest_padded[:, :, :]), (2, 0, 1)) / 256 - 0.5\n    testimage = transposeImage\n    cmodel = mx.mod.Module(symbol=sym, label_names=[])\n    cmodel.bind(data_shapes=[('data', (1, 3, testimage.shape[1], testimage.shape[2]))])\n    cmodel.init_params(arg_params=arg_params, aux_params=aux_params)\n    input_data_batch = DataBatch(mx.nd.array([testimage[:, :, :]]), 0)\n    cmodel.forward(input_data_batch)\n    result = cmodel.get_outputs()\n    heatmap = np.moveaxis(result[1].asnumpy()[0], 0, -1)\n    heatmap = cv.resize(heatmap, (0, 0), fx=model['stride'], fy=model['stride'], interpolation=cv.INTER_CUBIC)\n    heatmap = heatmap[:imageToTest_padded.shape[0] - pad[2], :imageToTest_padded.shape[1] - pad[3], :]\n    heatmap = cv.resize(heatmap, (oriImg.shape[1], oriImg.shape[0]), interpolation=cv.INTER_CUBIC)\n    heatmap_avg = heatmap_avg + heatmap / len(multiplier)\n    f = plt.figure(i)\n    plt.imshow(oriImg[:, :, [2, 1, 0]])\n    ax2 = plt.imshow(heatmap[:, :, 18], alpha=0.5)\n    f.show()\n```"}, {'reason': 'stop', 'result': '```python\nimport random\n\ndef compute_fitness(solution):\n    """\n        This function returns the total distance traveled on the current road trip.\n        \n        The genetic algorithm will favor road trips that have shorter\n        total distances traveled.\n    """\n    agent_fitness = 0.0\n    for index in range(len(solution)):\n        waypoint1 = solution[index - 1]\n        waypoint2 = solution[index]\n        agent_fitness += waypoint_distances[frozenset([waypoint1, waypoint2])]\n    return agent_fitness\n\ndef generate_random_agent():\n    """\n        Creates a random road trip from the waypoints.\n    """\n    new_random_agent = list(all_waypoints)\n    random.shuffle(new_random_agent)\n    return tuple(new_random_agent)\n\ndef mutate_agent(agent_genome, max_mutations=3):\n    """\n        Applies 1 - `max_mutations` point mutations to the given road trip.\n        \n        A point mutation swaps the order of two waypoints in the road trip.\n    """\n    agent_genome = list(agent_genome)\n    num_mutations = random.randint(1, max_mutations)\n    for mutation in range(num_mutations):\n        swap_index1 = random.randint(0, len(agent_genome) - 1)\n        swap_index2 = swap_index1\n        while swap_index1 == swap_index2:\n            swap_index2 = random.randint(0, len(agent_genome) - 1)\n        agent_genome[swap_index1], agent_genome[swap_index2] = (agent_genome[swap_index2], agent_genome[swap_index1])\n    return tuple(agent_genome)\n\ndef shuffle_mutation(agent_genome):\n    """\n        Applies a single shuffle mutation to the given road trip.\n        \n        A shuffle mutation takes a random sub-section of the road trip\n        and moves it to another location in the road trip.\n    """\n    agent_genome = list(agent_genome)\n    start_index = random.randint(0, len(agent_genome) - 1)\n    length = random.randint(2, 20)\n    genome_subset = agent_genome[start_index:start_index + length]\n    agent_genome = agent_genome[:start_index] + agent_genome[start_index + length:]\n    insert_index = random.randint(0, len(agent_genome) + len(genome_subset) - 1)\n    agent_genome = agent_genome[:insert_index] + genome_subset + agent_genome[insert_index:]\n    return tuple(agent_genome)\n\ndef generate_random_population(pop_size):\n    """\n        Generates a list with `pop_size` number of random road trips.\n    """\n    random_population = []\n    for agent in range(pop_size):\n        random_population.append(generate_random_agent())\n    return random_population\n\ndef run_genetic_algorithm(generations=5000, population_size=100):\n    """\n        The core of the Genetic Algorithm.\n        \n        `generations` and `population_size` must be a multiple of 10.\n    """\n    population_subset_size = int(population_size / 10.0)\n    generations_10pct = int(generations / 10.0)\n    population = generate_random_population(population_size)\n    for generation in range(generations):\n        agent_fitness = {}\n        for agent_genome in population:\n            if agent_genome in agent_fitness:\n                continue\n            agent_fitness[agent_genome] = compute_fitness(agent_genome)\n        new_population = []\n        for rank, agent_genome in enumerate(sorted(agent_fitness, key=agent_fitness.get)[:population_subset_size]):\n            if (generation % generations_10pct == 0 or generation == generations - 1) and rank == 0:\n                print(\'Generation %d best: %d | Unique genomes: %d\' % (generation, agent_fitness[agent_genome], len(agent_fitness)))\n                print(agent_genome)\n                print(\'\')\n            new_population.append(agent_genome)\n            for offspring in range(2):\n                new_population.append(mutate_agent(agent_genome, 3))\n            for offspring in range(7):\n                new_population.append(shuffle_mutation(agent_genome))\n        for i in range(len(population))[::-1]:\n            del population[i]\n        population = new_population\n```'}, {'reason': 'stop', 'result': '```python\ndef face_detector(img_path):\n    image = cv2.imread(img_path)\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    faces = face_cascade.detectMultiScale(gray)\n    return len(faces) > 0\n```'}, {'reason': 'stop', 'result': '```python\nnum_nodes = 64\ngraph = tf.Graph()\nwith graph.as_default():\n    ix = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n    im = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n    ib = tf.Variable(tf.zeros([1, num_nodes]))\n    fx = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n    fm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n    lstm_variable_def = tf.Variable(tf.zeros([1, num_nodes]))\n    cx = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n    cm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n    cb = tf.Variable(tf.zeros([1, num_nodes]))\n    ox = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n    om = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n    ob = tf.Variable(tf.zeros([1, num_nodes]))\n    saved_output = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False)\n    saved_state = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False)\n    w = tf.Variable(tf.truncated_normal([num_nodes, vocabulary_size], -0.1, 0.1))\n    b = tf.Variable(tf.zeros([vocabulary_size]))\n\n    def lstm_cell(i, o, state):\n        """Create a LSTM cell. See e.g.: http://arxiv.org/pdf/1402.1128v1.pdf\n    Note that in this formulation, we omit the various connections between the\n    previous state and the gates."""\n        input_gate = tf.sigmoid(tf.matmul(i, ix) + tf.matmul(o, im) + ib)\n        forget_gate = tf.sigmoid(tf.matmul(i, fx) + tf.matmul(o, fm) + lstm_variable_def)\n        update = tf.matmul(i, cx) + tf.matmul(o, cm) + cb\n        state = forget_gate * state + input_gate * tf.tanh(update)\n        output_gate = tf.sigmoid(tf.matmul(i, ox) + tf.matmul(o, om) + ob)\n        return (output_gate * tf.tanh(state), state)\n    train_data = list()\n    for _ in range(num_unrollings + 1):\n        train_data.append(tf.placeholder(tf.float32, shape=[batch_size, vocabulary_size]))\n    train_inputs = train_data[:num_unrollings]\n    train_labels = train_data[1:]\n    outputs = list()\n    output = saved_output\n    state = saved_state\n    for i in train_inputs:\n        output, state = lstm_cell(i, output, state)\n        outputs.append(output)\n    with tf.control_dependencies([saved_output.assign(output), saved_state.assign(state)]):\n        logits = tf.nn.xw_plus_b(tf.concat(outputs, 0), w, b)\n        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf.concat(train_labels, 0), logits=logits))\n    global_step = tf.Variable(0)\n    learning_rate = tf.train.exponential_decay(10.0, global_step, 5000, 0.1, staircase=True)\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n    gradients, v = zip(*optimizer.compute_gradients(loss))\n    gradients, _ = tf.clip_by_global_norm(gradients, 1.25)\n    optimizer = optimizer.apply_gradients(zip(gradients, v), global_step=global_step)\n    train_prediction = tf.nn.softmax(logits)\n    sample_input = tf.placeholder(tf.float32, shape=[1, vocabulary_size])\n    saved_sample_output = tf.Variable(tf.zeros([1, num_nodes]))\n    saved_sample_state = tf.Variable(tf.zeros([1, num_nodes]))\n    reset_sample_state = tf.group(saved_sample_output.assign(tf.zeros([1, num_nodes])), saved_sample_state.assign(tf.zeros([1, num_nodes])))\n    sample_output, sample_state = lstm_cell(sample_input, saved_sample_output, saved_sample_state)\n    with tf.control_dependencies([saved_sample_output.assign(sample_output), saved_sample_state.assign(sample_state)]):\n        sample_prediction = tf.nn.softmax(tf.nn.xw_plus_b(sample_output, w, b))\n```'}, {'reason': 'stop', 'result': "```python\nconnection_all = []\nspecial_k = []\nmid_num = 10\nfor k in range(len(mapIdx)):\n    score_mid = paf_avg[:, :, [x - 19 for x in mapIdx[k]]]\n    candA = all_peaks[limbSeq[k][0] - 1]\n    candB = all_peaks[limbSeq[k][1] - 1]\n    nA = len(candA)\n    nB = len(candB)\n    indexA, indexB = limbSeq[k]\n    if nA != 0 and nB != 0:\n        connection_candidate = []\n        for i in range(nA):\n            for j in range(nB):\n                vec = np.subtract(candB[j][:2], candA[i][:2])\n                norm = math.sqrt(vec[0] * vec[0] + vec[1] * vec[1])\n                vec = np.divide(vec, norm)\n                startend = zip(np.linspace(candA[i][0], candB[j][0], num=mid_num), np.linspace(candA[i][1], candB[j][1], num=mid_num))\n                vec_x = np.array([score_mid[int(round(startend[I][1])), int(round(startend[I][0])), 0] for I in range(len(startend))])\n                vec_y = np.array([score_mid[int(round(startend[I][1])), int(round(startend[I][0])), 1] for I in range(len(startend))])\n                score_midpts = np.multiply(vec_x, vec[0]) + np.multiply(vec_y, vec[1])\n                score_with_dist_prior = sum(score_midpts) / len(score_midpts) + min(0.5 * oriImg.shape[0] / norm - 1, 0)\n                is_valid_connection = len(np.nonzero(score_midpts > param['thre2'])[0]) > 0.8 * len(score_midpts)\n                criterion2 = score_with_dist_prior > 0\n                if is_valid_connection and criterion2:\n                    connection_candidate.append([i, j, score_with_dist_prior, score_with_dist_prior + candA[i][2] + candB[j][2]])\n        connection_candidate = sorted(connection_candidate, key=lambda x: x[2], reverse=True)\n        connection = np.zeros((0, 5))\n        for c in range(len(connection_candidate)):\n            i, j, s = connection_candidate[c][0:3]\n            if i not in connection[:, 3] and j not in connection[:, 4]:\n                connection = np.vstack([connection, [candA[i][3], candB[j][3], s, i, j]])\n                if len(connection) >= min(nA, nB):\n                    break\n        connection_all.append(connection)\n    else:\n        special_k.append(k)\n        connection_all.append([])\n```"}, {'reason': 'stop', 'result': '```python\nfrom yellowbrick.text import FreqDistVisualizer\nplt.figure(figsize=(15, 20))\nplaylist_freq_dist_visualizer = FreqDistVisualizer(n=100, features=cv_description.get_feature_names())\n```'}, {'reason': 'stop', 'result': "```python\nbatch_size = 100\nepochs = 100\ngenerated_samples = []\nlosses = []\nsaver = tf.train.Saver(var_list=g_vars)\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    for e in range(epochs):\n        for ii in range(mnist.train.num_examples // batch_size):\n            batch = mnist.train.next_batch(batch_size)\n            batch_images = batch[0].reshape((batch_size, 784))\n            batch_images = batch_images * 2 - 1\n            batch_z = np.random.uniform(-1, 1, size=(batch_size, z_size))\n            _ = sess.run(d_train_opt, feed_dict={input_real: batch_images, input_z: batch_z})\n            _ = sess.run(g_train_opt, feed_dict={input_z: batch_z})\n        train_loss_d = sess.run(d_loss, {input_z: batch_z, input_real: batch_images})\n        train_loss_g = g_loss.eval({input_z: batch_z})\n        print('Epoch {}/{}...'.format(e + 1, epochs), 'Discriminator Loss: {:.4f}...'.format(train_loss_d), 'Generator Loss: {:.4f}'.format(train_loss_g))\n        losses.append((train_loss_d, train_loss_g))\n        sample_z = np.random.uniform(-1, 1, size=(16, z_size))\n        gen_samples = sess.run(generator(input_z, input_size, n_units=g_hidden_size, reuse=True, alpha=alpha), feed_dict={input_z: sample_z})\n        generated_samples.append(gen_samples)\n        saver.save(sess, './checkpoints/generator.ckpt')\nwith open('train_samples.pkl', 'wb') as f:\n    pkl.dump(generated_samples, f)\n```"}, {'reason': 'stop', 'result': '```python\ntraining_tags = (tag for i, (word, tag) in enumerate(data.training_set.stream()))\nwords = (word for i, (word, tag) in enumerate(data.training_set.stream()))\nprint(type(training_tags))\nprint(type(words))\n```'}, {'reason': 'stop', 'result': "```python\nheight = 28\nwidth = 28\nchannels = 1\nn_inputs = height * width\nconv1_fmaps = 32\nconv1_ksize = 3\nconv1_stride = 1\nconv1_pad = 'SAME'\nconv2_fmaps = 64\nconv2_ksize = 3\nconv2_stride = 2\nconv2_pad = 'SAME'\npool3_fmaps = conv2_fmaps\nn_fc1 = 64\nn_outputs = 10\nreset_graph()\nwith tf.name_scope('inputs'):\n    X = tf.placeholder(tf.float32, shape=[None, n_inputs], name='X')\n    X_reshaped = tf.reshape(X, shape=[-1, height, width, channels])\n    y = tf.placeholder(tf.int32, shape=[None], name='y')\nconv1 = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps, kernel_size=conv1_ksize, strides=conv1_stride, padding=conv1_pad, activation=tf.nn.relu, name='conv1')\nconv2 = tf.layers.conv2d(conv1, filters=conv2_fmaps, kernel_size=conv2_ksize, strides=conv2_stride, padding=conv2_pad, activation=tf.nn.relu, name='conv2')\nwith tf.name_scope('pool3'):\n    pool3 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n    pool3_flat = tf.reshape(pool3, shape=[-1, pool3_fmaps * 7 * 7])\nwith tf.name_scope('fc1'):\n    fc1 = tf.layers.dense(pool3_flat, n_fc1, activation=tf.nn.relu, name='fc1')\nwith tf.name_scope('output'):\n    logits = tf.layers.dense(fc1, n_outputs, name='output')\n    Y_proba = tf.nn.softmax(logits, name='Y_proba')\nwith tf.name_scope('train'):\n    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n    loss = tf.reduce_mean(xentropy)\n    optimizer = tf.train.AdamOptimizer()\n    optimizer_minimization_op = optimizer.minimize(loss)\nwith tf.name_scope('eval'):\n    correct = tf.nn.in_top_k(logits, y, 1)\n    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\nwith tf.name_scope('init_and_save'):\n    init = tf.global_variables_initializer()\n    saver = tf.train.Saver()\n```"}, {'reason': 'stop', 'result': "```python\nmy_testword = 'CHOCOLATE'\nsign_language_model, logL = train_a_word(my_testword, 3, features_ground)\nshow_model_stats(my_testword, sign_language_model)\nprint('logL = {}'.format(logL))\n```"}, {'reason': 'stop', 'result': "```python\ncorpus = 'BrentProvidence'\nprovidence_data_file = os.path.join('data/words_sentences/providence_avg_prosody_pos.csv')\nbrent_data_file = os.path.join('data/words_sentences/brent_avg_prosody_pos.csv')\nboth_data_file = os.path.join('data/words_sentences/brentprovidence_avg_prosody_pos.csv')\nfeatures = list(range(1, 93))\npos_filter = None\ntarget_variable = 'y'\nprint('extracting providence...')\nprovidence_x_train, providence_y_train, _, _, _, _, labels = get_data_from_tsv(providence_data_file, x_fields=features, y_field=target_variable, x_filter=pos_filter, train_portion=1.0, shuffle=False)\nprint('extracting brent...')\nbrent_x_train, brent_y_train, _, _, _, _, labels = get_data_from_tsv(brent_data_file, x_fields=features, y_field=target_variable, x_filter=pos_filter, train_portion=1.0, shuffle=False)\nprint('extracting brentprovidence...')\nboth_x_train, both_y_train, _, _, _, _, labels = get_data_from_tsv(both_data_file, x_fields=features, y_field=target_variable, x_filter=pos_filter, train_portion=1.0, shuffle=False)\nif corpus == 'Providence':\n    x_train = providence_x_train\n    y_train = providence_y_train\nelif corpus == 'Brent':\n    x_train = brent_x_train\n    y_train = brent_y_train\nelif corpus == 'BrentProvidence':\n    x_train = both_x_train\n    y_train = both_y_train\nfirst_numeric_feature = x_train.columns.tolist().index('log_length')\nfirst_egemaps_feature = x_train.columns.tolist().index('F0semitoneFrom27.5Hz_sma3nz_amean')\nprint(first_numeric_feature, first_egemaps_feature)\n```"}, {'reason': 'stop', 'result': "```python\nX, Annotations = marconi['Soccer']\ncamera = 3\nframe = 79\nfig = plt.figure(figsize=(16, 8))\nax = fig.add_subplot(111)\nim = X[camera, frame]\nax.imshow(im)\nAnnotations_for_cam = Annotations[camera]\nAnnot_on_frame_cam = Annotations_for_cam[frame]\nCOLORS = ['red', 'yellow']\nfor i, ((tl, br), joints) in enumerate(Annot_on_frame_cam):\n    head_x, head_y_coordinate = utils.tl_br_to_plt_plot(tl[1], tl[0], br[1], br[0])\n    ax.plot(head_x, head_y_coordinate, color=COLORS[i])\n    for jx, jy, visible in joints:\n        plt.scatter(jx, jy, color=COLORS[i], alpha=1 if visible == 1 else 0.4)\nplt.axis('off')\nplt.show()\n```"}, {'reason': 'stop', 'result': "```python\nnum_steps = 100001\nwith tf.Session(graph=graph) as session:\n    tf.global_variables_initializer().run()\n    print('Initialized')\n    average_loss = 0\n    for step in range(num_steps):\n        batch_data, batch_labels = generate_batch(batch_size, num_skips, skip_window)\n        feed_dict = {train_dataset: batch_data, train_labels: batch_labels}\n        _, l = session.run([optimizer, loss], feed_dict=feed_dict)\n        average_loss += l\n        if step % 2000 == 0:\n            if step > 0:\n                average_loss = average_loss / 2000\n            print('Average loss at step %d: %f' % (step, average_loss))\n            average_loss = 0\n        if step % 10000 == 0:\n            sim = similarity.eval()\n            for i in range(valid_size):\n                valid_word = reverse_dictionary[valid_examples[i]]\n                top_k = 8\n                nearest_words_indices = (-sim[i, :]).argsort()[1:top_k + 1]\n                log = 'Nearest to %s:' % valid_word\n                for k in range(top_k):\n                    close_word = reverse_dictionary[nearest_words_indices[k]]\n                    log = '%s %s,' % (log, close_word)\n                print(log)\n    final_embeddings = normalized_embeddings.eval()\n```"}, {'reason': 'stop', 'result': "```python\nnon_pid_features = []\nnot_pid_importances = []\nfor feature in feature_names:\n    if 'playlist_pid' not in feature:\n        non_pid_features.append(feature)\n        idx = feature_names.index(feature)\n        not_pid_importances.append(top50importance[idx])\n```"}, {'reason': 'stop', 'result': '```python\nml_project_description = None\npreds = None\ncenters = None\nsample_preds = None\nscore = None\n```'}, {'reason': 'stop', 'result': '```python\nimport pyprind\npbar = pyprind.ProgBar(45)\nclasses = np.array([0, 1])\nfor _ in range(45):\n    minibatch_data, y_train = get_minibatch(doc_stream, size=1000)\n    if not minibatch_data:\n        break\n    minibatch_data = vect.transform(minibatch_data)\n    clf.partial_fit(minibatch_data, y_train, classes=classes)\n    pbar.update()\n```'}, {'reason': 'stop', 'result': "```python\ndef build_index(non_empty_days, from_time, to_time):\n    date_ranges = []\n    for date in non_empty_days:\n        yyyy, mm, dd = date.split('-')\n        from_hour, from_min = from_time.split(':')\n        to_hour, to_min = to_time.split(':')\n        datetime_range = datetime(int(yyyy), int(mm), int(dd), int(from_hour), int(from_min), 0)\n        t2 = datetime(int(yyyy), int(mm), int(dd), int(to_hour), int(to_min), 0)\n        date_ranges.append(pd.DataFrame({'OrganizedDateTime': pd.date_range(datetime_range, t2, freq='1Min').values}))\n    agg = pd.concat(date_ranges, axis=0)\n    agg.index = agg['OrganizedDateTime']\n    return agg\n```"}, {'reason': 'stop', 'result': '```python\ndef rbg_to_hls(img):\n    """ \n    Takes an RGB image and converts it to HLS.\n    Returns the converted image (3 channels)\n    """\n    hls_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n    return hls_image\n\ndef merge_channels(images):\n    """\n    Merge images from three different channels\n     - images: a list of 3 images, each in a channel\n    """\n    merged = weighted_img(images[0], images[1], α=0.5, β=0.5, λ=0.0)\n    merged = weighted_img(merged, images[2], α=1.0, β=0.5, λ=0.0)\n    return merged\n\ndef lane_detection_ppline_3_channels(image, k_size=3, vertex_ratio_h=0.45, vertex_ratio_v=0.6, low_thresh=50, high_thresh=200, L2gradient=False, rho=2, theta=1 * np.pi / 180.0, min_votes=15, min_line_len=40, max_line_gap=20, angle=3 * np.pi / 16, angle_thresh=np.pi / 16, debug=False):\n    """\n    Takes an image and parameters and applies the lane detection pipeline.\n    Returns an image combining the original and the extended lines detected\n    by the algorithm.\n     - debug: Whether or not to display the images after each step of the process, for\n     debugging or tuning purposes.\n    """\n    max_y, max_x = image.shape[:2]\n    roi = np.array([[(0, max_y), (round(max_x * vertex_ratio_h), round(max_y * vertex_ratio_v)), (round(max_x * (1 - vertex_ratio_h)), round(max_y * vertex_ratio_v)), (max_x, max_y)]])\n    if debug:\n        plt.subplot(5, 3, 1)\n        plt.imshow(image)\n    blurred_image = gaussian_blur(image, k_size)\n    if debug:\n        plt.subplot(5, 3, 2)\n        plt.imshow(blurred_image)\n    hls = rbg_to_hls(blurred_image)\n    if debug:\n        plt.subplot(5, 3, 3)\n        plt.imshow(hls)\n    edges_list = []\n    for chan in range(0, 3):\n        edges_list.append(canny(hls[:, :, chan], low_thresh, high_thresh, L2gradient=L2gradient))\n        if debug:\n            plt.subplot(5, 3, chan + 4)\n            plt.imshow(edges_list[chan])\n    masked_edges_list = []\n    for chan in range(0, 3):\n        masked_edges_list.append(region_of_interest(edges_list[chan], roi))\n        if debug:\n            plt.subplot(5, 3, chan + 7)\n            plt.imshow(masked_edges_list[chan])\n    lines_list = []\n    for chan in range(0, 3):\n        lines_list.append(hough_lines(masked_edges_list[chan], rho, theta, min_votes, min_line_len, max_line_gap))\n        if debug:\n            plt.subplot(5, 3, chan + 10)\n            plt.imshow(lines_list[chan][0])\n    lines = np.zeros((1, 1, 4))\n    for chan in range(0, 3):\n        lines = np.concatenate((lines, lines_list[chan][1]), axis=0)\n    if debug:\n        hls_lines_image = merge_channels([lines_list[0][0], lines_list[1][0], lines_list[2][0]])\n        plt.subplot(5, 3, 13)\n        plt.imshow(hls_lines_image)\n    try:\n        combined = extend_lines(image, lines, angle=angle, angle_thresh=angle_thresh)\n        if debug:\n            plt.subplot(5, 3, 14)\n            plt.imshow(combined)\n    except IndexError:\n        print(\'Error. Try relaxing your angle parameters a litte.\')\n    return combined\n\ndef process_image_3_channels(image, k_size=3, vertex_ratio_h=0.45, vertex_ratio_v=0.6, low_thresh=50, high_thresh=200, L2gradient=False, rho=2, theta=1 * np.pi / 180.0, min_votes=15, min_line_len=40, max_line_gap=20, angle=3 * np.pi / 16, angle_thresh=np.pi / 16, debug=False):\n    hours_scores_correlation = lane_detection_ppline_3_channels(image, k_size=k_size, low_thresh=low_thresh, high_thresh=high_thresh, L2gradient=L2gradient, rho=rho, theta=theta, min_votes=min_votes, min_line_len=min_line_len, max_line_gap=max_line_gap, angle=angle, angle_thresh=angle_threshold, debug=debug)\n    return hours_scores_correlation\n```'}, {'reason': 'stop', 'result': "```python\norientation_collection = path.join(DATA, 'field-orientations.geojson')\nwith fiona.open(orientation_collection) as ds:\n    for i, item in ds.items():\n        p = item['properties']\n        if p['planeType'].strip() != 'Bedding':\n            continue\n        asm = p.get('aster_smoothed')\n        alt = asm\n        alt -= 40\n        center = (*item['geometry']['coordinates'], alt)\n        err = 0.1 * N.pi / 180\n        a = ReconstructedPlane(p['strike'], p['dip'], 0, err, err)\n        orientation = a.to_mapping(center=center, color='#444', type='in-situ')\n        collection.append(orientation)\nremovedUIDs = ['89636280', '6031fd6f']\ncollection = [c for c in collection if 1600 < c['center'][2] < 1680]\ncollection = [c for c in collection if c['uid'] not in removedUIDs]\n```"}, {'reason': 'stop', 'result': "```python\nnodes = [ST, F, C, W, f_I, f_ST, f_F, f_C, f_W, I, B, f_B, S, f_S]\nfor n in nodes:\n    n.reset()\nC.pending.add(f_C)\nW.pending.add(f_W)\nf_I.pending.add(I)\nf_S.pending.add(S)\nST.pending.add(f_ST)\nF.pending.add(f_F)\nmax_sum(nodes)\nI_ulm = I.unnormalized_log_marginal()\nS_ulm = S.unnormalized_log_marginal()\nstate_variable_ulm = ST.unnormalized_log_marginal()\nF_ulm = F.unnormalized_log_marginal()\nB_ulm = B.unnormalized_log_marginal()\nC_ulm = C.unnormalized_log_marginal()\nW_ulm = W.unnormalized_log_marginal()\nprint('I', I_ulm)\nprint('S', S_ulm)\nprint('ST', state_variable_ulm)\nprint('F', F_ulm)\nprint('B', B_ulm)\nprint('C', C_ulm)\nprint('W', W_ulm)\n```"}, {'reason': 'stop', 'result': "```python\ndef r2(labels, predictions):\n    mean_labels = tf.reduce_mean(labels)\n    total_sum_squares = tf.reduce_sum((labels - mean_labels) ** 2)\n    residual_sum_squares = tf.reduce_sum((labels - predictions) ** 2)\n    r2_score = 1 - residual_sum_squares / total_sum_squares\n    return r2_score\npreds = model.predict(X)\nr2_score = r2(y, preds)\nprint('R2 score: ', r2_score.numpy())\n```"}, {'reason': 'stop', 'result': "```python\nfrom numpy import ma\nU = paf_avg[:, :, 16] * -1\npart_affinity_fields = paf_avg[:, :, 17]\nX, Y = np.meshgrid(np.arange(U.shape[1]), np.arange(U.shape[0]))\nM = np.zeros(U.shape, dtype='bool')\nM[U ** 2 + part_affinity_fields ** 2 < 0.3 * 0.3] = True\nU = ma.masked_array(U, mask=M)\npart_affinity_fields = ma.masked_array(part_affinity_fields, mask=M)\nplt.figure()\nplt.imshow(oriImg[:, :, [2, 1, 0]], alpha=0.5)\ns = 5\nQ = plt.quiver(X[::s, ::s], Y[::s, ::s], U[::s, ::s], part_affinity_fields[::s, ::s], scale=50, headaxislength=4, alpha=0.5, width=0.001, color='r')\nfig = matplotlib.pyplot.gcf()\nfig.set_size_inches(10, 10)\n```"}, {'reason': 'stop', 'result': "```python\nfrom keras import optimizers\nsgd = optimizers.SGD(lr=0.001, decay=1e-06, momentum=0.9, nesterov=True)\nimage_classification_optimizer = optimizers.RMSprop(lr=0.0001)\nVGG16Seq.compile(optimizer=image_classification_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n```"}, {'reason': 'stop', 'result': "```python\nbarwidth = 0.75\nfig, ax = plt.subplots(figsize=(9, 7))\nrects1 = ax.bar(0.5, RTanalysis.Valid.mean(), barwidth, yerr=RTstderror.Valid, ecolor='k', edgecolor=sns.xkcd_rgb['green'], linewidth=2, facecolor='none', error_kw=dict(lw=3))\nstimulus_control_association = ax.bar(1.5, RTanalysis.Invalid.mean(), barwidth, color=sns.xkcd_rgb['green'], yerr=RTstderror.Invalid, ecolor='k', error_kw=dict(lw=3))\nsns.set(context='notebook', style='white', font='Myriad Pro', font_scale=2, color_codes=False, rc=None)\nax.set_ylim(550, 610)\nax.set_xlim(0, 2.5)\nax.set_xticklabels(('Valid', 'Invalid'))\nax.set_xticks([0.5 + barwidth / 2, 1.5 + barwidth / 2])\nax.set_yticks(np.arange(550, 611, 10))\nplt.title('S-S Phase RT', fontsize=26, fontweight='bold')\nplt.ylabel('Reaction Time (ms)', fontsize=24, fontweight='bold')\nplt.xlabel('Trial Type', fontsize=24, fontweight='bold')\nsns.despine()\nplt.show()\n```"}, {'reason': 'stop', 'result': '```python\ndef lane_detection(image):\n    gray = grayscale(image)\n    blur_radius = 5\n    blur_gray = gaussian_blur(gray, 5)\n    low_threshold = 60\n    high_threshold = 180\n    edges = canny(blur_gray, low_threshold, high_threshold)\n    imshape = image.shape\n    vertices = np.array([[(0, imshape[0]), (450, 320), (490, 320), (imshape[1], imshape[0])]], dtype=np.int32)\n    masked_edges = region_of_interest(edges, vertices)\n    rho = 2\n    theta = np.pi / 180\n    threshold = 15\n    min_line_len = 40\n    max_line_gap = 20\n    line_image = hough_lines(masked_edges, rho, theta, threshold, min_line_len, max_line_gap)\n    color_edges = np.dstack((edges, edges, edges))\n    lines_edges = weighted_img(line_image, image, α=0.8, β=1.0, λ=0.0)\n    return lines_edges\n```'}, {'reason': 'stop', 'result': "```python\ngraduation_esl_plot, ax1 = plt.subplots()\ntick_locations = [value for value in x_axis]\nplt.xticks(tick_locations, county, rotation=90)\ngrad_rate = df_county_data['Graduation Rate']\ncounty = df_county_data['County Name']\npov_rate = df_county_data['Speak a language other than English']\nt = np.arange(len(county))\nax1.plot(t, pov_rate, 'b-')\nax1.set_xlabel('county')\nax1.set_ylabel('Speak a language other than English', color='b')\nax1.tick_params('y', colors='b')\nplt.title('High School Graduation Rates and ESL by County')\nax2 = ax1.twinx()\nax2.plot(t, grad_rate, 'r*')\nax2.set_ylabel('Graduation Rate', color='r')\nax2.tick_params('y', colors='r')\nzoom = 5\nw, h = graduation_esl_plot.get_size_inches()\ngraduation_esl_plot.set_size_inches(w * zoom, h * zoom / 2)\ngraduation_esl_plot.tight_layout()\nplt.savefig('Images/County_Grad_Speak a language other than English2.png', bbox_inches='tight')\nplt.show()\n```"}, {'reason': 'stop', 'result': '```python\ndef estimate_anottation_correct(img, coords, line_width=2, threshold=0.8):\n    """Make histograms of boundaries to estimate annotation error\n    (if boundaries are blank, high chance of dumb walk failure)"""\n    total = 0\n    cont = 0\n    xleft, ytop, xright, ybottom = [int(c) for c in coords]\n    leftside = img[ytop:ybottom, xleft:xleft + line_width - 1]\n    rightside = img[ytop:ybottom, xright - line_width:xright]\n    annotation_boundary_img = img[ytop:ytop + line_width - 1, xleft:xright]\n    bottomside = img[ybottom - line_width:ybottom, xleft:xright]\n    total = leftside.sum() + rightside.sum()\n    cont = leftside.size + rightside.size\n    \'for y in range(ytop, ybottom):\\n        for x in range(xleft, xright):\\n            total += img[y, xleft:xleft + line_width].sum()  # Left side\\n            total += img[y, xright - line_width:xright].sum()  # Right side\\n            total += img[ytop:ytop + line_width, x].sum()  # Top side\\n            total += img[ybottom - line_width:ybottom, x].sum()  # Bottom side\\n            cont +=1\\n    \'\n    percent_black = total / cont\n    return int(percent_black)\n```'}, {'reason': 'stop', 'result': '```python\nfeature_layer_coll_item = feature_layer_srch_results[0]\nfeature_layers = feature_layer_coll_item.layers\nfirst_feature_layer = feature_layers[0]\nfirst_feature_layer.properties.name\n```'}, {'reason': 'stop', 'result': "```python\nverbose = False\nfor i, f in enumerate(spectral_template):\n    spectral_template[i] = f.replace(b'SDSS', b'LSST').replace(b'BessellV', b'LSST_g')\nif verbose:\n    print(mjdmax)\n    print(mjd_to_sim)\n    print(spectral_template)\n```"}, {'reason': 'stop', 'result': '```python\ndef calc_other_neighbour_msg_prod(sender, receiver):\n    neighbour_message_product = get_neighbour_messages(sender, receiver)\n    return np.multiply.reduce(np.ix_(*neighbour_message_product))\n```'}, {'reason': 'stop', 'result': "```python\nimport numpy as np\nfrom scipy.special import expit\nn = 100\nxs = np.linspace(-3, 3, n)\nReLu = np.maximum(xs, 0)\nd_ReLu = np.concatenate((np.zeros(int(n / 2)), np.ones(int(n / 2))))\ntanh = np.tanh(xs)\ntanh_derivative = 1 - tanh ** 2\nsig = expit(xs)\nd_sig = sig * (1 - sig)\nplt.figure(figsize=(20, 5))\nplt.subplot(1, 3, 1)\nplt.plot(xs, ReLu, label='ReLu')\nplt.plot(xs, d_ReLu, label='d_Relu')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('ReLu(x) Plot')\nplt.ylim(-1.1, 1.1)\nplt.legend()\nplt.subplot(1, 3, 2)\nplt.plot(xs, tanh, label='tanh')\nplt.plot(xs, tanh_derivative, label='d_tanh')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('tanh(x) Plot')\nplt.ylim(-1.1, 1.1)\nplt.legend()\nplt.subplot(1, 3, 3)\nplt.plot(xs, sig, label='sigmoid')\nplt.plot(xs, d_sig, label='d_sigmoid')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Sigmoid(x) Plot')\nplt.ylim(-1.1, 1.1)\nplt.legend()\nplt.suptitle('Activation functions')\nplt.show()\n```"}, {'reason': 'stop', 'result': "```python\nimage_data = X[:, -1::-1][-1::-1, :]\nplt.imshow(image_data, interpolation='nearest', cmap=plt.cm.gray)\n```"}, {'reason': 'stop', 'result': "```python\nimport os\nimport sys\nimport tarfile\nimport time\ndata_download_url = 'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\ntarget = 'aclImdb_v1.tar.gz'\n\ndef reporthook(count, block_size, total_size):\n    global start_time\n    if count == 0:\n        start_time = time.time()\n        return\n    duration = time.time() - start_time\n    progress_size = int(count * block_size)\n    speed = progress_size / (1024.0 ** 2 * duration)\n    percent = count * block_size * 100.0 / total_size\n    sys.stdout.write('\\r%d%% | %d MB | %.2f MB/s | %d sec elapsed' % (percent, progress_size / 1024.0 ** 2, speed, duration))\n    sys.stdout.flush()\nif not os.path.isdir('aclImdb') and (not os.path.isfile('aclImdb_v1.tar.gz')):\n    if sys.version_info < (3, 0):\n        import urllib\n        urllib.urlretrieve(data_download_url, target, reporthook)\n    else:\n        import urllib.request\n        urllib.request.urlretrieve(data_download_url, target, reporthook)\n```"}, {'reason': 'stop', 'result': "```python\npileUp_filter_efficiency_MC = 'pileUpFilterEfficiency_MC.png'\nDATA_fraction = 'pileUpFilterEfficiency_DATA.png'\nImage(filename=pathname + pileUp_filter_efficiency_MC)\n```"}, {'reason': 'stop', 'result': "```python\ncols = ['SAT Math Avg. Score', 'SAT Critical Reading Avg. Score', 'SAT Writing Avg. Score']\nfor c in cols:\n    data['sat_results'][c] = pd.to_numeric(data['sat_results'][c], errors='coerce')\ndata['sat_results']['sat_score'] = data['sat_results'][cols[0]] + data['sat_results'][cols[1]] + data['sat_results'][cols[2]]\n\ndef find_lat(loc):\n    coords = re.findall('\\\\(.+, .+\\\\)', loc)\n    lat = coords[0].split(',')[0].replace('(', '')\n    return lat\n\ndef find_lon(loc):\n    coords = re.findall('\\\\(.+, .+\\\\)', loc)\n    longitude = coords[0].split(',')[1].replace(')', '').strip()\n    return longitude\ndata['hs_directory']['lat'] = data['hs_directory']['Location 1'].apply(find_lat)\ndata['hs_directory']['lon'] = data['hs_directory']['Location 1'].apply(find_lon)\ndata['hs_directory']['lat'] = pd.to_numeric(data['hs_directory']['lat'], errors='coerce')\ndata['hs_directory']['lon'] = pd.to_numeric(data['hs_directory']['lon'], errors='coerce')\n```"}, {'reason': 'stop', 'result': '```python\nsubset_indices = 200\ndataset_subset_indices = get_balanced_subset_indices(data_test.gt_patches.flatten(), np.arange(1, 9), pts_per_class=subset_indices)\ndataset_subset_indices = np.concatenate(dataset_subset_indices)\n```'}, {'reason': 'stop', 'result': '```python\nactivation_train = get_activations_batch(model_unet, -2, data_train_overlap.im_patches, 20, verbose=True)\nactivation_train = remove_overlap(data_train.imgs, activation_train, patch_size=64, stride=32)\nact_train = activation_train[pred_t_tr]\n```'}, {'reason': 'stop', 'result': '```python\npower_of_3, x3, x4 = powers(3)\nprint(x3)\n```'}, {'reason': 'stop', 'result': "```python\nreload(pccsims)\ncoco = pccsims.pyCoCo(pcc.utils.b(filter_path), pcc.utils.b(coco_root_path))\nflux, spectral_simulation_results = coco.simulate(b'SN2007uy', z_obs, 0.0, 0.0, 0.0, 3.1, mjdmax, mjd_to_sim, filters_to_sim)\n```"}, {'reason': 'stop', 'result': "```python\nSkyPresence = posttest.groupby(['subjID'])['Q2_SceneSkyPresence'].mean()\nSkyPresenceSEM = pd.Series.std(SkyPresence) / n\nColorScheme = posttest.groupby(['subjID'])['Q2_SceneColorScheme'].mean()\ncolor_scheme_std_dev = pd.Series.std(ColorScheme) / n\nTreeFreq = posttest.groupby(['subjID'])['Q2_SceneTreeFrequency'].mean()\nTreeFreqSEM = pd.Series.std(TreeFreq) / n\nImageType = posttest.groupby(['subjID'])['Q2_ImageType'].mean()\nImageTypeSEM = pd.Series.std(ImageType) / n\nFeatureType = posttest.groupby(['subjID'])['Q2_FeatureType'].mean()\nFeatureTypeSEM = pd.Series.std(FeatureType) / n\nLightType = posttest.groupby(['subjID'])['Q2_LightType'].mean()\nLightTypeSEM = pd.Series.std(LightType) / n\n```"}, {'reason': 'stop', 'result': "```python\nlog_transformed_data = np.log(data.copy())\nlog_data2 = np.log(data2.copy())\nlog_samples = np.log(samples.copy())\npd.scatter_matrix(log_data2, alpha=0.3, figsize=(14, 8), diagonal='kde')\n```"}, {'reason': 'stop', 'result': "```python\ndef validate_hypothesis(model, diag_classifier, hypothesis, train_len=50, test_len=1, text_len=500, temperature=0.8, save_hyp=None, save_diag=None, save_resp=None):\n\n    def gen_hyp_data(model, N, text_len=500):\n        texts, hiddens, generated_variable_definitions = ([], [], [])\n        for i in range(N):\n            text, variable_def = generate(model, '\\n\\n', text_len, temperature, True)\n            variable_def = variable_def.reshape(variable_def.shape[0], -1)\n            hyp = hypothesis(text)\n            hiddens.append(variable_def)\n            generated_variable_definitions.append(hyp)\n            texts.append(text)\n        return (''.join(texts), np.concatenate(generated_variable_definitions), np.concatenate(hiddens))\n    _, train_hyps, train_hiddens = gen_hyp_data(model, train_len)\n    test_texts, test_hyps, test_hiddens = gen_hyp_data(model, test_len)\n    print(pearsonr(train_hiddens, train_hyps))\n    print(pearsonr(test_hiddens, test_hyps))\n    diag_classifier.fit(train_hiddens, train_hyps)\n    pred_hyps = diag_classifier.predict(test_hiddens)\n    resp_neuron = np.argmax(np.abs(diag_classifier.coef_))\n    print(resp_neuron)\n    if save_hyp:\n        plot_colored_text(test_texts[:text_len], test_hyps[:text_len], title='Formed Hypothesis', save_file=save_hyp)\n    if save_diag:\n        plot_colored_text(test_texts[:text_len], pred_hyps[:text_len], title='Diagnostic Classifier Prediction', save_file=save_diag)\n    if save_resp:\n        plot_colored_text(test_texts[:text_len], test_hiddens[:text_len, resp_neuron], title='Most Responsible Neuron {}'.format(resp_neuron), save_file=save_resp)\n    del train_hyps\n    del train_hiddens\n    del test_texts\n    del test_hiddens\n    gc.collect()\n    return (test_hyps, pred_hyps)\n```"}, {'reason': 'stop', 'result': "```python\nt_min_max = (msig.timestamps[0], msig.timestamps[-1])\nx_test, generated_data = msig.generate()\nprint(x_test.shape)\nprint(generated_data.shape)\nscore = model.evaluate(x_test, generated_data, batch_size=batch_size)\nmodel.reset_states()\nprint(score)\ny_hat = model.predict(x_test, batch_size=batch_size)\ny_pred = np.argmax(y_hat, axis=1)\nmodel.reset_states()\nprint(y_pred.shape)\nfig, ax = plt.subplots(nrows=2, ncols=1, figsize=(15, 6))\nax[0].plot(msig.timestamps, msig.mixed_signal, color='grey', alpha=0.3)\nax[0].scatter(msig.timestamps, msig.mixed_signal, marker='.')\nax[0].set_title('loss = {:<6.4f}, accuracy = {:<6.4f}'.format(*score))\nax[0].set_xlim(t_min_max)\nax[1].plot(msig.timestamps[msig.window_size - 1:], x_test[:, -1, 0], color='grey', alpha=0.3)\nax[1].scatter(msig.timestamps[msig.window_size - 1:], x_test[:, -1, 0], marker='.', c=y_pred)\nax[1].set_xlim(t_min_max)\nax[1].set_xlabel('time')\nplt.show()\n```"}, {'reason': 'stop', 'result': '```python\ndef padRightDownCorner(img, stride, padValue):\n    h = img.shape[0]\n    w = img.shape[1]\n    pad = 4 * [None]\n    pad[0] = 0\n    pad[1] = 0\n    pad[2] = 0 if h % stride == 0 else stride - h % stride\n    pad[3] = 0 if w % stride == 0 else stride - w % stride\n    img_padded = img\n    pad_up = np.tile(img_padded[0:1, :, :] * 0 + padValue, (pad[0], 1, 1))\n    img_padded = np.concatenate((pad_up, img_padded), axis=0)\n    pad_left = np.tile(img_padded[:, 0:1, :] * 0 + padValue, (1, pad[1], 1))\n    img_padded = np.concatenate((pad_left, img_padded), axis=1)\n    padded_image = np.tile(img_padded[-2:-1, :, :] * 0 + padValue, (pad[2], 1, 1))\n    img_padded = np.concatenate((img_padded, padded_image), axis=0)\n    pad_right = np.tile(img_padded[:, -2:-1, :] * 0 + padValue, (1, pad[3], 1))\n    img_padded = np.concatenate((img_padded, pad_right), axis=1)\n    return (img_padded, pad)\n\nclass DataBatch(object):\n\n    def __init__(self, data, label, pad=0):\n        self.data = [data]\n        self.label = [label]\n        self.pad = pad\n```'}, {'reason': 'stop', 'result': "```python\nfrom tensorflow.python.framework import ops\nops.reset_default_graph()\nbatch_size = 16\npatch_size = 5\ndepth = 16\nnum_hidden = 64\ngraph = tf.Graph()\nwith graph.as_default():\n    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n    tf_valid_dataset = tf.constant(valid_dataset)\n    tf_test_dataset = tf.constant(test_dataset)\n    layer1_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, num_channels, depth], stddev=0.1))\n    layer1_biases = tf.Variable(tf.zeros([depth]))\n    layer2_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth, depth], stddev=0.1))\n    layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n    layer3_weights = tf.Variable(tf.truncated_normal([image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n    layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n    layer4_weights = tf.Variable(tf.truncated_normal([num_hidden, num_labels], stddev=0.1))\n    layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n\n    def model(data):\n        conv = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')\n        pool = tf.nn.max_pool(conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n        hidden = tf.nn.relu(pool + layer1_biases)\n        conv = tf.nn.conv2d(hidden, layer2_weights, [1, 1, 1, 1], padding='SAME')\n        pool = tf.nn.max_pool(conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n        hidden = tf.nn.relu(pool + layer2_biases)\n        shape = hidden.get_shape().as_list()\n        reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n        hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n        return tf.matmul(hidden, layer4_weights) + layer4_biases\n    logits = model(tf_train_dataset)\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n    optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n    train_prediction = tf.nn.softmax(logits)\n    valid_dataset_predictions = tf.nn.softmax(model(tf_valid_dataset))\n    test_prediction = tf.nn.softmax(model(tf_test_dataset))\n```"}, {'reason': 'stop', 'result': '```python\ncolor_palette = [\'b\', \'g\', \'r\', \'k\', \'c\', \'m\', \'y\']\nindex = 0\nfor segment in segments:\n    segDF = data.loc[data[\'RiverSeg\'] == segment]\n    segDF = segDF[segDF["lam\'"] > 0]\n    segDF = segDF.sort_values(\'Year\')\n    x = segDF[\'Year\']\n    y = segDF["1-lam\'"]\n    y.name = segment\n    plt.plot(x, y, color_palette[index])\n    plt.legend(loc=(1.05, 0.2))\n    index += 1\nplt.title("1-Lambda\', " + river + \' River Segments\')\nplt.xlabel(\'Year\')\nplt.ylabel("1-Lambda\'")\nplt.xticks(np.arange(min(x), max(x) + 1, 1.0))\nplt.xticks(rotation=90)\nplt.savefig(output + \'\\\\\' + river + "_1-Lambda\'.png", bbox_inches=\'tight\', dpi=300, size=(2000, 2000))\nplt.show()\n```'}, {'reason': 'stop', 'result': '```python\nurl = \'http://mattmahoney.net/dc/\'\n\ndef maybe_download(filename, expected_bytes):\n    """Download a file if not present, and make sure it\'s the right size."""\n    if not os.path.exists(filename):\n        filename, _ = urlretrieve(url + filename, filename)\n    file_stats = os.stat(filename)\n    if file_stats.st_size == expected_bytes:\n        print(\'Found and verified %s\' % filename)\n    else:\n        print(file_stats.st_size)\n        raise Exception(\'Failed to verify \' + filename + \'. Can you get to it with a browser?\')\n    return filename\nfilename = maybe_download(\'text8.zip\', 31344016)\n```'}, {'reason': 'stop', 'result': "```python\nbatch_size = 128\nembedding_size = 128\nskip_window = 1\nnum_skips = 2\nvalid_size = 16\nvalid_window = 100\nvalid_examples = np.array(random.sample(range(valid_window), valid_size))\nnum_sampled = 64\ngraph = tf.Graph()\nwith graph.as_default(), tf.device('/cpu:0'):\n    train_dataset = tf.placeholder(tf.int32, shape=[batch_size])\n    train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n    valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n    embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n    softmax_weights = tf.Variable(tf.truncated_normal([vocabulary_size, embedding_size], stddev=1.0 / math.sqrt(embedding_size)))\n    softmax_biases = tf.Variable(tf.zeros([vocabulary_size]))\n    embed = tf.nn.embedding_lookup(embeddings, train_dataset)\n    loss = tf.reduce_mean(tf.nn.sampled_softmax_loss(weights=softmax_weights, biases=softmax_biases, inputs=embed, labels=train_labels, num_sampled=num_sampled, num_classes=vocabulary_size))\n    optimizer = tf.train.AdagradOptimizer(1.0).minimize(loss)\n    normalized_embeddings_magnitude = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n    normalized_embeddings = embeddings / normalized_embeddings_magnitude\n    valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings, valid_dataset)\n    similarity = tf.matmul(valid_embeddings, tf.transpose(normalized_embeddings))\n```"}, {'reason': 'stop', 'result': '```python\nbasic_model = HiddenMarkovModel(name=\'base-hmm-tagger\')\ntags = (tag for i, (word, tag) in enumerate(data.training_set.stream()))\nwords = (word for i, (word, tag) in enumerate(data.training_set.stream()))\nemission_counts = pair_counts(tags, words)\nstates = {}\nfor tag, word_dict in emission_counts.items():\n    emission_dict = defaultdict(float)\n    for word in word_dict.keys():\n        emission_dict[word] = emission_counts[tag][word] / tag_unigrams[tag]\n    emission_distribution = DiscreteDistribution(dict(emission_dict))\n    states[tag] = State(emission_distribution, name=tag)\nbasic_model.add_states(list(states.values()))\nfor tag in data.training_set.tagset:\n    state = states[tag]\n    basic_model.add_transition(basic_model.start, state, tag_starts[tag] / len(data.training_set))\n    basic_model.add_transition(state, basic_model.end, tag_ends[tag] / tag_unigrams[tag])\n    for next_tag in data.training_set.tagset:\n        next_state = states[next_tag]\n        basic_model.add_transition(state, next_state, tag_bigrams[tag, next_tag] / tag_unigrams[tag])\nbasic_model.bake()\nassert all((tag in set((s.name for s in basic_model.states)) for tag in data.training_set.tagset)), \'Every state in your network should use the name of the associated tag, which must be one of the training set tags.\'\nassert basic_model.edge_count() == 168, \'Your network should have an edge from the start node to each state, one edge between every \' + \'pair of tags (states), and an edge from each state to the end node.\'\nHTML(\'<div class="alert alert-block alert-success">Your HMM network topology looks good!</div>\')\n```'}, {'reason': 'stop', 'result': "```python\ncircle_indices, x = np.indices((600, 800))\nimg[(x - 450) ** 2 + (circle_indices - 350) ** 2 < 50 ** 2] = (1, 0, 0)\nplt.imshow(img, interpolation='bilinear')\n```"}, {'reason': 'stop', 'result': '```python\nnlay, nrow, ncol = (1, 1, 200)\ncell_width = 50.0\ndelc = 1.0\nh1 = 23.0\nh2 = 5.0\nx = np.arange(0.0, float(ncol) * cell_width, cell_width) + cell_width / 2.0\nibound = np.ones((nlay, nrow, ncol), dtype=np.int)\nibound[:, :, 0] = -1\nibound[:, :, -1] = -1\nbotm = 25 * np.ones((nlay + 1, nrow, ncol), dtype=np.float)\nbase = 20.0\nfor j in range(ncol):\n    botm[1, :, j] = base\n    if j + 1 in [40, 80, 120, 160]:\n        base -= 5\nstrt = h1 * np.ones((nlay, nrow, ncol), dtype=np.float)\nstrt[:, :, -1] = h2\n```'}, {'reason': 'stop', 'result': "```python\nfrom my_model_selectors import SelectorDIC\ntraining = asl.build_training(features_ground)\nsequences = training.get_all_sequences()\nXlengths = training.get_all_Xlengths()\nfor word in words_to_train:\n    start = timeit.default_timer()\n    model = SelectorDIC(sequences, Xlengths, word, min_n_components=2, max_n_components=15, random_state=14).select()\n    training_time = timeit.default_timer() - start\n    if model is not None:\n        print('Training complete for {} with {} states with time {} seconds'.format(word, model.n_components, training_time))\n    else:\n        print('Training failed for {}'.format(word))\n```"}, {'reason': 'stop', 'result': '```python\nsegment_image = get_segment_img(clusters_2, img, posterior_mu_2, mcmc=True)\n```'}, {'reason': 'stop', 'result': "```python\nsamples_percentage_df = samples.copy()\nsamples_percentage_df['Total'] = samples_percentage_df.sum(axis=1)\nsamples_percentage = samples.loc[:, 'Fresh':'Delicatessen'].div(samples_percentage_df['Total'], axis=0) * 100\nsamples_percentage['Total'] = samples_percentage.sum(axis=1)\nsamples_percentage\n```"}, {'reason': 'stop', 'result': "```python\nimg[...] = 0\nheart_mask = (x - 400) / 30\nY = -(y - 300) / 30\nheart = heart_mask ** 2 + (Y - 2 * (heart_mask ** 2 + np.abs(heart_mask) - 6) / (3 * (heart_mask ** 2 + np.abs(heart_mask) + 2))) ** 2 < 36\nimg[heart] = (1, 0, 0)\nplt.imshow(img, interpolation='bilinear')\n```"}, {'reason': 'stop', 'result': "```python\nimport tensorflow as tf\nheight = 28\nwidth = 28\nchannels = 1\nn_inputs = height * width\nconv1_fmaps = 32\nconv1_ksize = 3\nconv1_stride = 1\nconv1_pad = 'SAME'\nconv2_fmaps = 64\nconv2_ksize = 3\nconv2_stride = 1\nconv2_pad = 'SAME'\nconv2_dropout_rate = 0.25\npool3_fmaps = conv2_fmaps\nn_fc1 = 128\nfc1_dropout_rate = 0.5\nn_outputs = 10\nreset_graph()\nwith tf.name_scope('inputs'):\n    X = tf.placeholder(tf.float32, shape=[None, n_inputs], name='X')\n    X_reshaped = tf.reshape(X, shape=[-1, height, width, channels])\n    y = tf.placeholder(tf.int32, shape=[None], name='y')\n    training = tf.placeholder_with_default(False, shape=[], name='training')\nconv1 = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps, kernel_size=conv1_ksize, strides=conv1_stride, padding=conv1_pad, activation=tf.nn.relu, name='conv1')\nconv2 = tf.layers.conv2d(conv1, filters=conv2_fmaps, kernel_size=conv2_ksize, strides=conv2_stride, padding=conv2_pad, activation=tf.nn.relu, name='conv2')\nwith tf.name_scope('pool3'):\n    pool3 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n    pool3_flat = tf.reshape(pool3, shape=[-1, pool3_fmaps * 14 * 14])\n    pool3_flat_drop = tf.layers.dropout(pool3_flat, conv2_dropout_rate, training=training)\nwith tf.name_scope('fc1'):\n    fc1 = tf.layers.dense(pool3_flat_drop, n_fc1, activation=tf.nn.relu, name='fc1')\n    fc1_drop = tf.layers.dropout(fc1, fc1_dropout_rate, training=training)\nwith tf.name_scope('output'):\n    logits = tf.layers.dense(fc1, n_outputs, name='output')\n    Y_proba = tf.nn.softmax(logits, name='Y_proba')\nwith tf.name_scope('train'):\n    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n    loss = tf.reduce_mean(xentropy)\n    optimizer = tf.train.AdamOptimizer()\n    training_op = optimizer.minimize(loss)\nwith tf.name_scope('eval'):\n    correct = tf.nn.in_top_k(logits, y, 1)\n    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\nwith tf.name_scope('init_and_save'):\n    init = tf.global_variables_initializer()\n    saver = tf.train.Saver()\n```"}, {'reason': 'stop', 'result': "```python\noutput_directory = 'test_images_output'\nif not os.path.exists(output_directory):\n    os.makedirs(output_directory)\nlane_image = mpimg.imread('test_images/solidYellowLeft.jpg')\nprint('This image is:', type(lane_image), 'with dimensions:', lane_image.shape)\nplt.imshow(lane_image)\n```"}, {'reason': 'stop', 'result': "```python\ncolor_mapping = plt.cm.YlOrRd(1 - probas_gmm_c)[:, :3][dataset_subset_indices]\nc_thresh_t = plt.cm.YlOrRd((probas_gmm_c[dataset_subset_indices] < np.sort(probas_gmm_c[dataset_subset_indices])[200]) * 255)[:, :3]\nc_thresh_f = plt.cm.YlOrRd((probas_gmm_c[dataset_subset_indices] > np.sort(probas_gmm_c[dataset_subset_indices])[200]) * 255)[:, :3]\n_, axes = plt.subplots(1, 2, figsize=(20, 10))\naxes[0].scatter(tsne_all[:, 0][pred_t], tsne_all[:, 1][pred_t], c=color_mapping[pred_t], alpha=0.6)\naxes[1].scatter(tsne_all[:, 0][pred_t], tsne_all[:, 1][pred_t], c=c_thresh_t[pred_t])\naxes[0].scatter(tsne_all[:, 0][pred_f], tsne_all[:, 1][pred_f], c=color_mapping[pred_f], marker='x')\naxes[1].scatter(tsne_all[:, 0][pred_f], tsne_all[:, 1][pred_f], c=c_thresh_f[pred_f], marker='x')\n```"}, {'reason': 'stop', 'result': "```python\nX, Annotations = marconi['Kickbox']\ncamera = 0\nframe_annotations = 0\nfig = plt.figure(figsize=(16, 8))\nax = fig.add_subplot(111)\nim = X[camera, frame_annotations]\nax.imshow(im)\nAnnotations_for_cam = Annotations[camera]\nAnnot_on_frame_cam = Annotations_for_cam[frame_annotations]\nCOLORS = ['red', 'yellow']\nfor i, ((tl, br), joints) in enumerate(Annot_on_frame_cam):\n    head_x, head_y = utils.tl_br_to_plt_plot(tl[1], tl[0], br[1], br[0])\n    ax.plot(head_x, head_y, color=COLORS[i])\n    for jx, jy, visible in joints:\n        plt.scatter(jx, jy, color=COLORS[i], alpha=1 if visible == 1 else 0.4)\nplt.axis('off')\nplt.show()\n```"}, {'reason': 'stop', 'result': "```python\nK.clear_session()\nmodel = Sequential()\nmodel.add(GlobalAveragePooling2D(input_shape=train_incp_bn.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(NUM_CLASSES, activation='softmax'))\nmodel.summary()\n```"}, {'reason': 'stop', 'result': "```python\npipe_knn = make_pipeline(MinMaxScaler(), SelectPercentile(), KNeighborsRegressor())\nparam_grid_knn = {'selectpercentile__percentile': range(10, 30, 5), 'kneighborsregressor__n_neighbors': range(1, 20), 'kneighborsregressor__weights': ['uniform', 'distance']}\nknn_grid = GridSearchCV(pipe_knn, param_grid_knn)\nknn_grid.fit(train_features, train_outcome)\nbest_knn_params = knn_grid.best_params_\nknn_grid_score = knn_grid.score(test_features, test_outcome)\nknn_mae = mean_absolute_error(knn_grid.predict(test_features), test_outcome)\nknn_evs = explained_variance_score(knn_grid.predict(test_features), test_outcome)\n```"}, {'reason': 'stop', 'result': "```python\nX, Annotations = marconi['Walk1']\ncamera = 0\nframe = 220\nfig = plt.figure(figsize=(16, 8))\nax = fig.add_subplot(111)\nim = X[camera, frame]\nax.imshow(im)\nframe_annotations = Annotations[camera]\nAnnot_on_frame_cam = frame_annotations[frame]\nCOLORS = ['red', 'yellow']\nfor i, annot in enumerate(Annot_on_frame_cam):\n    if annot is not None:\n        (tl, br), joints = annot\n        head_x, head_y = utils.tl_br_to_plt_plot(tl[1], tl[0], br[1], br[0])\n        ax.plot(head_x, head_y, color=COLORS[i])\n        for jx, jy, visible in joints:\n            plt.scatter(jx, jy, color=COLORS[i], alpha=1 if visible == 1 else 0.4)\nplt.axis('off')\nplt.show()\n```"}, {'reason': 'stop', 'result': "```python\naditya_height_m = 1.21\nbotan_height_m = 1.85\naverage_height_m = 1.688\nbiggest_distance_m = max(abs(aditya_height_m - average_height_m), abs(botan_height_m - average_height_m))\nprint('The biggest distance from the average height among these two people is', biggest_distance_m, 'meters.')\n```"}, {'reason': 'stop', 'result': "```python\nheprowPath = '/home/pyne-user/Dropbox/UCB/Research/ETAs/88Inch/Data/Experiments/PHS/33MeVTa_29-31Mar17/Unfold/BeamOnly/HEPROW/'\nheprowName = 'mik_Det0_1.gru'\nunfanaName = 'unf_Det0_1.gru'\ngravelName = 'grv_out_Det0_1.flu'\nfaltwPHSName = 'faltw_Det0_1.phs'\nmeasPHSName = 'Inputs/Det0_stat_100_phs_03.phs'\nmtxName = 'MIEKE_Det0_1.MTX'\neta_configuration = 'low'\nmeuldersPath = '/home/pyne-user/Dropbox/UCB/Research/ETAs/88Inch/Data/Experiments/PHS/33MeVTa_29-31Mar17/Unfold/'\nmeuldersName = 'Meulders33MeVTaSpectrum_1.txt'\nmeuldersBinBounds = 'up'\nmcnpPath = '/home/pyne-user/Dropbox/UCB/Research/ETAs/88Inch/Data/Simulated/PHS/33MeVTa/BeamOnly/Model/NoExtrap_Void_1deg/'\nmcnpName = '33MeVTaBeamOnly_Det.out'\nmcnpBinBounds = 'up'\noutPath = '/home/pyne-user/Dropbox/UCB/Research/ETAs/88Inch/Data/Experiments/PHS/33MeVTa_29-31Mar17/Unfold/BeamOnly/HEPROW/'\n```"}, {'reason': 'stop', 'result': "```python\nhotel_counts['Hotel_Count'] = hotel_counts.groupby('Hotel Name')['Hotel Name'].transform('count')\ndescending_hotels = hotel_counts.sort_values(by=['Hotel_Count'], ascending=False).reset_index()\ndf_hotels = descending_hotels['Hotel Name'].unique()[:150]\nmost_common_hotels = descending_hotels[descending_hotels['Hotel Name'].isin(df_hotels)]\n```"}, {'reason': 'stop', 'result': "```python\nfrom mpl_toolkits.mplot3d import Axes3D\nfig = plt.figure(figsize=(16, 8))\nax = fig.add_subplot(111, projection='3d')\nimport cv2\nR1 = Rt1[:, 0:3]\nt1 = Rt1[:, 3]\nR2 = Rt2[:, 0:3]\nt2 = Rt2[:, 3]\n\ndef draw_person(ax, indv_left, indv_right):\n    HND_l = 0\n    ELB_l = 1\n    SHO_l = 2\n    HND_r = 5\n    ELB_r = 4\n    SHO_r = 3\n    FOT_l = 6\n    KNE_l = 7\n    HIP_l = 8\n    FOT_r = 11\n    KNE_r = 10\n    HIP_r = 9\n\n    def triangulate(elem):\n        a = indv_left[1][elem]\n        b = indv_right[1][elem]\n        a = a[:2]\n        b = b[:2]\n        A = np.array([a], 'float32').T\n        B = np.array([b], 'float32').T\n        result = cv2.triangulatePoints(P1, P2, A, B)\n        result /= result[3]\n        return result[:3]\n    left_hand = triangulate(HND_l)\n    left_elbow = triangulate(ELB_l)\n    left_shoulder = triangulate(SHO_l)\n    right_hand = triangulate(HND_r)\n    right_elbow = triangulate(ELB_r)\n    right_shoulder = triangulate(SHO_r)\n    right_hip = triangulate(HIP_r)\n    right_knee = triangulate(KNE_r)\n    right_foot = triangulate(FOT_r)\n    left_hip = triangulate(HIP_l)\n    left_knee = triangulate(KNE_l)\n    left_foot = triangulate(FOT_l)\n    ALL = np.squeeze(np.array([left_hand, left_elbow, left_shoulder, right_shoulder, right_elbow, right_hand, right_elbow, right_shoulder, right_hip, right_knee, right_foot, right_knee, right_hip, left_hip, left_knee, left_foot, left_knee, left_hip, left_shoulder]))\n    joint_coordinates = ALL[:, 0]\n    Y = ALL[:, 1]\n    Z = ALL[:, 2]\n    ax.plot(joint_coordinates, Y, Z)\ndraw_person(ax, annot1[0], annot2[1])\ndraw_person(ax, annot2[0], annot1[1])\nax.set_xlim([-4000, 4000])\nax.set_ylim([-4000, 4000])\nax.set_zlim([0, 4000])\n\ndef plot_cam(ax, R, t):\n    pos = -R.T @ t\n    ax.scatter(pos[0], pos[1], pos[2])\n    ax.plot([pos[0], pos[0]], [pos[1], pos[1]], [pos[2], 0])\nplot_cam(ax, R1, t1)\nplot_cam(ax, R2, t2)\n```"}, {'reason': 'stop', 'result': '```python\nfrom sklearn.ensemble import AdaBoostClassifier\nada_boost_classifier = AdaBoostClassifier(random_state=42)\nmodel = ada_boost_classifier.fit(X_train, y_train)\nimportances = model.feature_importances_\nvs.feature_plot(importances, X_train, y_train)\n```'}, {'reason': 'stop', 'result': "```python\ninitial_test_input = ['Hello World']\ncgi_runner = FunctionCoverageRunner(cgi_decode)\nm = MutationCoverageFuzzer(initial_test_input)\nresults = m.runs(cgi_runner, 10000)\n```"}, {'reason': 'stop', 'result': '```python\nfrom IPython.display import clear_output\n\ndef save_annotations(adict):\n    timestamp = datetime.datetime.today().strftime(\'%Y%m%d%H%M\')\n    filename = \'annotations_\' + timestamp + \'.csv\'\n    print(filename)\n    with open(os.path.join(\'.\', filename), \'w\', newline=\'\') as out:\n        annotations_writer = csv.writer(out)\n        for key, value in adict.items():\n            line = [key, *value]\n            annotations_writer.writerow(line)\n\ndef create_anottations(lista, save=True):\n    """Use dumb walk heuristic to create anottations\n    Args: \n    \n        lista: list of images\n        save: if true, save on current directory a csv <annottations_timestamp.csv>\n    \n    Returns: \n        \n        a dict with name of image: (xleft, ytop, xright, ytop) coordinates\n    """\n    cont = 0\n    result = {}\n    for img in lista:\n        try:\n            result[img] = find_conteiner(img)\n        except ValueError:\n            pass\n        cont += 1\n        if cont % 100 == 0:\n            clear_output()\n            print(\'...\', cont, \'...\')\n    if save:\n        save_annotations(result)\n    return result\n\ndef draw_anottation():\n    """Create red boxes on images for visual annotations checking\n    Will have to save RGB images inside of \'L\' greyscale"""\n    pass\n```'}, {'reason': 'stop', 'result': "```python\ndef LeNet6(x, n_classes):\n    mu = 0\n    sigma = 0.1\n    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6), mean=mu, stddev=sigma))\n    bias_variable = tf.Variable(tf.zeros(6))\n    conv1 = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + bias_variable\n    conv1 = tf.nn.relu(conv1)\n    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean=mu, stddev=sigma))\n    conv2_b = tf.Variable(tf.zeros(16))\n    conv2 = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n    conv2 = tf.nn.relu(conv2)\n    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n    fc0 = flatten(conv2)\n    fc1_W = tf.Variable(tf.truncated_normal(shape=(400, 252), mean=mu, stddev=sigma))\n    fc1_b = tf.Variable(tf.zeros(252))\n    fc1 = tf.matmul(fc0, fc1_W) + fc1_b\n    fc1 = tf.nn.relu(fc1)\n    fc1 = tf.nn.dropout(fc1, keep_prob)\n    fc2_W = tf.Variable(tf.truncated_normal(shape=(252, 168), mean=mu, stddev=sigma))\n    fc2_b = tf.Variable(tf.zeros(168))\n    fc2 = tf.matmul(fc1, fc2_W) + fc2_b\n    fc2 = tf.nn.relu(fc2)\n    fc2 = tf.nn.dropout(fc2, keep_prob)\n    fc3_W = tf.Variable(tf.truncated_normal(shape=(168, 84), mean=mu, stddev=sigma))\n    fc3_b = tf.Variable(tf.zeros(84))\n    fc3 = tf.matmul(fc2, fc3_W) + fc3_b\n    fc3 = tf.nn.relu(fc3)\n    fc3 = tf.nn.dropout(fc3, keep_prob)\n    fc4_W = tf.Variable(tf.truncated_normal(shape=(84, n_classes), mean=mu, stddev=sigma))\n    fc4_b = tf.Variable(tf.zeros(n_classes))\n    logits = tf.matmul(fc3, fc4_W) + fc4_b\n    return logits\n```"}, {'reason': 'stop', 'result': "```python\nfrom skimage.morphology import disk, erosion, dilation, square\nB = square(3)\ndilated_image = dilation(X, selem=B)\nX_ero = erosion(X, selem=B)\nplt.figure(figsize=[10, 5])\nplt.subplot(1, 3, 1)\nplt.imshow(X, interpolation='nearest', cmap=plt.cm.gray)\nplt.title('$X$')\nplt.subplot(1, 3, 2)\nplt.imshow(dilated_image, interpolation='nearest', cmap=plt.cm.gray)\nplt.title('dilation of $X$ by $B$')\nplt.subplot(1, 3, 3)\nplt.imshow(X_ero, interpolation='nearest', cmap=plt.cm.gray)\nplt.title('erosion of $X$ by $B$')\nplt.figure(figsize=[6, 6])\nplt.imshow(X, interpolation='nearest', cmap=plt.cm.gray, alpha=0.3)\nplt.imshow(X_ero, interpolation='nearest', cmap=plt.cm.gray, alpha=0.3)\nplt.imshow(dilated_image, interpolation='nearest', cmap=plt.cm.gray, alpha=0.3)\n```"}, {'reason': 'stop', 'result': "```python\ndef get_data_from_tsv(feature_file, x_fields, y_field, x_filter=None, seed=0, as_np_array=False, scale=False, shuffle=False, train_portion=0.6, test_portion=0.2):\n    my_data = pandas.read_csv(feature_file)\n    print(my_data.shape)\n    my_data = my_data.dropna()\n    my_data = my_data.reset_index(drop=True)\n    print(my_data.shape)\n    if not x_filter == None:\n        for ff in x_filter:\n            my_data = my_data[my_data[ff[0]].isin(ff[1:])]\n            print('filtering %s by ' % ff[0], ff[1:], 'num datapoints left: ', len(my_data))\n        my_data = my_data.reset_index(drop=True)\n    labels = my_data['word']\n    if 'freq' in x_fields or my_data.columns.get_loc('freq') in x_fields:\n        idx = my_data.columns.get_loc('freq')\n        my_data.iloc[:, idx] = np.log(my_data.iloc[:, idx])\n        my_data = my_data.rename(columns={'freq': 'log_freq'})\n    if 'length' in x_fields or my_data.columns.get_loc('length') in x_fields:\n        idx = my_data.columns.get_loc('length')\n        my_data.iloc[:, idx] = np.log(my_data.iloc[:, idx])\n        my_data = my_data.rename(columns={'length': 'log_length'})\n    if type(x_fields[0]) == str:\n        x_fields.append(y_field)\n        my_data = my_data[x_fields]\n    else:\n        x_fields.append(my_data.columns.get_loc(y_field))\n        my_data = my_data.iloc[:, x_fields]\n    del x_fields[-1]\n    x_train, y_train, x_dev, y_dev, x_test, word_age_data = train_validate_test_split(my_data, y_field, train_percent=train_portion, validate_percent=test_portion, seed=seed, shuffle=shuffle)\n    if scale:\n        x_train = pandas.DataFrame(preprocessing.scale(x_train), columns=x_train.columns, index=x_train.index)\n        x_dev = pandas.DataFrame(preprocessing.scale(x_dev), columns=x_dev.columns, index=x_dev.index)\n        x_test = pandas.DataFrame(preprocessing.scale(x_test), columns=x_test.columns, index=x_test.index)\n        y_train = pandas.DataFrame(preprocessing.scale(y_train), columns=y_train.columns, index=y_train.index)\n        y_dev = pandas.DataFrame(preprocessing.scale(y_dev), columns=y_dev.columns, index=y_dev.index)\n        word_age_data = pandas.DataFrame(preprocessing.scale(word_age_data), columns=word_age_data.columns, index=word_age_data.index)\n    if as_np_array:\n        x_train = np.array(x_train).astype(np.float)\n        y_train = np.array(y_train).astype(np.float)\n        x_dev = np.array(x_dev).astype(np.float)\n        y_dev = np.array(y_dev).astype(np.float)\n        x_test = np.array(x_test).astype(np.float)\n        word_age_data = np.array(word_age_data).astype(np.float)\n    return (x_train, y_train, x_dev, y_dev, x_test, word_age_data, labels)\n```"}, {'reason': 'stop', 'result': "```python\nX_test_refined = pd.DataFrame([])\nr_precisions = []\npbar = tqdm(data_test.groupby(['playlist_pid']))\nfor pid, df in pbar:\n    p_info = df[playlist_df.columns].iloc[0]\n    labels = y_test.loc[df.index]\n    positive_tracks_idx = labels[labels == 1].index\n    positive_tracks_data = data_test.loc[positive_tracks_idx]\n    sp_positive_tracks = vectorizer.transform(positive_tracks_data.values)\n    negative_tracks_idx = ~np.isin(data_test.index, positive_tracks_idx)\n    negative_tracks = data_test[negative_tracks_idx].drop(playlist_df.columns, axis=1)\n    negative_playlist = np.array([p_info.values] * len(negative_tracks))\n    negative_playlist_samples = np.hstack([negative_tracks, negative_playlist])\n    sp_negative_tracks = vectorizer.transform(negative_playlist_samples)\n    test_tracks = vstack([sp_negative_tracks, sp_positive_tracks])\n    index_order = negative_tracks.index.append(positive_tracks_idx)\n    y_prob = AdaModel.predict_proba(test_tracks)\n    y_pred = np.argsort(-y_prob[:, 1])\n    best_pred = index_order[y_pred]\n    if len(positive_tracks_idx) > 0:\n        r_precisions.append(r_precision(positive_tracks_idx, best_pred))\n    pbar.set_description('{}'.format(np.mean(r_precisions)))\n```"}, {'reason': 'stop', 'result': "```python\nstarting_url = 'http://www.google.com/search?q=fuzzing'\nmutation_fuzzer = MutationCoverageFuzzer(seed=[starting_url])\nmutation_fuzzer.runs(http_runner, trials=10000)\nmutation_fuzzer.population\n```"}, {'reason': 'stop', 'result': "```python\nRTrunanalysis = pd.DataFrame()\nnew_RTlists = [[] for list in range(0, 5)]\nfor ID in range(10, 86):\n    sub = cdat[cdat.subject == ID]\n    for runID in range(0, 4):\n        subject_run_data = sub[sub.RunCounter == runID]\n        new_RTlists[0].append(ID)\n        new_RTlists[1].append(runID)\n        validRT_trials = subject_run_data[subject_run_data.TrialType == 'Valid'].RT.mean()\n        invalidRT_trials = subject_run_data[subject_run_data.TrialType == 'Invalid'].RT.mean()\n        new_RTlists[2].append(validRT_trials)\n        new_RTlists[3].append(invalidRT_trials)\nRTrunanalysis['SubjectID'] = new_RTlists[0]\nRTrunanalysis['Run'] = new_RTlists[1]\nRTrunanalysis['Valid'] = new_RTlists[2]\nRTrunanalysis['Invalid'] = new_RTlists[3]\n```"}, {'reason': 'stop', 'result': "```python\nnum_steps = 10001\nwith tf.Session(graph=graph) as session:\n    tf.initialize_all_variables().run()\n    start = datetime.datetime.now()\n    print('Initialized')\n    for step in range(num_steps):\n        offset = step * batch_size % (train_labels.shape[0] - batch_size)\n        batch_data = train_dataset[offset:offset + batch_size, :, :, :]\n        batch_labels = train_labels[offset:offset + batch_size, :]\n        feed_dict = {tf_train_dataset: batch_data, tf_train_labels: batch_labels, keep3: 0.9, keep4: 0.9}\n        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n        if step % 500 == 0:\n            ends = eta(start, step, num_steps)\n            valpred = valid_prediction.eval(feed_dict={keep3: 1.0, keep4: 1.0})\n            print('Step %d - Loss %f - Minibatch %.1f%% - Validation %.1f%% - ETA %s' % (step, l, accuracy(predictions, batch_labels), accuracy(valpred, valid_labels), ends))\n    print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(feed_dict={keep3: 1.0, keep4: 1.0}), test_labels))\n```"}, {'reason': 'stop', 'result': '```python\nblockPositions = []\ntestBlockPositions = []\naverageSpacing = 1\nkp = 40\nkc = 250\nmass = 1\nF0 = 50\nblock_variation = 0.01\nvBlock = 0\nvf = 3.0\nblockNum = 25\nmaxTimeSteps = 50000\nminBLockV = 1e-08\ntimeStepShort = 0.005\ntimeStepLong = 1\nvariation = 0.001\nfor n in range(0, blockNum + 1):\n    blockPositions.append(n * averageSpacing + (random.random() - 0.5) * 2 * block_variation)\n    testBlockPositions.append(n)\n```'}, {'reason': 'stop', 'result': "```python\ngraph_data = os.path.join(folder, filename_graph)\nwith h5py.File(graph_data, 'r') as graph:\n    print('Attributes:')\n    for attr in graph.attrs:\n        print('  {} = {}'.format(attr, graph.attrs[attr]))\n    print('Datasets:')\n    for dname, dset in graph.items():\n        print('  {:10}: {:10}, {}'.format(dname, dset.shape, dset.dtype))\n    pars = []\n    for par in ('data', 'indices', 'indptr', 'shape'):\n        pars.append(graph.get('L_' + par))\n    L = scipy.sparse.csr_matrix(tuple(pars[:3]), shape=pars[3])\nif L.shape != (X.shape[0], X.shape[0]):\n    raise ValueError('Graph size does not correspond to data size.')\n```"}, {'reason': 'stop', 'result': "```python\nnew_pc = eigvecs[:, -2:]\nplt.figure(figsize=(15, 5))\nplt.subplot(121)\nplt.scatter(X[y == 0, 0], X[y == 0, 1], color='red', alpha=0.5)\nplt.scatter(X[y == 1, 0], X[y == 1, 1], color='blue', alpha=0.5)\npca11 = plt.arrow(0, 0, *vec[:, 0] * val[0], head_width=0.05, head_length=0.05, color='Green', label='First PC')\npca12 = plt.arrow(0, 0, *vec[:, 1] * val[1], head_width=0.05, head_length=0.05, color='magenta', label='Second PC')\nplt.grid(True)\nprincipal_components = new_pc - new_pc.mean(0, keepdims=True)\ncov = principal_components.T @ principal_components / (principal_components.shape[0] - 1)\nval, vec = np.linalg.eigh(cov)\nplt.subplot(122)\nplt.scatter(new_pc[y == 0, 0], new_pc[y == 0, 1], color='red', alpha=0.5)\nplt.scatter(new_pc[y == 1, 0], new_pc[y == 1, 1], color='blue', alpha=0.5)\npca21 = plt.arrow(0, 0, *vec[:, 0] * val[0], head_width=0.005, head_length=0.005, color='Green', label='First PC')\npca22 = plt.arrow(0, 0, *vec[:, 1] * val[1], head_width=0.005, head_length=0.005, color='magenta', label='Second PC')\nplt.grid(True)\nplt.show()\n```"}, {'reason': 'stop', 'result': '```python\ndef process_image(image):\n    gray = grayscale(image)\n    kernel_size = 5\n    blur_gray = gaussian_blur(gray, kernel_size)\n    low_threshold = 50\n    high_threshold = 150\n    edges = canny(blur_gray, low_threshold, high_threshold)\n    imshape = image.shape\n    xPct = 0.05\n    lane_line_y_variable = 0.6\n    xbl = imshape[1] * xPct\n    xbr = imshape[1] * (1 - xPct)\n    xtl = imshape[1] * (0.5 - xPct)\n    xtr = imshape[1] * (0.5 + xPct)\n    yb = imshape[0]\n    yt = imshape[0] * lane_line_y_variable\n    vertices = np.array([[(xbl, yb), (xtl, yt), (xtr, yt), (xbr, yb)]], dtype=np.int32)\n    masked_image = region_of_interest(edges, vertices)\n    rho = 2\n    theta = np.pi / 180\n    threshold = 15\n    min_line_len = 20\n    max_line_gap = 30\n    line_img = hough_lines(masked_image, rho, theta, threshold, min_line_len, max_line_gap)\n    overlayedImg = weighted_img(line_img, image, 0.8, 1, 0)\n    return overlayedImg\n```'}, {'reason': 'stop', 'result': '```python\ncolor_palette = [\'b\', \'g\', \'r\', \'k\', \'c\', \'m\', \'y\']\nindex = 0\nfor segment in segments:\n    segDF = data.loc[data[\'RiverSeg\'] == segment]\n    segDF = segDF[segDF["lam\'"] > 0]\n    segDF = segDF.sort_values(\'Year\')\n    x = segDF[\'Year\']\n    y = segDF[\'N10\']\n    y.name = segment\n    plt.plot(x, y, color_palette[index])\n    plt.legend(loc=(1.05, 0.2))\n    index += 1\nplt.title(\'Hill N10, \' + river + \' River Segments\')\nplt.xlabel(\'Year\')\nplt.ylabel(\'N10\')\nplt.xticks(np.arange(min(x), max(x) + 1, 1.0))\nplt.xticks(rotation=90)\nplt.savefig(output + \'\\\\\' + river + \'_Hill_N10.png\', bbox_inches=\'tight\', dpi=300, size=(2000, 2000))\nplt.show()\n```'}, {'reason': 'stop', 'result': '```python\nimport tensorflow as tf\nimport numpy as np\nfrom sklearn.utils import shuffle\nX_train_normal = np.array(X_train / 255 - 0.5)\nX_valid_normal = np.array(X_valid / 255 - 0.5)\nX_test_normal = np.array(X_test / 255 - 0.5)\nnormalization_factor = 15\nBATCH_SIZE = 128\n```'}, {'reason': 'stop', 'result': "```python\nimport re\nCLASS_NAME_REGEX = re.compile('^n\\\\d+\\\\s+(.*)\\\\s*$', re.M | re.U)\n\ndef load_class_names():\n    with open(os.path.join('datasets', 'inception', 'imagenet_class_names.txt'), 'rb') as f:\n        class_names_text = f.read().decode('utf-8')\n        return CLASS_NAME_REGEX.findall(class_names_text)\n```"}, {'reason': 'stop', 'result': "```python\nfrom numpy import ma\nU = paf_avg[:, :, 16] * -1\nV = paf_avg[:, :, 17]\ngrid_coordinates, Y = np.meshgrid(np.arange(U.shape[1]), np.arange(U.shape[0]))\nM = np.zeros(U.shape, dtype='bool')\nM[U ** 2 + V ** 2 < 0.3 * 0.3] = True\nU = ma.masked_array(U, mask=M)\nV = ma.masked_array(V, mask=M)\nplt.figure()\nplt.imshow(oriImg[:, :, [2, 1, 0]], alpha=0.5)\ns = 5\nQ = plt.quiver(grid_coordinates[::s, ::s], Y[::s, ::s], U[::s, ::s], V[::s, ::s], scale=50, headaxislength=4, alpha=0.5, width=0.001, color='r')\nfig = matplotlib.pyplot.gcf()\nfig.set_size_inches(10, 10)\n```"}, {'reason': 'stop', 'result': "```python\ndef LeNet6(x, n_classes):\n    mean_variable = 0\n    sigma = 0.1\n    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6), mean=mean_variable, stddev=sigma))\n    conv1_b = tf.Variable(tf.zeros(6))\n    conv1 = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n    conv1 = tf.nn.relu(conv1)\n    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean=mean_variable, stddev=sigma))\n    conv2_b = tf.Variable(tf.zeros(16))\n    conv2 = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n    conv2 = tf.nn.relu(conv2)\n    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n    fc0 = flatten(conv2)\n    fc1_W = tf.Variable(tf.truncated_normal(shape=(400, 252), mean=mean_variable, stddev=sigma))\n    fc1_b = tf.Variable(tf.zeros(252))\n    fc1 = tf.matmul(fc0, fc1_W) + fc1_b\n    fc1 = tf.nn.relu(fc1)\n    fc1 = tf.nn.dropout(fc1, keep_prob)\n    fc2_W = tf.Variable(tf.truncated_normal(shape=(252, 168), mean=mean_variable, stddev=sigma))\n    fc2_b = tf.Variable(tf.zeros(168))\n    fc2 = tf.matmul(fc1, fc2_W) + fc2_b\n    fc2 = tf.nn.relu(fc2)\n    fc2 = tf.nn.dropout(fc2, keep_prob)\n    fc3_W = tf.Variable(tf.truncated_normal(shape=(168, 84), mean=mean_variable, stddev=sigma))\n    fc3_b = tf.Variable(tf.zeros(84))\n    fc3 = tf.matmul(fc2, fc3_W) + fc3_b\n    fc3 = tf.nn.relu(fc3)\n    fc3 = tf.nn.dropout(fc3, keep_prob)\n    fc4_W = tf.Variable(tf.truncated_normal(shape=(84, n_classes), mean=mean_variable, stddev=sigma))\n    fc4_b = tf.Variable(tf.zeros(n_classes))\n    logits = tf.matmul(fc3, fc4_W) + fc4_b\n    return logits\n```"}, {'reason': 'stop', 'result': '```python\nhours_until_success = seconds_until_success / 3600\nsuccess_years = hours_until_success / 24\nyears_until_success = success_years / 365.25\nyears_until_success\n```'}, {'reason': 'stop', 'result': "```python\ndef resize_images(src_dir, dest_dir):\n    if not os.path.isdir(src_dir):\n        raise Exception(src_dir + ' is not a directory')\n    if not os.path.exists(dest_dir):\n        os.mkdir(dest_dir)\n    raw_images = {image for image in os.listdir(src_dir) if image.endswith(JPEG_EXTENSIONS)}\n    dest_images = {image for image in os.listdir(dest_dir)}\n    for image in raw_images - dest_images:\n        if DEBUG:\n            print('Resizing ' + image)\n        resize_image(image, src_dir, dest_dir)\n\ndef resize_image(image_file, src_dir, dest_dir):\n    in_file = os.path.join(src_dir, image_file)\n    with open(in_file, 'r+b') as fd_img:\n        with Image.open(fd_img) as img:\n            resized_image = resizeimage.resize_contain(img, [299, 299]).convert('RGB')\n            resized_image.save(os.path.join(dest_dir, image_file), img.format)\nif os.path.isdir(images_resized_dir):\n    shutil.rmtree(images_resized_dir)\nos.mkdir(images_resized_dir)\nsubdirs = ('house_with_pool', 'house_without_pool')\nfor subdir in subdirs:\n    dest_dir = os.path.join(images_resized_dir, subdir)\n    if not os.path.isdir(dest_dir):\n        os.mkdir(dest_dir)\n    if stored_images_resized:\n        resized_images_dir = os.path.join(stored_images_resized, subdir)\n        if os.path.isdir(resized_images_dir):\n            for f in os.listdir(resized_images_dir):\n                path = os.path.join(resized_images_dir, f)\n                if os.path.isfile(path):\n                    shutil.copy(path, dest_dir)\n    resize_images(os.path.join(image_dir, subdir), dest_dir)\n```"}, {'reason': 'stop', 'result': "```python\nfig = plt.figure()\nfig.add_subplot()\ny1 = earningsgrowth10k\ny2 = earningsgrowth10k_18k\ny3 = earningsgrowth18k_32k\nearnings_growth_32k = earningsgrowth32kk\nx_axis = [x for x in range(1, 9)]\nx_axis2 = [x + 0.2 for x in range(1, 9)]\nx_axis3 = [x + 0.4 for x in range(1, 9)]\nx_axis4 = [x + 0.6 for x in range(1, 9)]\nplt.bar(x_axis, y1, width=0.2, label='Growth for Tier:10k')\nplt.bar(x_axis2, y2, width=0.2, label='Growth for Tier:10k-18k')\nplt.bar(x_axis3, y3, width=0.2, label='Growth for Tier:18k-32k')\nplt.bar(x_axis4, earnings_growth_32k, width=0.2, label='Growth for Tier: 32k')\nplt.title('Earnings Growth years 6-10')\nplt.xlabel('Region')\nplt.ylabel('Earnings Growth')\nplt.legend(title=['Earnings Growth years 6-10'])\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)\n```"}, {'reason': 'stop', 'result': "```python\nimage_array = mpimg.imread('test_images/solidWhiteCurve.jpg')\nlane_detected = lane_detection(image_array)\nplt.imshow(lane_detected)\n```"}, {'reason': 'stop', 'result': "```python\npredicted_centers = pca.inverse_transform(centers)\ntrue_centers = np.exp(predicted_centers)\nsegments = ['Segment {}'.format(i) for i in range(0, len(centers))]\ntrue_centers = pd.DataFrame(np.round(true_centers), columns=data.keys())\ntrue_centers.index = segments\ndisplay(true_centers)\n```"}, {'reason': 'stop', 'result': "```python\nimport csv\nimport datetime\nimport os\nimport glob\nimage_directory = '/home/ivan/Área de trabalho/2017'\nlista = []\nfor filename in glob.iglob(image_directory + '**/*/*/*/*stamp.jpg*', recursive=True):\n    lista.append(filename)\nprint(lista[:4])\nprint(len(lista))\nprint(find_conteiner(lista[1]))\nprint(find_conteiner(lista[15]))\n```"}, {'reason': 'stop', 'result': "```python\nprobas_patches_msr = np.reshape(get_acc_net_msr(y_pred_te).flatten(), np.shape(data_test.gt_patches))\nprobas_patches_msr -= np.min(probas_patches_msr)\nprobas_patches_msr /= np.max(probas_patches_msr)\nprobas_patches_margin = np.reshape((1 - get_acc_net_max_margin(y_pred_te)).flatten(), np.shape(data_test.gt_patches))\nprobas_patches_margin -= np.min(probas_patches_margin)\nprobas_patches_margin /= np.max(probas_patches_margin)\nprobas_patches_entropy = np.reshape((1 - get_acc_net_entropy(y_pred_te)).flatten(), np.shape(data_test.gt_patches))\nprobas_patches_entropy -= np.min(probas_patches_entropy)\nprobas_patches_entropy /= np.max(probas_patches_entropy)\nprobas_patches_msr = np.reshape(get_acc_net_msr(y_pred_te).flatten(), np.shape(data_test.gt_patches))\nprobas_patches_msr -= np.min(probas_patches_msr)\nprobas_patches_msr /= np.max(probas_patches_msr)\nprobas_patches_margin = np.reshape((1 - get_acc_net_max_margin(y_pred_te)).flatten(), np.shape(data_test.gt_patches))\nprobas_patches_margin -= np.min(probas_patches_margin)\nprobas_patches_margin /= np.max(probas_patches_margin)\nprobas_patches_entropy = np.reshape((1 - get_acc_net_entropy(y_pred_te)).flatten(), np.shape(data_test.gt_patches))\nprobas_patches_entropy -= np.min(probas_patches_entropy)\nprobas_patches_entropy /= np.max(probas_patches_entropy)\nacc_im_msr = convert_patches_to_image(data_test.imgs, probas_patches_msr[..., np.newaxis], 64, 64)\nacc_im_margin = convert_patches_to_image(data_test.imgs, probas_patches_margin[..., np.newaxis], 64, 64)\nentropy_image_certification = convert_patches_to_image(data_test.imgs, probas_patches_entropy[..., np.newaxis], 64, 64)\nfor img_idx in range(5):\n    plt.figure(figsize=(8, 8))\n    plt.imshow(acc_im_msr[img_idx], cmap='RdYlGn')\n    plt.axis('off')\n    plt.gca().xaxis.set_major_locator(plt.NullLocator())\n    plt.gca().yaxis.set_major_locator(plt.NullLocator())\n    plt.savefig('../Figures/Zurich/Im_cert/ED/net_msr_im_' + str(img_idx) + '.pdf', bbox_inches='tight', pad_inches=0)\n    plt.close()\n    plt.figure(figsize=(8, 8))\n    plt.imshow(acc_im_margin[img_idx], cmap='RdYlGn')\n    plt.axis('off')\n    plt.gca().xaxis.set_major_locator(plt.NullLocator())\n    plt.gca().yaxis.set_major_locator(plt.NullLocator())\n    plt.savefig('../Figures/Zurich/Im_cert/ED/net_margin_im_' + str(img_idx) + '.pdf', bbox_inches='tight', pad_inches=0)\n    plt.close()\n    plt.figure(figsize=(8, 8))\n    plt.imshow(entropy_image_certification[img_idx], cmap='RdYlGn')\n    plt.axis('off')\n    plt.gca().xaxis.set_major_locator(plt.NullLocator())\n    plt.gca().yaxis.set_major_locator(plt.NullLocator())\n    plt.savefig('../Figures/Zurich/Im_cert/ED/net_entropy_im_' + str(img_idx) + '.pdf', bbox_inches='tight', pad_inches=0)\n    plt.close()\n```"}, {'reason': 'stop', 'result': "```python\nfrom image_aq.utils.pascal_voc_io import PascalVocWriter\n\ndef gera_voc(file):\n    foldername, filename = os.path.split(file)\n    img = imageio.imread(file)\n    imgSize = img.shape\n    print(foldername, filename, imgSize)\n    pascal_voc_writer = PascalVocWriter(foldername, filename, imgSize)\n    coords = find_conteiner(file)\n    pascal_voc_writer.addBndBox(*coords, 'cc', '')\n    pascal_voc_writer.save(file[:-4] + '.xml')\nfile = lista[0]\nprint(file)\ngera_voc(file)\nglob.glob(foldername + '/*')\n```"}, {'reason': 'stop', 'result': '```python\ncolors = [\'b\', \'g\', \'r\', \'k\', \'c\', \'m\', \'y\']\ncolor_index = 0\nfor segment in segments:\n    segDF = data.loc[data[\'RiverSeg\'] == segment]\n    segDF = segDF[segDF["lam\'"] > 0]\n    segDF = segDF.sort_values(\'Year\')\n    x = segDF[\'Year\']\n    y = segDF[\'N1\']\n    y.name = segment\n    plt.plot(x, y, colors[color_index])\n    plt.legend(loc=(1.05, 0.2))\n    color_index += 1\nplt.title(\'Hill N1, \' + river + \' River Segments\')\nplt.xlabel(\'Year\')\nplt.ylabel("N1\'")\nplt.xticks(np.arange(min(x), max(x) + 1, 1.0))\nplt.xticks(rotation=90)\nplt.savefig(output + \'\\\\\' + river + \'_Hill_N1.png\', bbox_inches=\'tight\', dpi=300, size=(2000, 2000))\nplt.show()\n```'}, {'reason': 'stop', 'result': "```python\nif use_toy_data:\n    data_file = 'toy_input.txt'\n    with open(data_file, 'w') as f:\n        f.write('a b c\\td e f d e f\\n')\n        f.write('d e f\\ta b c a b c\\n')\nelse:\n    DATA_DIR = '../../data/'\n    data_file = 'instrumental.full.train'\n    data_file = os.path.join(DATA_DIR, data_file)\n    if not os.path.exists(data_file):\n        import urllib\n        data_file = urllib.request.URLopener()\n        data_file.retrieve('http://sandbox.mokk.bme.hu/~judit/resources/instrumental.full.train', data_file)\n```"}, {'reason': 'stop', 'result': "```python\nxmin = 0\nnum_features = x_test.shape[1]\nxindex = np.arange(xmin, num_features)\nnrows = 3\nfig, ax = plt.subplots(nrows=nrows, ncols=1, figsize=(15, 3 * nrows))\nax[0].scatter(xindex, x_test[0, :, 0], marker='.', c=y_true_colors)\nax[0].set_title('epoch = {}'.format(epoch))\nax[0].set_xlim((xmin, num_features))\nax[0].set_xticks([])\nax[0].grid(True)\nax[1].scatter(xindex, x_test[0, :, 0], marker='.', c=y_pred_colors)\nax[1].set_title('loss = {:<6.4f}, accuracy = {:<.2%}'.format(*score))\nax[1].set_xlim((xmin, num_features))\nax[1].set_xticks([])\nax[1].grid(True)\nlegend_labels = []\nfor wave in msig.waves:\n    ax[2].plot(xindex, wave.sample_full, color=wave.color, zorder=1)\n    legend_labels.append(wave.name)\nax[2].scatter(xindex[i_fail], x_test[0, i_fail, 0], marker='o', c=y_pred_colors[i_fail], zorder=2)\nax[2].set_xlim((xmin, num_features))\nax[2].grid(True)\nax[2].legend(legend_labels)\nplt.tight_layout()\nplt.savefig(os.path.join(msig.out_dir, 'prediction_analysis.png'), bbox_inches='tight')\n```"}, {'reason': 'stop', 'result': "```python\nbarwidth = 0.75\nfig, ax = plt.subplots(figsize=(9, 7))\nperceptual_category_bars = ax.bar(0.5, SkyPresence.mean(), barwidth, color=sns.xkcd_rgb['green'], yerr=SkyPresenceSEM, ecolor='k', error_kw=dict(lw=3))\nrects2 = ax.bar(1.5, ColorScheme.mean(), barwidth, color=(0.3, 0.9, 0.3), yerr=ColorSchemeSEM, ecolor='k', error_kw=dict(lw=3))\nrects3 = ax.bar(2.5, TreeFreq.mean(), barwidth, color=(0.15, 1, 0.15), yerr=TreeFreqSEM, ecolor='k', error_kw=dict(lw=3))\nrects4 = ax.bar(4, ImageType.mean(), barwidth, yerr=ImageTypeSEM, ecolor='k', edgecolor=sns.xkcd_rgb['green'], linewidth=2, facecolor='none', error_kw=dict(lw=3))\nrects5 = ax.bar(5, FeatureType.mean(), barwidth, yerr=FeatureTypeSEM, ecolor='k', edgecolor=(0.3, 0.9, 0.3), linewidth=2, facecolor='none', error_kw=dict(lw=3))\nrects6 = ax.bar(6, LightType.mean(), barwidth, yerr=LightTypeSEM, ecolor='k', edgecolor=(0.15, 1, 0.15), linewidth=2, facecolor='none', error_kw=dict(lw=3))\nsns.set(context='notebook', style='white', font='Myriad Pro', font_scale=2, color_codes=False, rc=None)\nax.set_ylim(0, 100)\nax.set_xlim(0, 7.5)\nax.set_xticklabels(('SP', 'CS', 'TF', 'IT', 'FT', 'LT'))\nax.set_xticks([0.5 + barwidth / 2, 1.5 + barwidth / 2, 2.5 + barwidth / 2, 4 + barwidth / 2, 5 + barwidth / 2, 6 + barwidth / 2])\nax.set_yticks(np.arange(0, 101, 10))\nplt.title('Q2: Rate the Frequency at Which These Perceptual Categories\\nPredicted an Easy/Hard Color-Word Trial', fontsize=18, fontweight='bold')\nplt.ylabel('<-- Less Likely      More Likely -->', fontsize=17, fontweight='bold')\nplt.xlabel('S-C Phase                 S-CT Phase', fontsize=17, fontweight='bold')\nsns.despine()\nplt.show()\n```"}, {'reason': 'stop', 'result': "```python\nfig = plt.figure()\nfig.add_subplot()\ny1 = earningsgrowth10k\ny2 = earningsgrowth10k_18k\ny3 = earningsgrowth18k_32k\ny4 = earningsgrowth32kk\nx_axis = [x for x in range(1, 9)]\nregion_bar_positions = [x + 0.2 for x in range(1, 9)]\nx_axis3 = [x + 0.4 for x in range(1, 9)]\nx_axis4 = [x + 0.6 for x in range(1, 9)]\nplt.bar(x_axis, y1, width=0.2, label='Growth for Tier:10k')\nplt.bar(region_bar_positions, y2, width=0.2, label='Growth for Tier:10k-18k')\nplt.bar(x_axis3, y3, width=0.2, label='Growth for Tier:18k-32k')\nplt.bar(x_axis4, y4, width=0.2, label='Growth for Tier: 32k')\nplt.title('Earnings Growth years 6-10')\nplt.xlabel('Region')\nplt.ylabel('Earnings Growth')\nplt.legend(title=['Earnings Growth years 6-10'])\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)\n```"}, {'reason': 'stop', 'result': '```python\ndef flip_random_character(s):\n    """Returns s with a random bit flipped in a random position"""\n    if s == \'\':\n        return s\n    pos = random.randint(0, len(s) - 1)\n    c = s[pos]\n    bit = 1 << random.randint(0, 6)\n    flipped_character = chr(ord(c) ^ bit)\n    return s[:pos] + flipped_character + s[pos + 1:]\n```'}, {'reason': 'stop', 'result': "```python\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import GridSearchCV\ntfidf = TfidfVectorizer(strip_accents=None, lowercase=False, preprocessor=None)\nparam_grid = [{'vect__ngram_range': [(1, 1)], 'vect__stop_words': [stop, None], 'vect__tokenizer': [tokenizer, tokenizer_porter], 'clf__penalty': ['l1', 'l2'], 'clf__C': [1.0, 10.0, 100.0]}, {'vect__ngram_range': [(1, 1)], 'vect__stop_words': [stop, None], 'vect__tokenizer': [tokenizer, tokenizer_porter], 'vect__use_idf': [False], 'vect__norm': [None], 'clf__penalty': ['l1', 'l2'], 'clf__C': [1.0, 10.0, 100.0]}]\ntext_classification_pipeline = Pipeline([('vect', tfidf), ('clf', LogisticRegression(random_state=0))])\ngs_lr_tfidf = GridSearchCV(text_classification_pipeline, param_grid, scoring='accuracy', cv=5, verbose=1, n_jobs=-1)\n```"}, {'reason': 'stop', 'result': '```python\ny_scores = (-get_acc_net_msr(y_pred_te)).flatten()\ny_true = pred_f_te.flatten()\nprecision_msr, recall_msr, _ = metrics.precision_recall_curve(y_true, y_scores)\npr_auc_msr = metrics.average_precision_score(y_true, y_scores)\nauroc_msr = metrics.roc_auc_score(y_true, y_scores)\nfpr_msr, tpr_msr, _ = metrics.roc_curve(y_true, y_scores)\ny_scores = (-get_acc_net_max_margin(y_pred_te)).flatten()\nprecision_margin, recall_margin, _ = metrics.precision_recall_curve(y_true, y_scores)\npr_auc_margin = metrics.average_precision_score(y_true, y_scores)\nauroc_margin = metrics.roc_auc_score(y_true, y_scores)\nfpr_margin, tpr_margin, _ = metrics.roc_curve(y_true, y_scores)\ny_scores = (-get_acc_net_entropy(y_pred_te)).flatten()\nprecision_entropy, precision_recall_curve_entropy, _ = metrics.precision_recall_curve(y_true, y_scores)\npr_auc_entropy = metrics.average_precision_score(y_true, y_scores)\nauroc_entropy = metrics.roc_auc_score(y_true, y_scores)\nfpr_entropy, tpr_entropy, _ = metrics.roc_curve(y_true, y_scores)\n```'}, {'reason': 'stop', 'result': "```python\ndef plot(embeddings, labels):\n    assert embeddings.shape[0] >= len(labels), 'More labels than embeddings'\n    pylab.figure(figsize=(15, 15))\n    for i, label in enumerate(labels):\n        embedding_coordinates, y = embeddings[i, :]\n        pylab.scatter(embedding_coordinates, y)\n        pylab.annotate(label, xy=(embedding_coordinates, y), xytext=(5, 2), textcoords='offset points', ha='right', va='bottom')\n    pylab.show()\nwords = [reverse_dictionary[i] for i in range(1, num_points + 1)]\nplot(two_d_embeddings, words)\n```"}, {'reason': 'stop', 'result': '```python\ndef rbg_to_hls(img):\n    """ \n    Takes an RGB image and converts it to HLS.\n    Returns the converted image (3 channels)\n    """\n    hls_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n    return hls_image\n\ndef merge_channels(images):\n    """\n    Merge images from three different channels\n     - images: a list of 3 images, each in a channel\n    """\n    combined_lines_image = weighted_img(images[0], images[1], α=0.5, β=0.5, λ=0.0)\n    combined_lines_image = weighted_img(combined_lines_image, images[2], α=1.0, β=0.5, λ=0.0)\n    return combined_lines_image\n\ndef lane_detection_ppline_3_channels(image, k_size=3, vertex_ratio_h=0.45, vertex_ratio_v=0.6, low_thresh=50, high_thresh=200, L2gradient=False, rho=2, theta=1 * np.pi / 180.0, min_votes=15, min_line_len=40, max_line_gap=20, angle=3 * np.pi / 16, angle_thresh=np.pi / 16, debug=False):\n    """\n    Takes an image and parameters and applies the lane detection pipeline.\n    Returns an image combining the original and the extended lines detected\n    by the algorithm.\n     - debug: Whether or not to display the images after each step of the process, for\n     debugging or tuning purposes.\n    """\n    max_y, max_x = image.shape[:2]\n    roi = np.array([[(0, max_y), (round(max_x * vertex_ratio_h), round(max_y * vertex_ratio_v)), (round(max_x * (1 - vertex_ratio_h)), round(max_y * vertex_ratio_v)), (max_x, max_y)]])\n    if debug:\n        plt.subplot(5, 3, 1)\n        plt.imshow(image)\n    blur = gaussian_blur(image, k_size)\n    if debug:\n        plt.subplot(5, 3, 2)\n        plt.imshow(blur)\n    hls = rbg_to_hls(blur)\n    if debug:\n        plt.subplot(5, 3, 3)\n        plt.imshow(hls)\n    edges_list = []\n    for chan in range(0, 3):\n        edges_list.append(canny(hls[:, :, chan], low_thresh, high_thresh, L2gradient=L2gradient))\n        if debug:\n            plt.subplot(5, 3, chan + 4)\n            plt.imshow(edges_list[chan])\n    masked_edges_list = []\n    for chan in range(0, 3):\n        masked_edges_list.append(region_of_interest(edges_list[chan], roi))\n        if debug:\n            plt.subplot(5, 3, chan + 7)\n            plt.imshow(masked_edges_list[chan])\n    lines_list = []\n    for chan in range(0, 3):\n        lines_list.append(hough_lines(masked_edges_list[chan], rho, theta, min_votes, min_line_len, max_line_gap))\n        if debug:\n            plt.subplot(5, 3, chan + 10)\n            plt.imshow(lines_list[chan][0])\n    lines = np.zeros((1, 1, 4))\n    for chan in range(0, 3):\n        lines = np.concatenate((lines, lines_list[chan][1]), axis=0)\n    if debug:\n        hls_lines_image = merge_channels([lines_list[0][0], lines_list[1][0], lines_list[2][0]])\n        plt.subplot(5, 3, 13)\n        plt.imshow(hls_lines_image)\n    try:\n        combined = extend_lines(image, lines, angle=angle, angle_thresh=angle_thresh)\n        if debug:\n            plt.subplot(5, 3, 14)\n            plt.imshow(combined)\n    except IndexError:\n        print(\'Error. Try relaxing your angle parameters a litte.\')\n    return combined\n\ndef process_image_3_channels(image, k_size=3, vertex_ratio_h=0.45, vertex_ratio_v=0.6, low_thresh=50, high_thresh=200, L2gradient=False, rho=2, theta=1 * np.pi / 180.0, min_votes=15, min_line_len=40, max_line_gap=20, angle=3 * np.pi / 16, angle_thresh=np.pi / 16, debug=False):\n    hours_scores_correlation = lane_detection_ppline_3_channels(image, k_size=k_size, low_thresh=low_thresh, high_thresh=high_thresh, L2gradient=L2gradient, rho=rho, theta=theta, min_votes=min_votes, min_line_len=min_line_len, max_line_gap=max_line_gap, angle=angle, angle_thresh=angle_threshold, debug=debug)\n    return hours_scores_correlation\n```'}, {'reason': 'stop', 'result': "```python\nI = Variable(name='I', num_states=2)\nS = Variable(name='S', num_states=2)\nST = Variable(name='ST', num_states=2)\nF = Variable(name='F', num_states=2)\nB = Variable(name='B', num_states=2)\nC = Variable(name='C', num_states=2)\nW = Variable(name='W', num_states=2)\nf_I = Factor(name='p(I)', f=np.array([0.95, 0.05]), neighbours=[I])\nf_S = Factor(name='p(S)', f=np.array([0.8, 0.2]), neighbours=[S])\nprob_ST = [[0.999, 0.7], [0.001, 0.3]]\nf_ST = Factor(name='p(ST |I)', f=np.array(prob_ST), neighbours=[ST, I])\ngraphical_model_variables = [[0.95, 0.1], [0.05, 0.9]]\nf_F = Factor(name='p(F |I)', f=np.array(graphical_model_variables), neighbours=[F, I])\nprob_B = [[[0.9999, 0.3], [0.1, 0.01]], [[0.0001, 0.7], [0.9, 0.99]]]\nf_B = Factor(name='p(B |I, S)', f=np.array(prob_B), neighbours=[B, I, S])\nprob_C = [[0.93, 0.2], [0.07, 0.8]]\nf_C = Factor(name='p(C |B)', f=np.array(prob_C), neighbours=[C, B])\nprob_W = [[0.999, 0.4], [0.001, 0.6]]\nf_W = Factor(name='p(W |B)', f=np.array(prob_W), neighbours=[W, B])\n```"}, {'reason': 'stop', 'result': "```python\nheprowPath = '/home/pyne-user/Dropbox/UCB/Research/ETAs/88Inch/Data/Experiments/PHS/33MeVTa_29-31Mar17/Unfold/BeamOnly/HEPROW/'\nheprowName = 'mik_Det0_1.gru'\nunfanaName = 'unf_Det0_1.gru'\ngravelName = 'grv_out_Det0_1.flu'\nfaltwPHSName = 'faltw_Det0_1.phs'\nmeasPHSName = 'Inputs/Det0_stat_100_phs_03.phs'\nmtxName = 'MIEKE_Det0_1.MTX'\nheprowBinBounds = 'low'\nmeuldersPath = '/home/pyne-user/Dropbox/UCB/Research/ETAs/88Inch/Data/Experiments/PHS/33MeVTa_29-31Mar17/Unfold/'\nmeuldersName = 'Meulders33MeVTaSpectrum_1.txt'\nmeuldersBinBounds = 'up'\nmcnpPath = '/home/pyne-user/Dropbox/UCB/Research/ETAs/88Inch/Data/Simulated/PHS/33MeVTa/BeamOnly/Model/NoExtrap_Void_1deg/'\nmcnpName = '33MeVTaBeamOnly_Det.out'\nmcnpBinBounds = 'up'\neta_data_directory = '/home/pyne-user/Dropbox/UCB/Research/ETAs/88Inch/Data/Experiments/PHS/33MeVTa_29-31Mar17/Unfold/BeamOnly/HEPROW/'\n```"}, {'reason': 'stop', 'result': "```python\nncomponents = 2\npca = decomp.PCA(n_components=ncomponents)\nraw_pca = pca.fit(np.array(x_train.iloc[:, first_egemaps_feature:]).astype(np.float))\nx_pca = raw_pca.transform(x_train.iloc[:, first_egemaps_feature:])\ngroups = x_train['pos']\nshort_pos = {'nouns': 'nn', 'verbs': 'vrb', 'other': 'oth', 'function_words': 'fct', 'adjectives': 'adj'}\ngroup_values = [short_pos[i] for i in groups.unique()]\nposIDs = groups.factorize()[0]\nlabels = np.array(x_train['word'])\nfig = plt.figure()\nax = fig.add_subplot(111)\nax.set_xlabel('PC 1')\nax.set_ylabel('PC 2')\ncolormap = plt.get_cmap('gnuplot', len(group_values))\npc1 = x_pca[:, 0]\npc2 = x_pca[:, 1]\np = ax.scatter(pc1, pc2, c=posIDs, cmap=colormap, s=10)\ncb = plt.colorbar(p)\nloc = np.arange(0, max(posIDs), max(posIDs) / float(len(group_values)))\ncb.set_ticks(loc)\ncb.set_ticklabels(group_values)\nfor label, x, y in zip(labels, pc1, pc2):\n    if y == np.amax(y) or x == np.amax(x):\n        plt.annotate(label, fontsize=2, xy=(x, y), xytext=(0, 1), textcoords='offset points', ha='right', va='bottom')\nif pos_filter == None:\n    axins = zoomed_inset_axes(ax, 2.5, loc=2)\n    x1, zoomed_inset_x_limit, y1, y2 = (-3.1, 2.5, 6.3, 9.8)\n    axins.set_xlim(x1, zoomed_inset_x_limit)\n    axins.set_ylim(y1, y2)\n    axins.scatter(pc1, pc2, c=posIDs, cmap=colormap)\n    plt.yticks(visible=False)\n    plt.xticks(visible=False)\n    mark_inset(ax, axins, loc1=2, loc2=4, fc='none', ec='0.5')\n    for label, x, y in zip(labels, pc1, pc2):\n        if y == np.amax(y) or x == np.amax(x):\n            plt.annotate(label, fontsize=8, xy=(x, y), xytext=(0, 1), textcoords='offset points', ha='right', va='bottom')\n    axins2 = zoomed_inset_axes(ax, 2.5, loc=4)\n    x1, zoomed_inset_x_limit, y1, y2 = (-4, 0.5, -8.5, -6.5)\n    axins2.set_xlim(x1, zoomed_inset_x_limit)\n    axins2.set_ylim(y1, y2)\n    axins2.scatter(pc1, pc2, c=posIDs, cmap=colormap)\n    plt.yticks(visible=False)\n    plt.xticks(visible=False)\n    mark_inset(ax, axins2, loc1=2, loc2=4, fc='none', ec='0.5')\n    for label, x, y in zip(labels, pc1, pc2):\n        if y == np.amax(y) or x == np.amax(x):\n            plt.annotate(label, fontsize=8, xy=(x, y), xytext=(0, 1), textcoords='offset points', ha='right', va='bottom')\nfilename = corpus + '_full_zoom.pdf'\nif pos_filter != None and len(pos_filter) == 1:\n    filename = corpus + '_pca_' + pos_filter[0][1] + '_' + pos_filter[0][2] + '.pdf'\nplt.savefig(filename, bbox_inches='tight')\n```"}, {'reason': 'stop', 'result': "```python\nRTanalysis = pd.DataFrame()\nlists = [[] for list in range(0, 5)]\nfor ID in range(10, 86):\n    sub = cdat[cdat.subject == ID]\n    lists[0].append(ID)\n    validRT_trials = sub[sub.TrialType == 'Valid'].RT.mean()\n    invalidRT_mean = sub[sub.TrialType == 'Invalid'].RT.mean()\n    lists[1].append(validRT_trials)\n    lists[2].append(invalidRT_mean)\nRTanalysis['SubjectID'] = lists[0]\nRTanalysis['Valid'] = lists[1]\nRTanalysis['Invalid'] = lists[2]\n```"}, {'reason': 'stop', 'result': '```python\nuncontrolled_charging_algorithm = algorithms.UncontrolledCharging()\n```'}, {'reason': 'stop', 'result': '```python\nnA = 100\nvariant_A_conversion = 20\nnB = 90\nxB = 25\nBayes_AB_test(nA=nA, xA=variant_A_conversion, nB=nB, xB=xB)\n```'}, {'reason': 'stop', 'result': '```python\ndef sgd_iter(x_train, t_train, W, b):\n    indices = np.arange(len(x_train))\n    np.random.shuffle(indices)\n    lr = 0.0001\n    log_likelihoods = np.zeros(len(x_train))\n    for i in indices:\n        x = x_train[i:i + 1]\n        t = t_train[i]\n        log_likelihoods[i], grad_w, grad_b = logreg_gradient(x, t, W, b)\n        W = W + lr * grad_w\n        b = b + lr * grad_b\n    logp_train = log_likelihoods.mean()\n    return (logp_train, W, b)\n```'}, {'reason': 'stop', 'result': '```python\nnum_hidden_units = 32\nkernel_size = 5\nn_hidden = 11\nstateful = False\n```'}, {'reason': 'stop', 'result': "```python\nfor i in range(len(multiplier)):\n    scale = multiplier[i]\n    imageToTest = cv.resize(oriImg, (0, 0), fx=scale, fy=scale, interpolation=cv.INTER_CUBIC)\n    imageToTest_padded, pad = padRightDownCorner(imageToTest, 8, 128)\n    transposeImage = np.transpose(np.float32(imageToTest_padded[:, :, :]), (2, 0, 1)) / 256 - 0.5\n    testimage = transposeImage\n    cmodel = mx.mod.Module(symbol=sym, label_names=[])\n    cmodel.bind(data_shapes=[('data', (1, 3, testimage.shape[1], testimage.shape[2]))])\n    cmodel.init_params(arg_params=arg_params, aux_params=aux_params)\n    onedata = DataBatch(mx.nd.array([testimage[:, :, :]]), 0)\n    cmodel.forward(onedata)\n    result = cmodel.get_outputs()\n    heatmap = np.moveaxis(result[1].asnumpy()[0], 0, -1)\n    heatmap = cv.resize(heatmap, (0, 0), fx=model['stride'], fy=model['stride'], interpolation=cv.INTER_CUBIC)\n    heatmap = heatmap[:imageToTest_padded.shape[0] - pad[2], :imageToTest_padded.shape[1] - pad[3], :]\n    heatmap = cv.resize(heatmap, (oriImg.shape[1], oriImg.shape[0]), interpolation=cv.INTER_CUBIC)\n    heatmap_avg = heatmap_avg + heatmap / len(multiplier)\n    f = plt.figure(i)\n    plt.imshow(oriImg[:, :, [2, 1, 0]])\n    keypoint_heatmap = plt.imshow(heatmap[:, :, 18], alpha=0.5)\n    f.show()\n```"}, {'reason': 'stop', 'result': "```python\nscores_auc = [auroc_msr, auroc_margin, auroc_entropy, auroc_dropout, auroc_gmm, auroc_svm, auroc_df]\nfalse_positive_rates = [fpr_msr, fpr_margin, fpr_entropy, fpr_dropout, fpr_gmm, fpr_svm, fpr_df]\ntprs = [tpr_msr, tpr_margin, tpr_entropy, tpr_dropout, tpr_gmm, tpr_svm, tpr_df]\nscores_order = np.argsort(scores_auc)\ncolors_lines = plt.cm.rainbow(np.linspace(0, 1, len(scores_auc)))[:, :3]\nfig = plt.figure(figsize=(6, 6))\nfor i in scores_order:\n    plt.step(false_positive_rates[i], tprs[i], where='post', c=colors_lines[i])\nplt.plot([0, 1], [0, 1], '--', c='gray')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.ylim([0.0, 1.05])\nplt.xlim([0.0, 1.0])\nplt.grid(alpha=0.3)\nfig.axes[0].spines['right'].set_visible(False)\nfig.axes[0].spines['top'].set_visible(False)\nplt.legend([str.format('%s: %.2f') % (names_methods[i], scores_auc[i]) for i in scores_order], title='AUROC')\nplt.savefig('../Figures/Zurich/Metrics/ROC_pred_ED.pdf', bbox_inches='tight', pad_inches=0)\n```"}, {'reason': 'stop', 'result': "```python\nsoftmax_logits = tf.nn.softmax(logits)\ntop_k = tf.nn.top_k(softmax_logits, k=3)\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    saver = tf.train.import_meta_graph('./lenet.meta')\n    saver.restore(sess, './lenet')\n    batch_x = np.expand_dims(my_images_normalized, axis=3)\n    sample_softmax_logits = sess.run(softmax_logits, feed_dict={x: batch_x, keep_prob: 1.0})\n    my_top_k = sess.run(top_k, feed_dict={x: batch_x, keep_prob: 1.0})\n    fig, axs = plt.subplots(len(my_images), 1, figsize=(20, 25))\n    fig.subplots_adjust(hspace=1.0, wspace=0.6)\n    axs = axs.ravel()\n    for i, image in enumerate(my_images):\n        axs[i].axis('off')\n        axs[i].imshow(cv.cvtColor(image, cv.COLOR_BGR2RGB))\n        guess1 = my_top_k[1][i][0]\n        index1 = np.argwhere(y_valid == guess1)[0]\n        guess2 = my_top_k[1][i][1]\n        index2 = np.argwhere(y_valid == guess2)[0]\n        third_guess_index = my_top_k[1][i][2]\n        index3 = np.argwhere(y_valid == third_guess_index)[0]\n        title = ''\n        title += 'guess 1: class ' + sign_dict[str(guess1)] + ', probability: ' + str(100 * my_top_k[0][i][0]) + '\\n'\n        title += 'guess 2: class ' + sign_dict[str(guess2)] + ', probability: ' + str(100 * my_top_k[0][i][1]) + '\\n'\n        title += 'guess 3: class ' + sign_dict[str(third_guess_index)] + ', probability: ' + str(100 * my_top_k[0][i][2])\n        axs[i].set_title(title)\n```"}, {'reason': 'stop', 'result': "```python\nQHrev = dfq.Revenue.max()[3]\nQHLoss = dfq.Revenue.min()[3]\nQmax = max(dfq.idxmax())\nmin_loss_quarter = min(dfq.idxmin())\nprint('Highest Grossing Quarterly Revenue of $%.0f was observed on the %s %s-quarter.' % (QHrev, Qmax[0], Qmax[1]))\nprint('Biggest Quarterly Loss of $%.00f was observed on the %s %s-quarter.' % (QHLoss, min_loss_quarter[0], min_loss_quarter[1]))\n```"}, {'reason': 'stop', 'result': '```python\ndef process_image(image):\n    """ Filter color """\n    color_select = np.copy(image)\n    color_thresholds = [200, 150, 95]\n    thresholds = (image[:, :, 0] < color_thresholds[0]) | (image[:, :, 1] < color_thresholds[1]) | (image[:, :, 2] < color_thresholds[2])\n    color_select[thresholds] = [0, 0, 0]\n    gray = grayscale(color_select)\n    blurred = gaussian_blur(gray, 3)\n    edges = canny(blurred, 50, 150)\n    xsize = image.shape[1]\n    ysize = image.shape[0]\n    vertices = np.array([[(0, ysize), (xsize / 2, ysize / 1.71), (xsize / 2, ysize / 1.71), (xsize, ysize)]], dtype=np.int32)\n    regioned = region_of_interest(edges, vertices)\n    hough = hough_lines(regioned, 1, np.pi / 180, 35, 35, 20)\n    result = weighted_img(hough, image)\n    return result\n```'}, {'reason': 'stop', 'result': '```python\ndef rbg_to_hls(img):\n    """ \n    Takes an RGB image and converts it to HLS.\n    Returns the converted image (3 channels)\n    """\n    hls_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n    return hls_image\n\ndef merge_channels(images):\n    """\n    Merge images from three different channels\n     - images: a list of 3 images, each in a channel\n    """\n    merged = weighted_img(images[0], images[1], α=0.5, β=0.5, λ=0.0)\n    merged = weighted_img(merged, images[2], α=1.0, β=0.5, λ=0.0)\n    return merged\n\ndef lane_detection_ppline_3_channels(image, k_size=3, vertex_ratio_h=0.45, vertex_ratio_v=0.6, low_thresh=50, high_thresh=200, L2gradient=False, rho=2, theta=1 * np.pi / 180.0, min_votes=15, min_line_len=40, max_line_gap=20, angle=3 * np.pi / 16, angle_thresh=np.pi / 16, debug=False):\n    """\n    Takes an image and parameters and applies the lane detection pipeline.\n    Returns an image combining the original and the extended lines detected\n    by the algorithm.\n     - debug: Whether or not to display the images after each step of the process, for\n     debugging or tuning purposes.\n    """\n    max_y, max_x = image.shape[:2]\n    roi = np.array([[(0, max_y), (round(max_x * vertex_ratio_h), round(max_y * vertex_ratio_v)), (round(max_x * (1 - vertex_ratio_h)), round(max_y * vertex_ratio_v)), (max_x, max_y)]])\n    if debug:\n        plt.subplot(5, 3, 1)\n        plt.imshow(image)\n    blur = gaussian_blur(image, k_size)\n    if debug:\n        plt.subplot(5, 3, 2)\n        plt.imshow(blur)\n    hls = rbg_to_hls(blur)\n    if debug:\n        plt.subplot(5, 3, 3)\n        plt.imshow(hls)\n    canny_edges = []\n    for chan in range(0, 3):\n        canny_edges.append(canny(hls[:, :, chan], low_thresh, high_thresh, L2gradient=L2gradient))\n        if debug:\n            plt.subplot(5, 3, chan + 4)\n            plt.imshow(canny_edges[chan])\n    masked_edges_list = []\n    for chan in range(0, 3):\n        masked_edges_list.append(region_of_interest(canny_edges[chan], roi))\n        if debug:\n            plt.subplot(5, 3, chan + 7)\n            plt.imshow(masked_edges_list[chan])\n    lines_list = []\n    for chan in range(0, 3):\n        lines_list.append(hough_lines(masked_edges_list[chan], rho, theta, min_votes, min_line_len, max_line_gap))\n        if debug:\n            plt.subplot(5, 3, chan + 10)\n            plt.imshow(lines_list[chan][0])\n    lines = np.zeros((1, 1, 4))\n    for chan in range(0, 3):\n        lines = np.concatenate((lines, lines_list[chan][1]), axis=0)\n    if debug:\n        hls_lines_image = merge_channels([lines_list[0][0], lines_list[1][0], lines_list[2][0]])\n        plt.subplot(5, 3, 13)\n        plt.imshow(hls_lines_image)\n    try:\n        combined = extend_lines(image, lines, angle=angle, angle_thresh=angle_thresh)\n        if debug:\n            plt.subplot(5, 3, 14)\n            plt.imshow(combined)\n    except IndexError:\n        print(\'Error. Try relaxing your angle parameters a litte.\')\n    return combined\n\ndef process_image_3_channels(image, k_size=3, vertex_ratio_h=0.45, vertex_ratio_v=0.6, low_thresh=50, high_thresh=200, L2gradient=False, rho=2, theta=1 * np.pi / 180.0, min_votes=15, min_line_len=40, max_line_gap=20, angle=3 * np.pi / 16, angle_thresh=np.pi / 16, debug=False):\n    hours_scores_correlation = lane_detection_ppline_3_channels(image, k_size=k_size, low_thresh=low_thresh, high_thresh=high_thresh, L2gradient=L2gradient, rho=rho, theta=theta, min_votes=min_votes, min_line_len=min_line_len, max_line_gap=max_line_gap, angle=angle, angle_thresh=angle_threshold, debug=debug)\n    return hours_scores_correlation\n```'}, {'reason': 'stop', 'result': "```python\nfig = plt.figure(figsize=(8, 6))\nx = df_county_data['Speak a language other than English']\ny = df_county_data['Graduation Rate']\nplt.scatter(x, y, color='g', marker='o', alpha=0.9)\nvalid_data_points = ~np.isnan(x) & ~np.isnan(y)\nsns.regplot(df_county_data['Speak a language other than English'], df_county_data['Graduation Rate'], color='r', label='Speak a language other than English')\nplt.title('High School Graduation Rates and ESL by County')\nplt.ylabel('Graduation Rate')\nplt.xlabel('Speak a language other than English')\nplt.legend(loc='best')\nplt.grid(True)\nsns.set_style('whitegrid')\nplt.text(65, 0.925, 'Note:\\nAreas with one or more Foreign languages beside English language \\ntend to have a Lower graduation rate.')\nplt.savefig('Images/County_Grad_Speak a language other than English3.png', bbox_inches='tight')\nplt.show()\n```"}, {'reason': 'stop', 'result': "```python\ndef get_wide_deep():\n    categorical_features, mother_age, plurality, gestation_weeks = [tf.feature_column.categorical_column_with_vocabulary_list('is_male', ['True', 'False', 'Unknown']), tf.feature_column.numeric_column('mother_age'), tf.feature_column.categorical_column_with_vocabulary_list('plurality', ['Single(1)', 'Twins(2)', 'Triplets(3)', 'Quadruplets(4)', 'Quintuplets(5)', 'Multiple(2+)']), tf.feature_column.numeric_column('gestation_weeks')]\n    age_buckets = tf.feature_column.bucketized_column(mother_age, boundaries=np.arange(15, 45, 1).tolist())\n    gestation_buckets = tf.feature_column.bucketized_column(gestation_weeks, boundaries=np.arange(17, 47, 1).tolist())\n    wide = [categorical_features, plurality, age_buckets, gestation_buckets]\n    crossed = tf.feature_column.crossed_column(wide, hash_bucket_size=20000)\n    embed = tf.feature_column.embedding_column(crossed, 3)\n    deep = [mother_age, gestation_weeks, embed]\n    return (wide, deep)\n```"}, {'reason': 'stop', 'result': "```python\nDEBUG = False\nJPEG_EXTENSIONS = ('.jpeg', '.JPEG', '.jpg', '.JPG')\nimage_dir = '../data/images'\ntest_images_dir = '../data/test_images'\nstored_images_resized = '../data/images_resized'\nbottleneck_directory = '../data/bottlenecks'\ntmp_dir = '/tmp'\nbottleneck_dir = os.path.join(tmp_dir, 'bottlenecks')\nimages_resized_dir = os.path.join(tmp_dir, 'images_resized')\nsummaries_dir = os.path.join(tmp_dir, 'retrain_logs')\nmodel_dir = os.path.join(tmp_dir, 'inception')\ninception_url = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'\noutput_graph_orig = 'output_graph_orig.pb'\noutput_graph = 'output_graph.pb'\noutput_labels = 'output_labels.txt'\narchitecture = 'inception_v3'\nfinal_tensor_name = 'final_result'\nhow_many_training_steps = 500\nlearning_rate = 0.01\ntesting_percentage = 10\nvalidation_percentage = 10\neval_step_interval = 10\ntrain_batch_size = 100\ntest_batch_size = -1\nvalidation_batch_size = 100\nprint_misclassified_test_images = False\nflip_left_right = False\nrandom_crop = 0\nrandom_scale = 0\nrandom_brightness = 0\nforce_inception_download = False\nFLAGS = type('FlagsObject', (object,), {'architecture': architecture, 'model_dir': model_dir, 'intermediate_store_frequency': 0, 'summaries_dir': summaries_dir, 'learning_rate': learning_rate, 'image_dir': images_resized_dir, 'testing_percentage': testing_percentage, 'validation_percentage': validation_percentage, 'random_scale': random_scale, 'random_crop': random_crop, 'flip_left_right': flip_left_right, 'random_brightness': random_brightness, 'bottleneck_dir': bottleneck_directory, 'final_tensor_name': final_tensor_name, 'how_many_training_steps': how_many_training_steps, 'train_batch_size': train_batch_size, 'test_batch_size': test_batch_size, 'eval_step_interval': eval_step_interval, 'validation_batch_size': validation_batch_size, 'print_misclassified_test_images': print_misclassified_test_images, 'output_graph': output_graph, 'output_labels': output_labels})\nretrain.FLAGS = FLAGS\n```"}, {'reason': 'stop', 'result': "```python\ndef process_image(img):\n    warped, mask = perspect_transform(img, source, destination)\n    threshed = color_thresh(warped)\n    obs_map = np.absolute(np.float32(threshed) - 1) * mask\n    xpix, ypix = rover_coords(threshed)\n    world_size = data.worldmap.shape[0]\n    scale = 2 * dst_size\n    xpos = data.xpos[data.count]\n    ypos = data.ypos[data.count]\n    yaw = data.yaw[data.count]\n    x_world, y_world = pix_to_world(xpix, ypix, xpos, ypos, yaw, world_size, scale)\n    obsxpix, obsypix = rover_coords(obs_map)\n    obs_x_world, obs_y_world = pix_to_world(obsxpix, obsypix, xpos, ypos, yaw, world_size, scale)\n    data.worldmap[y_world, x_world, 2] = 255\n    data.worldmap[obs_y_world, obs_x_world, 0] = 255\n    nav_pix = data.worldmap[:, :, 2] > 0\n    data.worldmap[nav_pix, 0] = 0\n    rock_map = find_rocks(warped, levels=(110, 110, 50))\n    if rock_map.any():\n        rock_coords, rock_y = rover_coords(rock_map)\n        rock_x_world, rock_y_world = pix_to_world(rock_coords, rock_y, xpos, ypos, yaw, world_size, scale)\n        data.worldmap[rock_y_world, rock_x_world, :] = 255\n    output_image = np.zeros((img.shape[0] + data.worldmap.shape[0], img.shape[1] * 2, 3))\n    output_image[0:img.shape[0], 0:img.shape[1]] = img\n    output_image[0:img.shape[0], img.shape[1]:] = warped\n    map_add = cv2.addWeighted(data.worldmap, 1, data.ground_truth, 0.5, 0)\n    output_image[img.shape[0]:, 0:data.worldmap.shape[1]] = np.flipud(map_add)\n    cv2.putText(output_image, 'Populate this image with your analyses to make a video!', (20, 20), cv2.FONT_HERSHEY_COMPLEX, 0.4, (255, 255, 255), 1)\n    if data.count < len(data.images) - 1:\n        data.count += 1\n    return output_image\n```"}, {'reason': 'stop', 'result': '```python\nimport math\nleft_lane_line = [(0, 0, 0, 0)]\nrightline = [(0, 0, 0, 0)]\n\ndef grayscale(img):\n    """Applies the Grayscale transform\n    This will return an image with only one color channel\n    but NOTE: to see the returned image as grayscale\n    (assuming your grayscaled image is called \'gray\')\n    you should call plt.imshow(gray, cmap=\'gray\')"""\n    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n\ndef canny(img, low_threshold, high_threshold):\n    """Applies the Canny transform"""\n    return cv2.Canny(img, low_threshold, high_threshold)\n\ndef gaussian_blur(img, kernel_size):\n    """Applies a Gaussian Noise kernel"""\n    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n\ndef region_of_interest(img, vertices):\n    """\n    Applies an image mask.\n    \n    Only keeps the region of the image defined by the polygon\n    formed from `vertices`. The rest of the image is set to black.\n    """\n    mask = np.zeros_like(img)\n    if len(img.shape) > 2:\n        channel_count = img.shape[2]\n        ignore_mask_color = (255,) * channel_count\n    else:\n        ignore_mask_color = 255\n    cv2.fillPoly(mask, vertices, ignore_mask_color)\n    masked_image = cv2.bitwise_and(img, mask)\n    return masked_image\n\ndef draw_lines(img, lines, color=[255, 0, 0], thickness=2):\n    """\n    NOTE: this is the function you might want to use as a starting point once you want to \n    average/extrapolate the line segments you detect to map out the full\n    extent of the lane (going from the result shown in raw-lines-example.mp4\n    to that shown in P1_example.mp4).  \n    \n    Think about things like separating line segments by their \n    slope ((y2-y1)/(x2-x1)) to decide which segments are part of the left\n    line vs. the right line.  Then, you can average the position of each of \n    the lines and extrapolate to the top and bottom of the lane.\n    \n    This function draws `lines` with `color` and `thickness`.    \n    Lines are drawn on the image inplace (mutates the image).\n    If you want to make the lines semi-transparent, think about combining\n    this function with the weighted_img() function below\n    """\n    for line in lines:\n        for x1, y1, x2, y2 in line:\n            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n\ndef draw_lines_roi(img, lines, vertices, color=[255, 0, 0], thickness=2):\n    """\n    NOTE: this is the function you might want to use as a starting point once you want to \n    average/extrapolate the line segments you detect to map out the full\n    extent of the lane (going from the result shown in raw-lines-example.mp4\n    to that shown in P1_example.mp4).  \n    \n    Think about things like separating line segments by their \n    slope ((y2-y1)/(x2-x1)) to decide which segments are part of the left\n    line vs. the right line.  Then, you can average the position of each of \n    the lines and extrapolate to the top and bottom of the lane.\n    \n    This function draws `lines` with `color` and `thickness`.    \n    Lines are drawn on the image inplace (mutates the image).\n    If you want to make the lines semi-transparent, think about combining\n    this function with the weighted_img() function below\n    """\n    global left_lane_line\n    global rightline\n    imshape = img.shape\n    y_min = np.int(imshape[0] * 0.61)\n    y_max = imshape[0]\n    left_x1 = []\n    left_x2 = []\n    right_x1 = []\n    right_x2 = []\n    left_count = 0\n    right_count = 0\n    for line in lines:\n        for x1, y1, x2, y2 in line:\n            m = (y2 - y1) / (x2 - x1)\n            if (m > 0.3) & (m < 7):\n                fit = np.polyfit([x1, x2], [y1, y2], 1)\n                right_x1.append(np.int(np.float(y_min - fit[1]) / np.float(fit[0])))\n                right_x2.append(np.int(np.float(y_max - fit[1]) / np.float(fit[0])))\n                right_count += 1\n            if (m < -0.3) & (m > -7):\n                fit = np.polyfit([x1, x2], [y1, y2], 1)\n                left_x1.append(np.int(np.float(y_min - fit[1]) / np.float(fit[0])))\n                left_x2.append(np.int(np.float(y_max - fit[1]) / np.float(fit[0])))\n                left_count += 1\n    if left_count > 0:\n        left_lane_line = np.int(np.nanmedian(left_x1))\n        left_line_x2 = np.int(np.nanmedian(left_x2))\n        if leftline[0][2] != 0:\n            if (abs(leftline[0][2] - left_line_x2) < 100) & (abs(leftline[0][0] - left_lane_line) < 50):\n                leftline = [(left_lane_line, y_min, left_line_x2, y_max)]\n        else:\n            leftline = [(left_lane_line, y_min, left_line_x2, y_max)]\n    if right_count > 0:\n        right_line_x1 = np.int(np.nanmedian(right_x1))\n        right_line_x2 = np.int(np.nanmedian(right_x2))\n        if rightline[0][2] != 0:\n            if (abs(rightline[0][2] - right_line_x2) < 100) & (abs(rightline[0][0] - right_line_x1) < 50):\n                rightline = [(right_line_x1, y_min, right_line_x2, y_max)]\n        else:\n            rightline = [(right_line_x1, y_min, right_line_x2, y_max)]\n    newlines = [leftline, rightline]\n    draw_lines(img, newlines, color, thickness)\n    return img\n\ndef hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap, vertices):\n    """\n    `img` should be the output of a Canny transform.\n        \n    Returns an image with hough lines drawn.\n    """\n    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n    result = draw_lines_roi(line_img, lines, vertices, [255, 0, 0], 14)\n    return result\n\ndef weighted_img(img, initial_img, α=0.8, β=1.0, λ=0.0):\n    """\n    `img` is the output of the hough_lines(), An image with lines drawn on it.\n    Should be a blank image (all black) with lines drawn on it.\n    \n    `initial_img` should be the image before any processing.\n    \n    The result image is computed as follows:\n    \n    initial_img * α + img * β + λ\n    NOTE: initial_img and img must be the same shape!\n    """\n    return cv2.addWeighted(initial_img, α, img, β, λ)\n```'}, {'reason': 'stop', 'result': "```python\ntime_range = (vsig.timestamps[0], vsig.timestamps[-1])\nlayer = '2'\no_or_s = 'output'\nval_arrays = np.load(os.path.join(vsig.out_dir, '_'.join(['valid_hidden_layer', layer, o_or_s])) + '.npy')\nn_generations, _, n_neurons = val_arrays.shape\nncols = 2\nnrows = n_neurons // ncols\nfig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(16, 20))\nfor g in range(n_generations):\n    for i in range(n_neurons):\n        ax = axes[i // ncols, i % ncols]\n        ax.cla()\n        y_pred_colors = val_arrays[g, :, i]\n        ax.plot(vsig.timestamps, vsig.mixed_signal, color='grey', alpha=0.3)\n        ax.scatter(vsig.timestamps, x_val[0, :, 0], vsig.timestamps[vsig.window_size - 1:], marker='o', c=y_pred_colors, cmap=plt.get_cmap('coolwarm'), vmin=-1, vmax=1)\n        ax.set_title('neuron = {}'.format(i + 1))\n        ax.set_xlim(time_range)\n        ax.grid(True)\n    plt.tight_layout()\n    plt.suptitle('hidden layer = {}, ({}), generation = {}'.format(layer, o_or_s, g + 1))\n    plt.savefig(os.path.join(vsig.out_dir, '_'.join(['valid_hidden_layer', layer, o_or_s, 'gen', str(g + 1)]) + '.png'))\nplt.show()\n```"}, {'reason': 'stop', 'result': "```python\nrnn_model = torch.load('models/linux_3x512_0d3_lstm_200l_40000E.model').cuda()\nmodel_gru = torch.load('models/linux_3x512_0d3_gru_200l_40000E.model').cuda()\nprint('Perplexity LSTM:', 2 ** np.mean([test_model(rnn_model, 'data/linux/test.txt') for _ in range(1)]))\nprint('Perplexity GRU: ', 2 ** np.mean([test_model(model_gru, 'data/linux/test.txt') for _ in range(1)]))\n```"}, {'reason': 'stop', 'result': "```python\nfrom __future__ import division, print_function\nimport numpy as np\ntry:\n    from pylab import plt\nexcept ImportError:\n    print('Unable to import pylab. R_pca.plot_fit() will not work.')\ntry:\n    range = xrange\nexcept NameError:\n    pass\n\nclass R_pca:\n\n    def __init__(self, D, mu=None, lmbda=None):\n        self.D = D\n        self.S = np.zeros(self.D.shape)\n        self.Y = np.zeros(self.D.shape)\n        if mu:\n            self.mu = mu\n        else:\n            self.mu = np.prod(self.D.shape) / (4 * self.norm_p(self.D, 2))\n        self.mu_inv = 1 / self.mu\n        if lmbda:\n            self.lmbda = lmbda\n        else:\n            self.lmbda = 1 / np.sqrt(np.max(self.D.shape))\n\n    @staticmethod\n    def norm_p(M, p):\n        return np.sum(np.power(M, p))\n\n    @staticmethod\n    def shrink(M, tau):\n        return np.sign(M) * np.maximum(np.abs(M) - tau, np.zeros(M.shape))\n\n    def svd_threshold(self, M, tau):\n        U, S, V = np.linalg.svd(M, full_matrices=False)\n        return np.dot(U, np.dot(np.diag(self.shrink(S, tau)), V))\n\n    def fit(self, tol=None, max_iter=1000, iter_print=100):\n        iter = 0\n        err = np.Inf\n        Sk = self.S\n        Yk = self.Y\n        Lk = np.zeros(self.D.shape)\n        if tol:\n            _tol = tol\n        else:\n            _tol = 1e-07 * self.norm_p(np.abs(self.D), 2)\n        while err > _tol and iter < max_iter:\n            Lk = self.svd_threshold(self.D - Sk + self.mu_inv * Yk, self.mu_inv)\n            Sk = self.shrink(self.D - Lk + self.mu_inv * Yk, self.mu_inv * self.lmbda)\n            Yk = Yk + self.mu * (self.D - Lk - Sk)\n            err = self.norm_p(np.abs(self.D - Lk - Sk), 2)\n            iter += 1\n            if iter % iter_print == 0 or iter == 1 or iter > max_iter or (err <= _tol):\n                print('iteration: {0}, error: {1}'.format(iter, err))\n        self.L = Lk\n        self.S = Sk\n        return (Lk, Sk)\n\n    def plot_fit(self, fit_plot_size=None, tol=0.1, axis_on=True):\n        n, fit_plot_size = self.D.shape\n        if fit_plot_size:\n            nrows, ncols = fit_plot_size\n        else:\n            sq = np.ceil(np.sqrt(n))\n            nrows = int(sq)\n            ncols = int(sq)\n        ymin = np.nanmin(self.D)\n        ymax = np.nanmax(self.D)\n        print('ymin: {0}, ymax: {1}'.format(ymin, ymax))\n        numplots = np.min([n, nrows * ncols])\n        plt.figure()\n        for n in range(numplots):\n            plt.subplot(nrows, ncols, n + 1)\n            plt.ylim((ymin - tol, ymax + tol))\n            plt.plot(self.L[n, :] + self.S[n, :], 'r')\n            plt.plot(self.L[n, :], 'b')\n            if not axis_on:\n                plt.axis('off')\n```"}, {'reason': 'stop', 'result': "```python\nfig, ax1 = plt.subplots()\ntick_locations = [value for value in x_axis]\nplt.xticks(tick_locations, county, rotation=90)\ngraduation_rate = df_county_data['Graduation Rate']\ncounty = df_county_data['County Name']\npov_rate = df_county_data['Speak a language other than English']\nt = np.arange(len(county))\nax1.plot(t, pov_rate, 'b-')\nax1.set_xlabel('county')\nax1.set_ylabel('Speak a language other than English', color='b')\nax1.tick_params('y', colors='b')\nplt.title('High School Graduation Rates and ESL by County')\nax2 = ax1.twinx()\nax2.plot(t, graduation_rate, 'r*')\nax2.set_ylabel('Graduation Rate', color='r')\nax2.tick_params('y', colors='r')\nzoom = 5\nw, h = fig.get_size_inches()\nfig.set_size_inches(w * zoom, h * zoom / 2)\nfig.tight_layout()\nplt.savefig('Images/County_Grad_Speak a language other than English2.png', bbox_inches='tight')\nplt.show()\n```"}, {'reason': 'stop', 'result': '```python\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.metrics import silhouette_score\nx = 3\ngmm_model = GaussianMixture(n_components=x)\ngmm_model.fit(reduced_data)\npreds = gmm_model.predict(reduced_data)\ncenters = gmm_model.means_\nsample_preds = gmm_model.predict(pca_samples)\nscore = silhouette_score(reduced_data, preds)\nprint(x, score)\n```'}, {'reason': 'stop', 'result': "```python\nimage_array[...] = 0\nX = (x - 400) / 30\nY = -(y - 300) / 30\nheart = X ** 2 + (Y - 2 * (X ** 2 + np.abs(X) - 6) / (3 * (X ** 2 + np.abs(X) + 2))) ** 2 < 36\nimage_array[heart] = (1, 0, 0)\nplt.imshow(image_array, interpolation='bilinear')\n```"}, {'reason': 'stop', 'result': "```python\ncolor_matrix[...] = 0\nX = (x - 400) / 30\nY = -(y - 300) / 30\nR = np.sqrt(X ** 2 + Y ** 2)\nt = np.arctan2(Y, X)\ncolor_matrix[R < 5] = (1, 0, 0)\ncolor_matrix[(t > 0) & (t < 3.14 / 4)] = (0, 0, 1)\nplt.imshow(color_matrix, interpolation='bilinear')\n```"}, {'reason': 'stop', 'result': '```python\nfrom sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n\ndef nparray_to_list(nparray):\n    return [x for x in nparray]\n\ndef cv_split(X, y):\n    splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.05)\n    X_np = np.asarray(X)\n    y_np = np.asarray(y)\n    for train_index, valid_index in splitter.split(X_np, y_np):\n        X_train, X_valid = (nparray_to_list(X_np[train_index]), nparray_to_list(X_np[valid_index]))\n        y_train, y_valid = (nparray_to_list(y_np[train_index]), nparray_to_list(y_np[valid_index]))\n    train = (X_train, y_train)\n    valid = (X_valid, y_valid)\n    return (train, valid)\n```'}, {'reason': 'stop', 'result': "```python\nsamples_w_total = samples.copy()\nsamples_w_total['Total'] = samples_w_total.sum(axis=1)\npercentage_spending = samples.loc[:, 'Fresh':'Delicatessen'].div(samples_w_total['Total'], axis=0) * 100\npercentage_spending['Total'] = percentage_spending.sum(axis=1)\npercentage_spending\n```"}, {'reason': 'stop', 'result': "```python\ndef perspect_transform(img, src, dst):\n    M = cv2.getPerspectiveTransform(src, dst)\n    warped = cv2.warpPerspective(img, M, (img.shape[1], img.shape[0]))\n    mask = cv2.warpPerspective(np.ones_like(img[:, :, 0]), M, (img.shape[1], img.shape[0]))\n    return (warped, mask)\ndst_size = 5\nbottom_offset = 6\nperspective_transform_points = np.float32([[14, 140], [301, 140], [200, 96], [118, 96]])\ndestination = np.float32([[image.shape[1] / 2 - dst_size, image.shape[0] - bottom_offset], [image.shape[1] / 2 + dst_size, image.shape[0] - bottom_offset], [image.shape[1] / 2 + dst_size, image.shape[0] - 2 * dst_size - bottom_offset], [image.shape[1] / 2 - dst_size, image.shape[0] - 2 * dst_size - bottom_offset]])\nwarped, mask = perspect_transform(grid_img, perspective_transform_points, destination)\nfig = plt.figure(figsize=(12, 3))\nplt.subplot(121)\nplt.imshow(warped)\nplt.subplot(122)\nplt.imshow(mask, cmap='gray')\n```"}, {'reason': 'stop', 'result': "```python\ndf0_10k = clean_info.loc[clean_info['tuition_cost_tier'] == 'less_10k']\ndf0_10k_edit0 = df0_10k[df0_10k.region != 0]\nfiltered_data_low_cost = df0_10k_edit0[df0_10k_edit0.region != 9]\ndf10_18k = clean_info.loc[clean_info['tuition_cost_tier'] == '10k_18k']\ndf10_18k_edit = df10_18k[df10_18k.region != 9]\ndf18_32 = clean_info.loc[clean_info['tuition_cost_tier'] == '18k_32k']\ndf32 = clean_info.loc[clean_info['tuition_cost_tier'] == 'greater_32k']\n```"}, {'reason': 'stop', 'result': "```python\nDEBUG = False\nJPEG_EXTENSIONS = ('.jpeg', '.JPEG', '.jpg', '.JPG')\nimage_dir = '../data/images'\ntest_images_dir = '../data/test_images'\nstored_images_resized = '../data/images_resized'\nstored_bottlenecks = '../data/bottlenecks'\ntmp_dir = '/tmp'\nbottleneck_dir = os.path.join(tmp_dir, 'bottlenecks')\nimages_resized_dir = os.path.join(tmp_dir, 'images_resized')\nlog_summaries_dir = os.path.join(tmp_dir, 'retrain_logs')\nmodel_dir = os.path.join(tmp_dir, 'inception')\ninception_url = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'\noutput_graph_orig = 'output_graph_orig.pb'\noutput_graph = 'output_graph.pb'\noutput_labels = 'output_labels.txt'\narchitecture = 'inception_v3'\nfinal_tensor_name = 'final_result'\nhow_many_training_steps = 500\nlearning_rate = 0.01\ntesting_percentage = 10\nvalidation_percentage = 10\neval_step_interval = 10\ntrain_batch_size = 100\ntest_batch_size = -1\nvalidation_batch_size = 100\nprint_misclassified_test_images = False\nflip_left_right = False\nrandom_crop = 0\nrandom_scale = 0\nrandom_brightness = 0\nforce_inception_download = False\nFLAGS = type('FlagsObject', (object,), {'architecture': architecture, 'model_dir': model_dir, 'intermediate_store_frequency': 0, 'summaries_dir': log_summaries_dir, 'learning_rate': learning_rate, 'image_dir': images_resized_dir, 'testing_percentage': testing_percentage, 'validation_percentage': validation_percentage, 'random_scale': random_scale, 'random_crop': random_crop, 'flip_left_right': flip_left_right, 'random_brightness': random_brightness, 'bottleneck_dir': bottleneck_dir, 'final_tensor_name': final_tensor_name, 'how_many_training_steps': how_many_training_steps, 'train_batch_size': train_batch_size, 'test_batch_size': test_batch_size, 'eval_step_interval': eval_step_interval, 'validation_batch_size': validation_batch_size, 'print_misclassified_test_images': print_misclassified_test_images, 'output_graph': output_graph, 'output_labels': output_labels})\nretrain.FLAGS = FLAGS\n```"}, {'reason': 'stop', 'result': "```python\nwith tf.variable_scope('train'):\n    if is_time_major:\n        logits = tf.transpose(logits, [1, 0, 2])\n        cross_entropy_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=dataset.tgt_out_ids, logits=logits)\n        target_weights = tf.sequence_mask(dataset.tgt_size, tf.shape(logits)[1], tf.float32)\n    else:\n        cross_entropy_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=dataset.tgt_out_ids, logits=logits)\n        target_weights = tf.sequence_mask(dataset.tgt_size, tf.shape(logits)[1], tf.float32)\n    loss = tf.reduce_sum(cross_entropy_loss * target_weights) / tf.to_float(batch_size)\n    tf.summary.scalar('loss', loss)\n    learning_rate = tf.placeholder(dtype=tf.float32, name='learning_rate')\n    max_global_norm = tf.placeholder(dtype=tf.float32, name='max_global_norm')\n    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=0.5)\n    params = tf.trainable_variables()\n    gradients = tf.gradients(loss, params)\n    for grad, var in zip(gradients, params):\n        tf.summary.histogram(var.op.name + '/gradient', grad)\n    gradients, _ = tf.clip_by_global_norm(gradients, max_global_norm)\n    for grad, var in zip(gradients, params):\n        tf.summary.histogram(var.op.name + '/clipped_gradient', grad)\n    update = optimizer.apply_gradients(zip(gradients, params))\n```"}, {'reason': 'stop', 'result': '```python\ndef recall(labels, predictions, weights=None):\n    confusion_matrix = tf.confusion_matrix(labels, predictions, num_classes=3)\n    tp_and_fn = tf.reduce_sum(confusion_matrix, axis=1)\n    tp = tf.diag_part(confusion_matrix)\n    recall_scores = tp / tp_and_fn\n    if weights:\n        recall_score = tf.multiply(recall_scores, weights) / tf.reduce_sum(weights)\n    else:\n        recall_score = tf.reduce_mean(recall_scores)\n    return recall_score\n```'}, {'reason': 'stop', 'result': "```python\nX_train, y_train = shuffle(X_train_augmented, y_train_augmented)\n\ndef get_random_img(X_data, y_label):\n    index = random.randint(0, len(X_data))\n    image = X_data[index].squeeze()\n    return (image, y_label[index], index)\n\ndef plot_imgs(X_data, y_label):\n    f, axarr = plt.subplots(3, 3, figsize=(16, 16))\n    random_image_indices = []\n    for i in range(9):\n        image, label, index = get_random_img(X_data, y_label)\n        random_image_indices.append(index)\n        label_str = str(label)\n        axarr[i // 3, i % 3].imshow(image, cmap='gray')\n        axarr[i // 3, i % 3].set_title(label_str + ': ' + sign_dict[label_str])\n        plt.setp([a.get_xticklabels() for a in axarr[0, :]], visible=False)\n        plt.setp([a.get_yticklabels() for a in axarr[:, 1]], visible=False)\n    return random_image_indices\nrand_img_indices = plot_imgs(X_train, y_train)\nprint(rand_img_indices)\n```"}, {'reason': 'stop', 'result': '```python\noptimizer = tf.train.GradientDescentOptimizer(0.5)\nneural_network_model = two_layer_nn(output_size=2)\nnum_epochs = 5\nneural_network_model.fit(X, y, optimizer, num_epochs=num_epochs)\n```'}, {'reason': 'stop', 'result': '```python\nfeature_layer_coll_item = feature_layer_srch_results[0]\nfeature_layer_collection = feature_layer_coll_item.layers\nfeature_layer = feature_layer_collection[0]\nfeature_layer.properties.name\n```'}, {'reason': 'stop', 'result': '```python\ndef process_image(image):\n    gray = grayscale(image)\n    kernel_size = 5\n    blurred_gray_image = gaussian_blur(gray, kernel_size)\n    low_threshold = 50\n    high_threshold = 150\n    edges = canny(blurred_gray_image, low_threshold, high_threshold)\n    imshape = image.shape\n    xPct = 0.05\n    yPct = 0.6\n    xbl = imshape[1] * xPct\n    xbr = imshape[1] * (1 - xPct)\n    xtl = imshape[1] * (0.5 - xPct)\n    xtr = imshape[1] * (0.5 + xPct)\n    yb = imshape[0]\n    yt = imshape[0] * yPct\n    vertices = np.array([[(xbl, yb), (xtl, yt), (xtr, yt), (xbr, yb)]], dtype=np.int32)\n    masked_image = region_of_interest(edges, vertices)\n    rho = 2\n    theta = np.pi / 180\n    threshold = 15\n    min_line_len = 20\n    max_line_gap = 30\n    line_img = hough_lines(masked_image, rho, theta, threshold, min_line_len, max_line_gap)\n    overlayedImg = weighted_img(line_img, image, 0.8, 1, 0)\n    return overlayedImg\n```'}, {'reason': 'stop', 'result': "```python\nimage_size = 28\nnum_labels = 10\nchannel_depth = 1\n\ndef reformat(dataset, labels):\n    dataset = dataset.reshape((-1, image_size, image_size, channel_depth)).astype(np.float32)\n    labels = (np.arange(num_labels) == labels[:, None]).astype(np.float32)\n    return (dataset, labels)\ntrain_dataset, train_labels = reformat(train_dataset, train_labels)\nvalid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\ntest_dataset, test_labels = reformat(test_dataset, test_labels)\nprint('Training set', train_dataset.shape, train_labels.shape)\nprint('Validation set', valid_dataset.shape, valid_labels.shape)\nprint('Test set', test_dataset.shape, test_labels.shape)\n```"}, {'reason': 'stop', 'result': "```python\nif 'p' in globals().keys():\n    for key, value in p.items():\n        globals()[key] = value\nelse:\n    m = 64\n    ls = 1\n    ld = 10\n    le = None\n    lg = 1\n    rtol = 1e-05\n    N_inner = 500\n    N_outer = 50\n    Ngenres, Nclips, Nframes = (10, 100, 644)\n    noise_std = 0\n    folder = 'data'\n    filename_audio = 'audio.hdf5'\n    filename_graph = 'graph.hdf5'\n    output_features_file = 'features.hdf5'\n```"}, {'reason': 'stop', 'result': "```python\nimage_file_pattern = '../test_dataset/IMG/*'\nimg_list = glob.glob(image_file_pattern)\nidx = np.random.randint(0, len(img_list) - 1)\nimage = mpimg.imread(img_list[idx])\nplt.imshow(image)\n```"}, {'reason': 'stop', 'result': '```python\nindex = 0\nX[index, :]\n```'}, {'reason': 'stop', 'result': "```python\nfig, ax1 = plt.subplots()\ntick_locations = [value for value in x_axis]\nplt.xticks(tick_locations, county, rotation=90)\ngrad_rate = df_county_data['Graduation Rate']\ncounty = df_county_data['County Name']\npov_rate = df_county_data['Unemployment Rate']\nt = np.arange(len(county))\nax1.plot(t, pov_rate, 'b-')\nax1.set_xlabel('county')\nax1.set_ylabel('Unemployment Rate', color='b')\nax1.tick_params('y', colors='b')\ngraduation_unemployment_plot = ax1.twinx()\nplt.title('High School Graduation Rates and Unemployment Rate by County')\ngraduation_unemployment_plot.plot(t, grad_rate, 'r*')\ngraduation_unemployment_plot.set_ylabel('Graduation Rate', color='r')\ngraduation_unemployment_plot.tick_params('y', colors='r')\nzoom = 5\nw, h = fig.get_size_inches()\nfig.set_size_inches(w * zoom, h * zoom / 2)\nfig.tight_layout()\nplt.savefig('Images/County_Grad_Unemployment Rate1.png', bbox_inches='tight')\nplt.show()\n```"}, {'reason': 'stop', 'result': "```python\nfrom pandas import DataFrame\nfrom pandas import Series\nfrom pandas import concat\nfrom pandas import read_csv\nfrom pandas import datetime\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom math import sqrt\nfrom matplotlib import pyplot\nimport numpy\nshampoo_sales_data_path = '/Users/shengyuchen/Dropbox/Engagement - Business/My Hub/AI:ML:DL Playground/Local Python/AI-ML-DL Algorithms/LSTM Neural Networks/shampoo-sales.csv'\n\ndef parser(x):\n    return datetime.strptime('190' + x, '%Y-%b')\n\ndef timeseries_to_supervised(data, lag=1):\n    df = DataFrame(data)\n    columns = [df.shift(i) for i in range(1, lag + 1)]\n    columns.append(df)\n    df = concat(columns, axis=1)\n    df.fillna(0, inplace=True)\n    return df\n\ndef difference(dataset, interval=1):\n    diff = list()\n    for i in range(interval, len(dataset)):\n        value = dataset[i] - dataset[i - interval]\n        diff.append(value)\n    return Series(diff)\n```"}, {'reason': 'stop', 'result': "```python\nfrom tensorflow.python.framework import ops\nops.reset_default_graph()\nbatch_size = 16\nnum_channels = 5\ndepth = 16\nnum_hidden_full_1 = 96\nnum_hidden_full_2 = 96\ngraph = tf.Graph()\nwith graph.as_default():\n    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n    tf_valid_dataset = tf.constant(valid_dataset)\n    tf_test_dataset = tf.constant(test_dataset)\n    layer3_weights = init_weights([image_size * image_size * 64, num_hidden_full_1])\n    layer3_biases = init_weights([num_hidden_full_1], method='ones')\n    keep3 = tf.placeholder('float')\n    layer4_weights = init_weights([num_hidden_full_1, num_hidden_full_2])\n    layer4_biases = init_weights([num_hidden_full_2], method='ones')\n    keep4 = tf.placeholder('float')\n    layer5_weights = init_weights([num_hidden_full_2, num_labels])\n    layer5_biases = init_weights([num_labels], method='ones')\n    inception_1x1_weights = tf.Variable(tf.truncated_normal([1, 1, num_channels, depth], stddev=0.1))\n    inception_1x1_biases = tf.Variable(tf.zeros([depth]))\n    pre_inception_1x1_weights = tf.Variable(tf.truncated_normal([1, 1, num_channels, depth], stddev=0.1))\n    pre_inception_1x1_biases = tf.Variable(tf.zeros([depth]))\n    inception_1x1_pool_weights = tf.Variable(tf.truncated_normal([1, 1, num_channels, depth], stddev=0.1))\n    inception_1x1_pool_biases = tf.Variable(tf.zeros([depth]))\n    inception_3x3_weights = tf.Variable(tf.truncated_normal([3, 3, depth, depth], stddev=0.1))\n    inception_3x3_biases = tf.Variable(tf.zeros([depth]))\n    inception_5x5_weights = tf.Variable(tf.truncated_normal([5, 5, depth, depth], stddev=0.1))\n    inception_5x5_biases = tf.Variable(tf.zeros([depth]))\n\n    def inception_layer(data):\n        conv_1x1 = tf.nn.conv2d(data, inception_1x1_weights, [1, 1, 1, 1], padding='SAME')\n        conv_1x1 = tf.nn.relu(conv_1x1 + inception_1x1_biases)\n        print('1x1', conv_1x1.get_shape())\n        conv_pre = tf.nn.conv2d(data, pre_inception_1x1_weights, [1, 1, 1, 1], padding='SAME')\n        conv_pre = tf.nn.relu(conv_pre + pre_inception_1x1_biases)\n        conv_pool = tf.nn.avg_pool(data, [1, 3, 3, 1], [1, 1, 1, 1], padding='SAME')\n        conv_pool = tf.nn.conv2d(conv_pool, inception_1x1_pool_weights, [1, 1, 1, 1], padding='SAME')\n        conv_pool = tf.nn.relu(conv_pool + inception_1x1_pool_biases)\n        print('pool', conv_pool.get_shape())\n        conv_3x3 = tf.nn.conv2d(conv_pre, inception_3x3_weights, [1, 1, 1, 1], padding='SAME')\n        conv_3x3 = tf.nn.relu(conv_3x3 + inception_3x3_biases)\n        print('3x3', conv_3x3.get_shape())\n        conv_5x5 = tf.nn.conv2d(conv_pre, inception_5x5_weights, [1, 1, 1, 1], padding='SAME')\n        conv_5x5 = tf.nn.relu(conv_5x5 + inception_5x5_biases)\n        print('5x5', conv_5x5.get_shape())\n        inception_result = tf.concat(3, [conv_1x1, conv_3x3, conv_5x5, conv_pool])\n        print(inception_result.get_shape())\n        return inception_result\n\n    def model(data):\n        hidden = inception_layer(data)\n        shape = hidden.get_shape().as_list()\n        reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n        hidden = tf.nn.elu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n        hidden = tf.nn.dropout(hidden, keep3)\n        hidden = tf.nn.elu(tf.matmul(hidden, layer4_weights) + layer4_biases)\n        hidden = tf.nn.dropout(hidden, keep4)\n        output = tf.matmul(hidden, layer5_weights) + layer5_biases\n        return output\n    logits = model(tf_train_dataset)\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n    optimizer = tf.train.AdamOptimizer(0.0001).minimize(loss)\n    train_prediction = tf.nn.softmax(logits)\n    valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n    test_prediction = tf.nn.softmax(model(tf_test_dataset))\n```"}, {'reason': 'stop', 'result': "```python\ndef engineer_date_range(dates):\n    unprocessed_df = read_s3_csv(dates)\n    print('Loaded CSV data set from S3')\n    cleaned_df = clean_data(unprocessed_df, inplace=True)\n    print('Cleaned CSV data set')\n    engineered_data = create_xgb_features(cleaned_df, 5, inplace=True)\n    engineered_data['NextMaxPrice'] = create_xgb_target(engineered_data)\n    print('Engineered CSV data set')\n    train_data, validate_data = train_test_split(engineered_data, train_size=0.8, test_size=0.2, shuffle=True)\n    cols = list(train_data.columns.values)\n    cols.remove('NextMaxPrice')\n    cols = ['NextMaxPrice'] + cols\n    train_data = pd.get_dummies(train_data[cols])\n    validate_data = pd.get_dummies(validate_data[cols])\n    print('Data split for training purposes')\n    return (train_data, validate_data)\n```"}, {'reason': 'stop', 'result': "```python\nbatch_size = 128\nembedding_size = 128\nskip_window = 1\nnum_skips = 2\nvalid_size = 16\nmax_valid_examples = 100\nvalid_examples = np.array(random.sample(range(max_valid_examples), valid_size))\nnum_sampled = 64\ngraph = tf.Graph()\nwith graph.as_default(), tf.device('/cpu:0'):\n    train_dataset = tf.placeholder(tf.int32, shape=[batch_size])\n    train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n    valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n    embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n    softmax_weights = tf.Variable(tf.truncated_normal([vocabulary_size, embedding_size], stddev=1.0 / math.sqrt(embedding_size)))\n    softmax_biases = tf.Variable(tf.zeros([vocabulary_size]))\n    embed = tf.nn.embedding_lookup(embeddings, train_dataset)\n    loss = tf.reduce_mean(tf.nn.sampled_softmax_loss(weights=softmax_weights, biases=softmax_biases, inputs=embed, labels=train_labels, num_sampled=num_sampled, num_classes=vocabulary_size))\n    optimizer = tf.train.AdagradOptimizer(1.0).minimize(loss)\n    norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n    normalized_embeddings = embeddings / norm\n    valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings, valid_dataset)\n    similarity = tf.matmul(valid_embeddings, tf.transpose(normalized_embeddings))\n```"}, {'reason': 'stop', 'result': "```python\ny_scores = -probas_gmm\nprecision_gmm, recall_gmm, _ = metrics.precision_recall_curve(y_true, y_scores)\npr_auc_gmm = metrics.auc(recall_gmm, precision_gmm)\nroc_curve_fpr_gmm, tpr_gmm, _ = metrics.roc_curve(y_true, y_scores)\nauroc_gmm = metrics.roc_auc_score(y_true, y_scores)\nprint('AUROC: %.2f, PR AUC: %.2f' % (auroc_gmm, pr_auc_gmm))\n```"}, {'reason': 'stop', 'result': '```python\nprediction_scores = (-get_acc_net_msr(y_pred_te)).flatten()\ny_true = pred_f_te.flatten()\nprecision_msr, recall_msr, _ = metrics.precision_recall_curve(y_true, prediction_scores)\npr_auc_msr = metrics.average_precision_score(y_true, prediction_scores)\nauroc_msr = metrics.roc_auc_score(y_true, prediction_scores)\nfpr_msr, tpr_msr, _ = metrics.roc_curve(y_true, prediction_scores)\nprediction_scores = (-get_acc_net_max_margin(y_pred_te)).flatten()\nprecision_margin, recall_margin, _ = metrics.precision_recall_curve(y_true, prediction_scores)\npr_auc_margin = metrics.average_precision_score(y_true, prediction_scores)\nauroc_margin = metrics.roc_auc_score(y_true, prediction_scores)\nfpr_margin, tpr_margin, _ = metrics.roc_curve(y_true, prediction_scores)\nprediction_scores = (-get_acc_net_entropy(y_pred_te)).flatten()\nprecision_entropy, recall_entropy, _ = metrics.precision_recall_curve(y_true, prediction_scores)\npr_auc_entropy = metrics.average_precision_score(y_true, prediction_scores)\nauroc_entropy = metrics.roc_auc_score(y_true, prediction_scores)\nfpr_entropy, tpr_entropy, _ = metrics.roc_curve(y_true, prediction_scores)\n```'}, {'reason': 'stop', 'result': "```python\nX, Annotations = marconi['Soccer']\ncamera = 3\nframe = 79\nfig = plt.figure(figsize=(16, 8))\nax = fig.add_subplot(111)\nim = X[camera, frame]\nax.imshow(im)\nAnnotations_for_cam = Annotations[camera]\nAnnot_on_frame_cam = Annotations_for_cam[frame]\nannotation_colors = ['red', 'yellow']\nfor i, ((tl, br), joints) in enumerate(Annot_on_frame_cam):\n    head_x, head_y = utils.tl_br_to_plt_plot(tl[1], tl[0], br[1], br[0])\n    ax.plot(head_x, head_y, color=annotation_colors[i])\n    for jx, jy, visible in joints:\n        plt.scatter(jx, jy, color=annotation_colors[i], alpha=1 if visible == 1 else 0.4)\nplt.axis('off')\nplt.show()\n```"}, {'reason': 'stop', 'result': "```python\ncov = X.T @ X / (X.shape[0] - 1)\nval, vec = np.linalg.eigh(cov)\nidx = np.argsort(val)[::-1]\nval = val[idx]\nvec = vec[:, idx]\nproject_X = X @ vec\neigen_vectors = vec.T @ vec\ninversed_vec = np.linalg.inv(vec)\ninversed_vec = inversed_vec - inversed_vec.mean(1)\nrevert_X = project_X @ inversed_vec\nrevertedV = eigen_vectors @ inversed_vec.T\n\ndef plot():\n    plt.figure(figsize=(15, 5))\n    plt.subplot(131)\n    plt.scatter(X[y == 0, 0], X[y == 0, 1], color='red', alpha=0.5)\n    plt.scatter(X[y == 1, 0], X[y == 1, 1], color='blue', alpha=0.5)\n    pca11 = plt.arrow(0, 0, *vec[:, 0] * val[0], head_width=0.05, head_length=0.05, color='Green', label='First PC')\n    pca12 = plt.arrow(0, 0, *vec[:, 1] * val[1], head_width=0.05, head_length=0.05, color='magenta', label='Second PC')\n    plt.grid(True)\n    plt.subplot(132)\n    plt.scatter(project_X[y == 0, 0], project_X[y == 0, 1], color='red', alpha=0.5)\n    plt.scatter(project_X[y == 1, 0], project_X[y == 1, 1], color='blue', alpha=0.5)\n    pca21 = plt.arrow(0, 0, *eigen_vectors[:, 0] * val_reduced[0], head_width=0.05, head_length=0.05, color='Green', label='First PC')\n    pca22 = plt.arrow(0, 0, *eigen_vectors[:, 1] * val_reduced[1], head_width=0.05, head_length=0.05, color='magenta', label='Second PC')\n    plt.grid(True)\n    plt.subplot(133)\n    plt.scatter(revert_X[y == 0, 0], revert_X[y == 0, 1], color='red', alpha=0.5)\n    plt.scatter(revert_X[y == 1, 0], revert_X[y == 1, 1], color='blue', alpha=0.5)\n    pca21 = plt.arrow(0, 0, *revertedV[:, 0] * val[0], head_width=0.05, head_length=0.05, color='Green', label='First PC')\n    pca22 = plt.arrow(0, 0, *revertedV[:, 1] * val[1], head_width=0.05, head_length=0.05, color='magenta', label='Second PC')\n    plt.grid(True)\n    plt.show()\nplot()\n```"}, {'reason': 'stop', 'result': "```python\nnum_steps = 7001\nsummary_frequency = 100\nwith tf.Session(graph=graph) as session:\n    tf.global_variables_initializer().run()\n    print('Initialized')\n    average_loss = 0\n    for step in range(num_steps):\n        batches = train_batches.next()\n        feed_dict = dict()\n        for i in range(num_unrollings + 1):\n            feed_dict[train_data[i]] = batches[i]\n        _, l, predictions, lr = session.run([optimizer, loss, train_prediction, learning_rate], feed_dict=feed_dict)\n        average_loss += l\n        if step % summary_frequency == 0:\n            if step > 0:\n                average_loss = average_loss / summary_frequency\n            print('Average loss at step %d: %f learning rate: %f' % (step, average_loss, lr))\n            average_loss = 0\n            labels = np.concatenate(list(batches)[1:])\n            print('Minibatch perplexity: %.2f' % float(np.exp(logprob(predictions, labels))))\n            if step % (summary_frequency * 10) == 0:\n                print('=' * 80)\n                for _ in range(5):\n                    feed = sample(random_distribution())\n                    sentence = characters(feed)[0]\n                    reset_sample_state.run()\n                    for _ in range(79):\n                        prediction = sample_prediction.eval({sample_input: feed})\n                        feed = sample(prediction)\n                        sentence += characters(feed)[0]\n                    print(sentence)\n                print('=' * 80)\n            reset_sample_state.run()\n            valid_logprob = 0\n            for _ in range(valid_size):\n                b = valid_batches.next()\n                predictions = sample_prediction.eval({sample_input: b[0]})\n                valid_logprob = valid_logprob + logprob(predictions, b[1])\n            print('Validation set perplexity: %.2f' % float(np.exp(valid_logprob / valid_size)))\n```"}, {'reason': 'stop', 'result': "```python\nsoftmax_logits = tf.nn.softmax(logits)\ntop_k = tf.nn.top_k(softmax_logits, k=3)\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    model_restore = tf.train.import_meta_graph('./lenet.meta')\n    model_restore.restore(sess, './lenet')\n    batch_x = np.expand_dims(my_images_normalized, axis=3)\n    sample_softmax_logits = sess.run(softmax_logits, feed_dict={x: batch_x, keep_prob: 1.0})\n    my_top_k = sess.run(top_k, feed_dict={x: batch_x, keep_prob: 1.0})\n    fig, axs = plt.subplots(len(my_images), 1, figsize=(20, 25))\n    fig.subplots_adjust(hspace=1.0, wspace=0.6)\n    axs = axs.ravel()\n    for i, image in enumerate(my_images):\n        axs[i].axis('off')\n        axs[i].imshow(cv.cvtColor(image, cv.COLOR_BGR2RGB))\n        guess1 = my_top_k[1][i][0]\n        index1 = np.argwhere(y_valid == guess1)[0]\n        guess2 = my_top_k[1][i][1]\n        index2 = np.argwhere(y_valid == guess2)[0]\n        guess3 = my_top_k[1][i][2]\n        index3 = np.argwhere(y_valid == guess3)[0]\n        title = ''\n        title += 'guess 1: class ' + sign_dict[str(guess1)] + ', probability: ' + str(100 * my_top_k[0][i][0]) + '\\n'\n        title += 'guess 2: class ' + sign_dict[str(guess2)] + ', probability: ' + str(100 * my_top_k[0][i][1]) + '\\n'\n        title += 'guess 3: class ' + sign_dict[str(guess3)] + ', probability: ' + str(100 * my_top_k[0][i][2])\n        axs[i].set_title(title)\n```"}, {'reason': 'stop', 'result': '```python\ndef hypothesis_inlinecounter(text):\n    hyp = np.concatenate([np.linspace(1, -1, len(x) + 1) for x in text.split(\'\\n\')])[:-1]\n    return hyp\n\ndef hypothesis_inside_one(text, single):\n    hyp = re.sub(\'\\\\{}.*?\\\\{}\'.format(single, single), lambda m: single + \'#\' * (len(m.group()) - 2) + single, text)\n    return np.array([1 if x == \'#\' else -1 for x in hyp])\n\ndef hypothesis_inside_two(text, left, right):\n    hyp = np.full(len(text), -1)\n    is_variable_definition = False\n    for i in range(len(text) - 1):\n        if text[i] == left:\n            is_variable_definition = True\n        elif text[i] == right:\n            is_variable_definition = False\n        if is_variable_definition:\n            hyp[i + 1] = 1\n    return hyp\nhypothesis_inside_quotation = lambda x: hypothesis_inside_one(x, \'"\')\nhypothesis_inside_parantheses = lambda x: hypothesis_inside_two(x, \'(\', \')\')\n\ndef hypothesis_comments(text):\n    hyp = np.full(len(text), -1)\n    in_brac_comment = False\n    in_line_comment = False\n    for i in range(len(text)):\n        if text[i:i + 2] == \'//\':\n            in_line_comment = True\n        elif text[i] == \'\\n\':\n            in_line_comment = False\n        elif text[i:i + 2] == \'/*\':\n            in_brac_comment = True\n        elif text[i:i + 2] == \'*/\':\n            in_brac_comment = False\n        if in_brac_comment:\n            hyp[i:i + 3] = 1\n        if in_line_comment:\n            hyp[i:i + 1] = 1\n    return hyp\n\ndef hypothesis_indentation(text, level):\n    hyp = np.full(len(text), -1)\n    cur_level = 0\n    for i, char in enumerate(text):\n        if char == \'\\n\':\n            cur_level = 0\n        elif char == \'\\t\':\n            cur_level += 1\n        if cur_level >= level:\n            hyp[i] = 1\n    return hyp\n```'}, {'reason': 'stop', 'result': '```python\ny_scores = -probas_svm\nprecision_svm, recall_svm, _ = metrics.precision_recall_curve(y_true, y_scores)\narea_under_precision_recall_curve = metrics.auc(recall_svm, precision_svm)\nfpr_svm, tpr_svm, _ = metrics.roc_curve(y_true, y_scores)\nauroc_svm = metrics.roc_auc_score(y_true, y_scores)\n```'}, {'reason': 'stop', 'result': '```python\ndef sframe_to_scipy(x, column_name):\n    """\n    Convert a dictionary column of an SFrame into a sparse matrix format where\n    each (row_id, column_id, value) triple corresponds to the value of\n    x[row_id][column_id], where column_id is a key in the dictionary.\n       \n    Example\n    >>> sparse_matrix, map_key_to_index = sframe_to_scipy(sframe, column_name)\n    """\n    assert x[column_name].dtype() == dict, \'The chosen column must be dict type, representing sparse data.\'\n    x = x.add_row_number()\n    x = x.stack(column_name, [\'feature\', \'value\'])\n    f = graphlab.feature_engineering.OneHotEncoder(features=[\'feature\'])\n    f.fit(x)\n    x = f.transform(x)\n    mapping = f[\'feature_encoding\']\n    x[\'feature_id\'] = x[\'encoded_features\'].dict_keys().apply(lambda x: x[0])\n    i = np.array(x[\'id\'])\n    j = np.array(x[\'feature_id\'])\n    v = np.array(x[\'value\'])\n    width = x[\'id\'].max() + 1\n    height = x[\'feature_id\'].max() + 1\n    sparse_matrix = csr_matrix((v, (i, j)), shape=(width, height))\n    return (sparse_matrix, mapping)\n```'}, {'reason': 'stop', 'result': '```python\nnum_nodes = 64\ngraph = tf.Graph()\nwith graph.as_default():\n    ix = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n    im = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n    ib = tf.Variable(tf.zeros([1, num_nodes]))\n    fx = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n    fm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n    fb = tf.Variable(tf.zeros([1, num_nodes]))\n    cx = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n    cm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n    cb = tf.Variable(tf.zeros([1, num_nodes]))\n    ox = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n    om = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n    ob = tf.Variable(tf.zeros([1, num_nodes]))\n    saved_output = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False)\n    saved_state = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False)\n    w = tf.Variable(tf.truncated_normal([num_nodes, vocabulary_size], -0.1, 0.1))\n    b = tf.Variable(tf.zeros([vocabulary_size]))\n\n    def lstm_cell(i, o, state):\n        """Create a LSTM cell. See e.g.: http://arxiv.org/pdf/1402.1128v1.pdf\n    Note that in this formulation, we omit the various connections between the\n    previous state and the gates."""\n        input_gate = tf.sigmoid(tf.matmul(i, ix) + tf.matmul(o, im) + ib)\n        forget_gate = tf.sigmoid(tf.matmul(i, fx) + tf.matmul(o, fm) + fb)\n        update = tf.matmul(i, cx) + tf.matmul(o, cm) + cb\n        state = forget_gate * state + input_gate * tf.tanh(update)\n        output_gate = tf.sigmoid(tf.matmul(i, ox) + tf.matmul(o, om) + ob)\n        return (output_gate * tf.tanh(state), state)\n    train_data = list()\n    for _ in range(num_unrollings + 1):\n        train_data.append(tf.placeholder(tf.float32, shape=[batch_size, vocabulary_size]))\n    train_inputs = train_data[:num_unrollings]\n    train_labels = train_data[1:]\n    outputs = list()\n    output = saved_output\n    state = saved_state\n    for i in train_inputs:\n        output, state = lstm_cell(i, output, state)\n        outputs.append(output)\n    with tf.control_dependencies([saved_output.assign(output), saved_state.assign(state)]):\n        logits = tf.nn.xw_plus_b(tf.concat(outputs, 0), w, b)\n        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf.concat(train_labels, 0), logits=logits))\n    global_step = tf.Variable(0)\n    learning_rate = tf.train.exponential_decay(10.0, global_step, 5000, 0.1, staircase=True)\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n    gradients, v = zip(*optimizer.compute_gradients(loss))\n    gradients, _ = tf.clip_by_global_norm(gradients, 1.25)\n    optimizer = optimizer.apply_gradients(zip(gradients, v), global_step=global_step)\n    train_prediction = tf.nn.softmax(logits)\n    sample_input = tf.placeholder(tf.float32, shape=[1, vocabulary_size])\n    sample_lstm_output = tf.Variable(tf.zeros([1, num_nodes]))\n    saved_sample_state = tf.Variable(tf.zeros([1, num_nodes]))\n    reset_sample_state = tf.group(sample_lstm_output.assign(tf.zeros([1, num_nodes])), saved_sample_state.assign(tf.zeros([1, num_nodes])))\n    sample_output, sample_state = lstm_cell(sample_input, sample_lstm_output, saved_sample_state)\n    with tf.control_dependencies([sample_lstm_output.assign(sample_output), saved_sample_state.assign(sample_state)]):\n        sample_prediction = tf.nn.softmax(tf.nn.xw_plus_b(sample_output, w, b))\n```'}, {'reason': 'stop', 'result': "```python\nwith tf.variable_scope('train'):\n    if is_time_major:\n        logits = tf.transpose(logits, [1, 0, 2])\n        crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=dataset.tgt_out_ids, logits=logits)\n        target_weights = tf.sequence_mask(dataset.tgt_size, tf.shape(logits)[1], tf.float32)\n    else:\n        crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=dataset.tgt_out_ids, logits=logits)\n        target_weights = tf.sequence_mask(dataset.tgt_size, tf.shape(logits)[1], tf.float32)\n    loss_variable = tf.reduce_sum(crossent * target_weights) / tf.to_float(batch_size)\n    tf.summary.scalar('loss', loss_variable)\n    learning_rate = tf.placeholder(dtype=tf.float32, name='learning_rate')\n    max_global_norm = tf.placeholder(dtype=tf.float32, name='max_global_norm')\n    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=0.5)\n    params = tf.trainable_variables()\n    gradients = tf.gradients(loss_variable, params)\n    for grad, var in zip(gradients, params):\n        tf.summary.histogram(var.op.name + '/gradient', grad)\n    gradients, _ = tf.clip_by_global_norm(gradients, max_global_norm)\n    for grad, var in zip(gradients, params):\n        tf.summary.histogram(var.op.name + '/clipped_gradient', grad)\n    update = optimizer.apply_gradients(zip(gradients, params))\n```"}, {'reason': 'stop', 'result': "```python\nfor f in tqdm(feats):\n    rasterized_image = features.rasterize([(shape(f['geometry']), 1)], out_shape=out_shape, transform=new_aff, fill=0, all_touched=True)\n    region = data.where(rasterized_image == 1)\n    res = region.stack(allpoints=['x', 'y']).mean(dim='allpoints').to_dataframe(name=f['properties']['LSOA11CD'])\n    dfs.append(res)\npollution_hospital_admissions = pd.concat(dfs, axis=1)\n```"}, {'reason': 'stop', 'result': "```python\nncomponents = 2\npca = decomp.PCA(n_components=ncomponents)\nraw_pca = pca.fit(np.array(x_train.iloc[:, first_egemaps_feature:]).astype(np.float))\nx_pca = raw_pca.transform(x_train.iloc[:, first_egemaps_feature:])\ngroups = x_train['pos']\nshort_pos = {'nouns': 'nn', 'verbs': 'vrb', 'other': 'oth', 'function_words': 'fct', 'adjectives': 'adj'}\ngroup_values = [short_pos[i] for i in groups.unique()]\nposIDs = groups.factorize()[0]\nlabels = np.array(x_train['word'])\nfig = plt.figure()\nax = fig.add_subplot(111)\nax.set_xlabel('PC 1')\nax.set_ylabel('PC 2')\ncolormap = plt.get_cmap('gnuplot', len(group_values))\npc1 = x_pca[:, 0]\npc2 = x_pca[:, 1]\np = ax.scatter(pc1, pc2, c=posIDs, cmap=colormap, s=10)\ncb = plt.colorbar(p)\nloc = np.arange(0, max(posIDs), max(posIDs) / float(len(group_values)))\ncb.set_ticks(loc)\ncb.set_ticklabels(group_values)\nfor label, x, y in zip(labels, pc1, pc2):\n    if y == np.amax(y) or x == np.amax(x):\n        plt.annotate(label, fontsize=2, xy=(x, y), xytext=(0, 1), textcoords='offset points', ha='right', va='bottom')\nif pos_filter == None:\n    axins = zoomed_inset_axes(ax, 2.5, loc=2)\n    x1, x2, y1, zoomed_inset_y_limit = (-3.1, 2.5, 6.3, 9.8)\n    axins.set_xlim(x1, x2)\n    axins.set_ylim(y1, zoomed_inset_y_limit)\n    axins.scatter(pc1, pc2, c=posIDs, cmap=colormap)\n    plt.yticks(visible=False)\n    plt.xticks(visible=False)\n    mark_inset(ax, axins, loc1=2, loc2=4, fc='none', ec='0.5')\n    for label, x, y in zip(labels, pc1, pc2):\n        if y == np.amax(y) or x == np.amax(x):\n            plt.annotate(label, fontsize=8, xy=(x, y), xytext=(0, 1), textcoords='offset points', ha='right', va='bottom')\n    axins2 = zoomed_inset_axes(ax, 2.5, loc=4)\n    x1, x2, y1, zoomed_inset_y_limit = (-4, 0.5, -8.5, -6.5)\n    axins2.set_xlim(x1, x2)\n    axins2.set_ylim(y1, zoomed_inset_y_limit)\n    axins2.scatter(pc1, pc2, c=posIDs, cmap=colormap)\n    plt.yticks(visible=False)\n    plt.xticks(visible=False)\n    mark_inset(ax, axins2, loc1=2, loc2=4, fc='none', ec='0.5')\n    for label, x, y in zip(labels, pc1, pc2):\n        if y == np.amax(y) or x == np.amax(x):\n            plt.annotate(label, fontsize=8, xy=(x, y), xytext=(0, 1), textcoords='offset points', ha='right', va='bottom')\nfilename = corpus + '_full_zoom.pdf'\nif pos_filter != None and len(pos_filter) == 1:\n    filename = corpus + '_pca_' + pos_filter[0][1] + '_' + pos_filter[0][2] + '.pdf'\nplt.savefig(filename, bbox_inches='tight')\n```"}, {'reason': 'stop', 'result': "```python\nearningscost10k = [earningscost for earningscost in df0_10k_grouped['earnings_cost_ratio']]\nearningsgrowth10k = [earnings for earnings in df0_10k_grouped['earnings_growth_y6_y10']]\nweighted_growth10k = [worthit for worthit in df0_10k_grouped['weighted_growth_to_tuition']]\nearningscost10k_18k = [earningscost for earningscost in df10_18k_grouped['earnings_cost_ratio']]\nearningsgrowth10k_18k = [earnings for earnings in df10_18k_grouped['earnings_growth_y6_y10']]\nweighted_growth_to_tuition_list = [worthit for worthit in df10_18k_grouped['weighted_growth_to_tuition']]\nearningscost18k_32k = [earningscost for earningscost in df18_32_grouped['earnings_cost_ratio']]\nearningsgrowth18k_32k = [earnings for earnings in df18_32_grouped['earnings_growth_y6_y10']]\nweighted_growth18k_32k = [worthit for worthit in df18_32_grouped['weighted_growth_to_tuition']]\nearningscost32k = [earningscost for earningscost in df32_grouped['earnings_cost_ratio']]\nearningsgrowth32kk = [earnings for earnings in df32_grouped['earnings_growth_y6_y10']]\nweighted_growth32k = [worthit for worthit in df32_grouped['weighted_growth_to_tuition']]\n```"}, {'reason': 'stop', 'result': '```python\nmean_valid_accuracy = ACCanalysis.Valid.mean()\nsms.DescrStatsW(ACCanalysis.Valid).tconfint_mean()\n```'}, {'reason': 'stop', 'result': '```python\ndef estimate_anottation_correct(img, coords, line_width=2, threshold=0.8):\n    """Make histograms of boundaries to estimate annotation error\n    (if boundaries are blank, high chance of dumb walk failure)"""\n    boundary_histogram_sum = 0\n    cont = 0\n    xleft, ytop, xright, ybottom = [int(c) for c in coords]\n    leftside = img[ytop:ybottom, xleft:xleft + line_width - 1]\n    rightside = img[ytop:ybottom, xright - line_width:xright]\n    topside = img[ytop:ytop + line_width - 1, xleft:xright]\n    bottomside = img[ybottom - line_width:ybottom, xleft:xright]\n    boundary_histogram_sum = leftside.sum() + rightside.sum()\n    cont = leftside.size + rightside.size\n    \'for y in range(ytop, ybottom):\\n        for x in range(xleft, xright):\\n            total += img[y, xleft:xleft + line_width].sum()  # Left side\\n            total += img[y, xright - line_width:xright].sum()  # Right side\\n            total += img[ytop:ytop + line_width, x].sum()  # Top side\\n            total += img[ybottom - line_width:ybottom, x].sum()  # Bottom side\\n            cont +=1\\n    \'\n    percent_black = boundary_histogram_sum / cont\n    return int(percent_black)\n```'}, {'reason': 'stop', 'result': "```python\ntutorial_steps = []\ntutorial_steps.append('A')\ntutorial_steps.append('d')\ntutorial_steps.append('d')\nprint(tutorial_steps)\n```"}, {'reason': 'stop', 'result': '```python\ntrain_test_split = int(np.ceil(2 * len(y) / float(3)))\nwindowed_data = X[:train_test_split, :]\ny_train = y[:train_test_split]\nX_test = X[train_test_split:, :]\ny_test = y[train_test_split:]\nwindowed_data = np.asarray(np.reshape(windowed_data, (windowed_data.shape[0], window_size, 1)))\nX_test = np.asarray(np.reshape(X_test, (X_test.shape[0], window_size, 1)))\n```'}, {'reason': 'stop', 'result': "```python\ndef test_sgd(x_train, t_train, x_valid, t_valid, w, b):\n    Lts = []\n    validation_losses = []\n    epsilon = 0.01\n    while (len(Lts) < 2 or abs(Lts[-1] - Lts[-2]) > epsilon) and len(Lts) < 25:\n        L_train, w, b = sgd_iter(x_train, t_train, w, b)\n        logp = []\n        for x, t in zip(x_valid, t_valid):\n            _, _, logp_valid = logprob(x, w, b)\n            logp.append(logp_valid[t])\n        L_valid = np.array(logp).mean()\n        Lts.append(L_train)\n        validation_losses.append(L_valid)\n    x = np.arange(len(Lts))\n    plt.plot(x, Lts, label='L_train')\n    plt.plot(x, validation_losses, label='L_validation')\n    plt.legend()\n    plt.show()\n    return (w, b)\nnp.random.seed(1243)\nw = np.zeros((28 * 28, 10))\nb = np.zeros(10)\nw, b = test_sgd(x_train, t_train, x_valid, t_valid, w, b)\n```"}, {'reason': 'stop', 'result': "```python\nplt.figure(figsize=(15, 5))\nplt.subplot(131)\nplt.scatter(X[y == 0, 0], X[y == 0, 1], color='red', alpha=0.5)\nplt.scatter(X[y == 1, 0], X[y == 1, 1], color='blue', alpha=0.5)\nfirst_principal_component_arrow = plt.arrow(0, 0, *vec[:, 0] * val[0], head_width=0.05, head_length=0.05, color='Green', label='First PC')\npca12 = plt.arrow(0, 0, *vec[:, 1] * val[1], head_width=0.05, head_length=0.05, color='magenta', label='Second PC')\nplt.grid(True)\nplt.subplot(132)\nplt.scatter(L[y == 0, 0], L[y == 0, 1], color='red', alpha=0.5)\nplt.scatter(L[y == 1, 0], L[y == 1, 1], color='blue', alpha=0.5)\nplt.grid(True)\nplt.subplot(133)\nplt.scatter(S[y == 0, 0], S[y == 0, 1], color='red', alpha=0.5)\nplt.scatter(S[y == 1, 0], S[y == 1, 1], color='blue', alpha=0.5)\nplt.grid(True)\nplt.show()\n```"}, {'reason': 'stop', 'result': "```python\nsparse_data = my_spca.transform(X)\nplt.figure(figsize=(15, 5))\nplt.subplot(121)\nplt.scatter(X[y == 0, 0], X[y == 0, 1], color='red', alpha=0.5)\nplt.scatter(X[y == 1, 0], X[y == 1, 1], color='blue', alpha=0.5)\npca11 = plt.arrow(0, 0, *vec[:, 0] * val[0], head_width=0.05, head_length=0.05, color='Green', label='First PC')\npca12 = plt.arrow(0, 0, *vec[:, 1] * val[1], head_width=0.05, head_length=0.05, color='magenta', label='Second PC')\nplt.grid(True)\nnew_pc_cen = sparse_data - sparse_data.mean(0, keepdims=True)\ncov = new_pc_cen.T @ new_pc_cen / (new_pc_cen.shape[0] - 1)\nval, vec = np.linalg.eigh(cov)\nplt.subplot(122)\nplt.scatter(new_pc[y == 0, 0], new_pc[y == 0, 1], color='red', alpha=0.5)\nplt.scatter(new_pc[y == 1, 0], new_pc[y == 1, 1], color='blue', alpha=0.5)\nprincipal_components = plt.arrow(0, 0, *vec[:, 0] * val[0], head_width=0.005, head_length=0.005, color='Green', label='First PC')\npca22 = plt.arrow(0, 0, *vec[:, 1] * val[1], head_width=0.005, head_length=0.005, color='magenta', label='Second PC')\nplt.grid(True)\nplt.show()\n```"}, {'reason': 'stop', 'result': '```python\nstart_inds = [100, 200, 300, 400, 500, 600, 700]\nf = open(\'text_gen_output/RNN_large_textdata_output.txt\', \'w\')\nmodel.load_weights(\'model_weights/best_RNN_large_textdata_weights.hdf5\')\nfor s in start_inds:\n    start_index = s\n    input_chars = text[start_index:start_index + window_size]\n    predict_input = predict_next_chars(model, input_chars, num_to_predict=100)\n    text_generation_output_separator = \'-------------------\' + \'\\n\'\n    print(text_generation_output_separator)\n    f.write(text_generation_output_separator)\n    input_line = \'input chars = \' + \'\\n\' + input_chars + \'"\' + \'\\n\'\n    print(input_line)\n    f.write(input_line)\n    predict_line = \'predicted chars = \' + \'\\n\' + predict_input + \'"\' + \'\\n\'\n    print(predict_line)\n    f.write(predict_line)\nf.close()\n```'}, {'reason': 'stop', 'result': '```python\nmax_sequence_length = 100\nstep_size = 5\nX, y = encode_io_pairs(text, max_sequence_length, step_size)\n```'}, {'reason': 'stop', 'result': "```python\ndef inverse_difference(history, yhat, interval=1):\n    return yhat + history[-interval]\n\ndef scale(train, test):\n    scaler = MinMaxScaler(feature_range=(-1, 1))\n    scaler = scaler.fit(train)\n    train = train.reshape(train.shape[0], train.shape[1])\n    train_scaled = scaler.transform(train)\n    test = test.reshape(test.shape[0], test.shape[1])\n    test_scaled = scaler.transform(test)\n    return (scaler, train_scaled, test_scaled)\n\ndef invert_scale(scaler, X, value):\n    new_row = [x for x in X] + [value]\n    new_row_array = numpy.array(new_row)\n    new_row_array = new_row_array.reshape(1, len(new_row_array))\n    inverted = scaler.inverse_transform(new_row_array)\n    return inverted[0, -1]\n\ndef fit_lstm(train, batch_size, nb_epoch, neurons):\n    X, y = (train[:, 0:-1], train[:, -1])\n    X = X.reshape(X.shape[0], 1, X.shape[1])\n    model = Sequential()\n    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n    model.add(Dense(1))\n    model.compile(loss='mean_squared_error', optimizer='adam')\n    for i in range(nb_epoch):\n        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n        model.reset_states()\n    return model\n```"}, {'reason': 'stop', 'result': '```python\nimport eda\nreload(eda)\nnon_unique_customer_data = log_data.loc[[x for x in log_data.index if x not in d_unique_idx.keys()]]\nsamples2 = log_data.loc[[x[0] for x in d_unique_idx.iteritems() if x[1] > 1]]\nax = eda.features_boxplot(non_unique_customer_data, samples2, samples2.index)\n```'}, {'reason': 'stop', 'result': '```python\ntraining_data_names = data_train.names\ncolors = data_train.colors\n```'}, {'reason': 'stop', 'result': '```python\ndef lane_detection_ppline(image, k_size=3, vertex_ratio_h=0.45, vertex_ratio_v=0.6, low_thresh=50, high_thresh=200, L2gradient=False, rho=2, theta=1 * np.pi / 180.0, min_votes=15, min_line_len=40, max_line_gap=20, angle=3 * np.pi / 16, angle_thresh=np.pi / 16, debug=False):\n    """\n    Takes an image and parameters and applies the lane detection pipeline.\n    Returns an image combining the original and the extended lines detected\n    by the algorithm.\n     - debug: Whether or not to display the images after each step of the process, for\n     debugging or tuning purposes.\n    """\n    max_y, max_x = image.shape[:2]\n    roi = np.array([[(0, max_y), (round(max_x * vertex_ratio_h), round(max_y * vertex_ratio_v)), (round(max_x * (1 - vertex_ratio_h)), round(max_y * vertex_ratio_v)), (max_x, max_y)]])\n    if debug:\n        plt.subplot(4, 2, 1)\n        plt.imshow(image)\n    grayscale_image = grayscale(image)\n    if debug:\n        plt.subplot(4, 2, 2)\n        plt.imshow(grayscale_image, cmap=\'gray\')\n    blur_gray = gaussian_blur(grayscale_image, k_size)\n    if debug:\n        plt.subplot(4, 2, 3)\n        plt.imshow(blur_gray, cmap=\'gray\')\n    edges = canny(blur_gray, low_thresh, high_thresh, L2gradient=L2gradient)\n    if debug:\n        plt.subplot(4, 2, 4)\n        plt.imshow(edges)\n    masked_edges = region_of_interest(edges, roi)\n    if debug:\n        plt.subplot(4, 2, 5)\n        plt.imshow(masked_edges)\n    line_img, lines = hough_lines(masked_edges, rho, theta, min_votes, min_line_len, max_line_gap)\n    if debug:\n        plt.subplot(4, 2, 6)\n        plt.imshow(line_img)\n    try:\n        combined = extend_lines(image, lines, angle=angle, angle_thresh=angle_thresh)\n        if debug:\n            plt.subplot(4, 2, 7)\n            plt.imshow(combined)\n    except IndexError:\n        print(\'Error. Try relaxing your angle parameters a litte.\')\n    return combined\n```'}, {'reason': 'stop', 'result': "```python\nSkyPresence = posttest.groupby(['subjID'])['Q2_SceneSkyPresence'].mean()\nSkyPresenceSEM = pd.Series.std(SkyPresence) / n\nColorScheme = posttest.groupby(['subjID'])['Q2_SceneColorScheme'].mean()\nColorSchemeSEM = pd.Series.std(ColorScheme) / n\nTreeFreq = posttest.groupby(['subjID'])['Q2_SceneTreeFrequency'].mean()\nTreeFreqSEM = pd.Series.std(TreeFreq) / n\nImageType = posttest.groupby(['subjID'])['Q2_ImageType'].mean()\nImageTypeSEM = pd.Series.std(ImageType) / n\nFeatureType = posttest.groupby(['subjID'])['Q2_FeatureType'].mean()\nfeature_type_sem = pd.Series.std(FeatureType) / n\nLightType = posttest.groupby(['subjID'])['Q2_LightType'].mean()\nLightTypeSEM = pd.Series.std(LightType) / n\n```"}, {'reason': 'stop', 'result': "```python\nx_axis = [x for x in range(1, 9)]\ntuition_earnings_ratio = df0_10k_grouped['earnings_cost_ratio']\ny_axis2 = df10_18k_grouped['earnings_cost_ratio']\ny_axis3 = df18_32_grouped['earnings_cost_ratio']\ny_axis4 = df32_grouped['earnings_cost_ratio']\nlessThan10k = plt.plot(x_axis, tuition_earnings_ratio, 'go--', linewidth=2, markersize=8, color='blue', label='lessThan10k')\nTenKto18k = plt.plot(x_axis, y_axis2, 'go--', linewidth=2, markersize=8, color='green', label='10Kto18k')\nEighteenTo32k = plt.plot(x_axis, y_axis3, 'go--', linewidth=2, markersize=8, color='yellow', label='18kTo32k')\ngreaterThan32k = plt.plot(x_axis, y_axis4, 'go--', linewidth=2, markersize=8, color='red', label='>32k')\nplt.title('Tiered Earnings-Cost ratio per region ($)')\nplt.xlabel('Region')\nplt.ylabel('Tiered Earnings-cost Ratio')\nplt.grid()\nplt.legend(title=['Tiered Tuitions'])\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)\n```"}, {'reason': 'stop', 'result': "```python\ntext_corpus = open('datasets/holmes.txt').read().lower()\nprint('our original text has ' + str(len(text_corpus)) + ' characters')\n```"}, {'reason': 'stop', 'result': "```python\nDEBUG = False\nJPEG_EXTENSIONS = ('.jpeg', '.JPEG', '.jpg', '.JPG')\nimage_dir = '../data/images'\ntest_images_dir = '../data/test_images'\nstored_images_resized = '../data/images_resized'\nstored_bottlenecks = '../data/bottlenecks'\ntmp_dir = '/tmp'\nbottleneck_dir = os.path.join(tmp_dir, 'bottlenecks')\nimages_resized_dir = os.path.join(tmp_dir, 'images_resized')\nsummaries_dir = os.path.join(tmp_dir, 'retrain_logs')\nmodel_dir = os.path.join(tmp_dir, 'inception')\ninception_url = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'\noutput_graph_orig = 'output_graph_orig.pb'\noutput_graph = 'output_graph.pb'\noutput_labels = 'output_labels.txt'\narchitecture = 'inception_v3'\nfinal_tensor_name = 'final_result'\nhow_many_training_steps = 500\nlearning_rate = 0.01\ntesting_percentage = 10\nvalidation_percentage = 10\neval_step_interval = 10\ntrain_batch_size = 100\ntest_batch_size = -1\nvalidation_batch_size = 100\nprint_misclassified_test_images = False\nflip_left_right = False\nrandom_crop = 0\nrandom_scale = 0\nrandom_brightness = 0\nforce_inception_download = False\nFLAGS = type('FlagsObject', (object,), {'architecture': architecture, 'model_dir': model_dir, 'intermediate_store_frequency': 0, 'summaries_dir': summaries_dir, 'learning_rate': learning_rate, 'image_dir': images_resized_dir, 'testing_percentage': testing_percentage, 'validation_percentage': validation_percentage, 'random_scale': random_scale, 'random_crop': random_crop, 'flip_left_right': flip_left_right, 'random_brightness': random_brightness, 'bottleneck_dir': bottleneck_dir, 'final_tensor_name': final_tensor_name, 'how_many_training_steps': how_many_training_steps, 'train_batch_size': train_batch_size, 'test_batch_size': test_batch_size, 'eval_step_interval': eval_step_interval, 'validation_batch_size': validation_batch_size, 'print_misclassified_test_images': print_misclassified_test_images, 'output_graph': output_graph, 'output_labels': output_labels})\nretrain.FLAGS = FLAGS\n```"}, {'reason': 'stop', 'result': '```python\np_asymp = 0.51\nsc = 0.47\natt_symp = 14.4\np_true_pos = 0.971\nchlamydia_prevalence_rate = 0.00314\n```'}, {'reason': 'stop', 'result': "```python\nheight = 28\nwidth = 28\nchannels = 1\nn_inputs = height * width\nconv1_fmaps = 32\nconv1_ksize = 3\nconv1_stride = 1\nconv1_pad = 'SAME'\nconv2_fmaps = 64\nconv2_ksize = 3\nconv2_stride = 2\nconv2_pad = 'SAME'\npool3_fmaps = conv2_fmaps\nn_fc1 = 64\nn_outputs = 10\nreset_graph()\nwith tf.name_scope('inputs'):\n    X = tf.placeholder(tf.float32, shape=[None, n_inputs], name='X')\n    X_reshaped = tf.reshape(X, shape=[-1, height, width, channels])\n    y = tf.placeholder(tf.int32, shape=[None], name='y')\nconv1 = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps, kernel_size=conv1_ksize, strides=conv1_stride, padding=conv1_pad, activation=tf.nn.relu, name='conv1')\nconv2 = tf.layers.conv2d(conv1, filters=conv2_fmaps, kernel_size=conv2_ksize, strides=conv2_stride, padding=conv2_pad, activation=tf.nn.relu, name='conv2')\nwith tf.name_scope('pool3'):\n    pooled_conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n    pool3_flat = tf.reshape(pooled_conv2, shape=[-1, pool3_fmaps * 7 * 7])\nwith tf.name_scope('fc1'):\n    fc1 = tf.layers.dense(pool3_flat, n_fc1, activation=tf.nn.relu, name='fc1')\nwith tf.name_scope('output'):\n    logits = tf.layers.dense(fc1, n_outputs, name='output')\n    Y_proba = tf.nn.softmax(logits, name='Y_proba')\nwith tf.name_scope('train'):\n    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n    loss = tf.reduce_mean(xentropy)\n    optimizer = tf.train.AdamOptimizer()\n    training_op = optimizer.minimize(loss)\nwith tf.name_scope('eval'):\n    correct = tf.nn.in_top_k(logits, y, 1)\n    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\nwith tf.name_scope('init_and_save'):\n    init = tf.global_variables_initializer()\n    saver = tf.train.Saver()\n```"}, {'reason': 'stop', 'result': "```python\nrevenue_summary = df.pivot_table(index=[df.index.year, df.index.quarter], aggfunc=(np.mean, np.sum, min, max)).rename_axis(['year', 'quarter'])\nrevenue_summary.style.applymap(color_negative_red).apply(highlight_max).apply(highlight_min)\n```"}, {'reason': 'stop', 'result': "```python\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.callbacks import ReduceLROnPlateau\nBATCH_SIZE = 32\nnum_epochs = 8\ncheckpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', verbose=1, save_best_only=True)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.0005, verbose=1)\naugment_data = False\nif not augment_data:\n    print('Training... without data augmentation')\n    history = scratch_model.fit(train_tensors, train_targets, validation_data=(valid_tensors, valid_targets), epochs=num_epochs, batch_size=BATCH_SIZE, callbacks=[checkpointer], verbose=1)\nelse:\n    print('Training... WITH data augmentation')\n    history = scratch_model.fit_generator(datagen_train.flow(train_tensors, train_targets, batch_size=BATCH_SIZE), steps_per_epoch=train_tensors.shape[0] // BATCH_SIZE, epochs=num_epochs, verbose=2, callbacks=[checkpointer], validation_data=datagen_valid.flow(valid_tensors, valid_targets, batch_size=BATCH_SIZE), validation_steps=valid_tensors.shape[0] // BATCH_SIZE)\nprint('Done training')\nshow_history_graph(history)\n```"}, {'reason': 'stop', 'result': "```python\nncomponents = 2\npca = decomp.PCA(n_components=ncomponents)\nraw_pca = pca.fit(np.array(x_train.iloc[:, first_egemaps_feature:]).astype(np.float))\nx_pca = raw_pca.transform(x_train.iloc[:, first_egemaps_feature:])\ngroups = x_train['pos']\nshort_pos = {'nouns': 'nn', 'verbs': 'vrb', 'other': 'oth', 'function_words': 'fct', 'adjectives': 'adj'}\ngroup_values = [short_pos[i] for i in groups.unique()]\nposIDs = groups.factorize()[0]\nlabels = np.array(x_train['word'])\nfig = plt.figure()\nax = fig.add_subplot(111)\nax.set_xlabel('PC 1')\nax.set_ylabel('PC 2')\ncolor_map = plt.get_cmap('gnuplot', len(group_values))\npc1 = x_pca[:, 0]\npc2 = x_pca[:, 1]\np = ax.scatter(pc1, pc2, c=posIDs, cmap=color_map, s=10)\ncb = plt.colorbar(p)\nloc = np.arange(0, max(posIDs), max(posIDs) / float(len(group_values)))\ncb.set_ticks(loc)\ncb.set_ticklabels(group_values)\nfor label, x, y in zip(labels, pc1, pc2):\n    if y == np.amax(y) or x == np.amax(x):\n        plt.annotate(label, fontsize=2, xy=(x, y), xytext=(0, 1), textcoords='offset points', ha='right', va='bottom')\nif pos_filter == None:\n    axins = zoomed_inset_axes(ax, 2.5, loc=2)\n    x1, x2, y1, y2 = (-3.1, 2.5, 6.3, 9.8)\n    axins.set_xlim(x1, x2)\n    axins.set_ylim(y1, y2)\n    axins.scatter(pc1, pc2, c=posIDs, cmap=color_map)\n    plt.yticks(visible=False)\n    plt.xticks(visible=False)\n    mark_inset(ax, axins, loc1=2, loc2=4, fc='none', ec='0.5')\n    for label, x, y in zip(labels, pc1, pc2):\n        if y == np.amax(y) or x == np.amax(x):\n            plt.annotate(label, fontsize=8, xy=(x, y), xytext=(0, 1), textcoords='offset points', ha='right', va='bottom')\n    axins2 = zoomed_inset_axes(ax, 2.5, loc=4)\n    x1, x2, y1, y2 = (-4, 0.5, -8.5, -6.5)\n    axins2.set_xlim(x1, x2)\n    axins2.set_ylim(y1, y2)\n    axins2.scatter(pc1, pc2, c=posIDs, cmap=color_map)\n    plt.yticks(visible=False)\n    plt.xticks(visible=False)\n    mark_inset(ax, axins2, loc1=2, loc2=4, fc='none', ec='0.5')\n    for label, x, y in zip(labels, pc1, pc2):\n        if y == np.amax(y) or x == np.amax(x):\n            plt.annotate(label, fontsize=8, xy=(x, y), xytext=(0, 1), textcoords='offset points', ha='right', va='bottom')\nfilename = corpus + '_full_zoom.pdf'\nif pos_filter != None and len(pos_filter) == 1:\n    filename = corpus + '_pca_' + pos_filter[0][1] + '_' + pos_filter[0][2] + '.pdf'\nplt.savefig(filename, bbox_inches='tight')\n```"}, {'reason': 'stop', 'result': "```python\nsign_words = ['FISH', 'BOOK', 'VEGETABLE', 'FUTURE', 'JOHN']\nimport timeit\n```"}, {'reason': 'stop', 'result': '```python\nbatch_size = 64\nnum_unrollings = 10\n\nclass BatchGenerator(object):\n\n    def __init__(self, text, batch_size, num_unrollings):\n        self._text = text\n        self._text_size = len(text)\n        self._batch_size = batch_size\n        self._num_unrollings = num_unrollings\n        segment = self._text_size // batch_size\n        self._cursor = [offset * segment for offset in range(batch_size)]\n        self._last_batch = self._next_batch()\n\n    def _next_batch(self):\n        """Generate a single batch from the current cursor position in the data."""\n        batch = np.zeros(shape=(self._batch_size, vocabulary_size), dtype=np.float)\n        for b in range(self._batch_size):\n            batch[b, char2id(self._text[self._cursor[b]])] = 1.0\n            self._cursor[b] = (self._cursor[b] + 1) % self._text_size\n        return batch\n\n    def next(self):\n        """Generate the next array of batches from the data. The array consists of\n    the last batch of the previous array, followed by num_unrollings new ones.\n    """\n        batches = [self._last_batch]\n        for step in range(self._num_unrollings):\n            batches.append(self._next_batch())\n        self._last_batch = batches[-1]\n        return batches\n\ndef characters(probabilities):\n    """Turn a 1-hot encoding or a probability distribution over the possible\n  characters back into its (most likely) character representation."""\n    return [id2char(c) for c in np.argmax(probabilities, 1)]\n\ndef batches2string(batches):\n    """Convert a sequence of batches back into their (most likely) string\n  representation."""\n    s = [\'\'] * batches[0].shape[0]\n    for b in batches:\n        s = [\'\'.join(x) for x in zip(s, characters(b))]\n    return s\ntrain_batches = BatchGenerator(train_text, batch_size, num_unrollings)\nvalidation_batches = BatchGenerator(valid_text, 1, 1)\nprint(batches2string(train_batches.next()))\nprint(batches2string(train_batches.next()))\nprint(batches2string(validation_batches.next()))\nprint(batches2string(validation_batches.next()))\n```'}, {'reason': 'stop', 'result': '```python\ndef get_df_cols(csvfilename, cols, separator):\n    """\n  Method to get a dataframe from a csv file with specified columns\n  \n  @csvfilename : the name of the file to convert in dataframe\n  @cols        : list of string giving columns name to keep\n  @separator   : character used to delimit fields in the csv file\n  \n  @return      : a dataframe\n  """\n    dataframe = pd.read_csv(BOOKINGS, error_bad_lines=False, encoding=\'UTF8\', sep=separator, usecols=cols)\n    return dataframe\n\ndef get_name(IATA_code):\n    """\n    Function to return the name of the airport linked to IATA_code\n    \n    @IATA_code : String object which is a IATA_code\n   \n    @return    : String object which is the name of the airport\n  """\n    try:\n        result = GEO_O.get(IATA_code.replace(\' \', \'\'), \'name\')\n    except KeyError as e:\n        result = \'NOT FOUND IATA CODE\'\n    return result\n\ndef get_airports_arrival_sorted(dataframe):\n    """\n  Method to print the get arrivals airports in 2013 from searches file\n  \n  @dataframe : the dataframe containing the data\n  \n  @return    : a new dataframe\n  """\n    top_arrival_airports = dataframe.groupby([\'arr_port\']).sum()\n    top_arrival_airports = top_arrival_airports.sort_values(by=[\'pax\'], ascending=False)\n    return top_arrival_airports\n\ndef add_airports_name(dataframe):\n    """\n  Method to add a column in a dataframe containing the full name of airports\n  thanks to the IATA CODE\n  \n  @dataframe : the dataframe to modify\n  \n  @return    : the dataframe modified\n  """\n    dataframe = dataframe.reset_index()\n    dataframe[\'airport_name\'] = dataframe[\'arr_port\'].apply(lambda x: get_name(x))\n    return dataframe\n\ndef print_top_n_arrival_airport(dataframe, n):\n    """\n  Method to print the top n of arrival airports in 2013\n  \n  @dataframe : the preformatted dataframe by columns containing the data\n  @n         : the number of airports to show\n  """\n    top_arrival_airports = get_airports_arrival_sorted(dataframe)\n    top_arrival_airports = add_airports_name(top_arrival_airports)\n    print(top_arrival_airports.head(n))\n```'}, {'reason': 'stop', 'result': "```python\nimport boto3\nfrom sagemaker.amazon.amazon_estimator import get_image_uri\nfrom sagemaker import get_execution_role\nrole = get_execution_role()\ntraining_image = get_image_uri(boto3.Session().region_name, 'xgboost')\ns3_input_train = 's3://{}/{}/train'.format(YOUR_BUCKET_NAME, prefix)\nvalidation_data_s3_uri = 's3://{}/{}/validate/'.format(YOUR_BUCKET_NAME, prefix)\ntraining_job_definition = {'AlgorithmSpecification': {'TrainingImage': training_image, 'TrainingInputMode': 'File'}, 'InputDataConfig': [{'ChannelName': 'train', 'CompressionType': 'None', 'ContentType': 'csv', 'DataSource': {'S3DataSource': {'S3DataDistributionType': 'FullyReplicated', 'S3DataType': 'S3Prefix', 'S3Uri': s3_input_train}}}, {'ChannelName': 'validation', 'CompressionType': 'None', 'ContentType': 'csv', 'DataSource': {'S3DataSource': {'S3DataDistributionType': 'FullyReplicated', 'S3DataType': 'S3Prefix', 'S3Uri': validation_data_s3_uri}}}], 'OutputDataConfig': {'S3OutputPath': 's3://{}/{}/output'.format(YOUR_BUCKET_NAME, prefix)}, 'ResourceConfig': {'InstanceCount': 1, 'InstanceType': 'ml.c5.4xlarge', 'VolumeSizeInGB': 20}, 'RoleArn': role, 'StaticHyperParameters': {'eval_metric': 'rmse', 'objective': 'reg:linear', 'rate_drop': '0.3', 'tweedie_variance_power': '1.4'}, 'StoppingCondition': {'MaxRuntimeInSeconds': 43200}}\n```"}, {'reason': 'stop', 'result': "```python\nmodel = {'boxsize': 368}\nmodel['stride'] = 8\nscale_search_multiplier = {}\nscale_search_multiplier['scale_search'] = [0.5, 1, 1.5, 2]\nmultiplier = [x * model['boxsize'] * 1.0 / oriImg.shape[0] for x in scale_search_multiplier['scale_search']]\n```"}, {'reason': 'stop', 'result': '```python\nscaled_data = preprocessing.scale(act_train)\nact_val_all_svm = preprocessing.scale(act_val_all)\nact_test_svm = preprocessing.scale(act_test)\n```'}, {'reason': 'stop', 'result': '```python\ndef process_image(image):\n    """ Filter color """\n    filtered_image = np.copy(image)\n    rgb_threshold = [200, 150, 95]\n    thresholds = (image[:, :, 0] < rgb_threshold[0]) | (image[:, :, 1] < rgb_threshold[1]) | (image[:, :, 2] < rgb_threshold[2])\n    filtered_image[thresholds] = [0, 0, 0]\n    gray = grayscale(filtered_image)\n    blurred = gaussian_blur(gray, 3)\n    edges = canny(blurred, 50, 150)\n    xsize = image.shape[1]\n    ysize = image.shape[0]\n    vertices = np.array([[(0, ysize), (xsize / 2, ysize / 1.71), (xsize / 2, ysize / 1.71), (xsize, ysize)]], dtype=np.int32)\n    regioned = region_of_interest(edges, vertices)\n    hough = hough_lines(regioned, 1, np.pi / 180, 35, 35, 20)\n    result = weighted_img(hough, image)\n    return result\n```'}, {'reason': 'stop', 'result': "```python\npm25_validation_data = pd.read_csv('D:\\\\Annies_Dissertation\\\\Analysis\\\\Regression\\\\Validation\\\\Monthly_PM25_LSOA_Validation.csv', parse_dates=['time'])\n```"}, {'reason': 'stop', 'result': '```python\ndef blockMotion(t, blockPositions, vBlock, i, blockNum, kp, kc, mass, F0, v0, vf):\n    """\n    Returns the differential equation that models the motion of the blocks\n    \n    Arguments:  t - time\n                blockPositions - the positions of the blocks\n                vBlock - the velocity of the block\n                i - the index of the current block\n                blockNum - the number of blocks\n                kp - spring constant of leaf springs\n                kc - spring constant of springs between blocks\n                mass - mass of individual block\n                F0 - the static friction force\n                v0 - initial velocity of top plate\n                vf - the friction coefficient\n                \n    Returned: The differential equation modeling the motion of the individual blocks\n    \n    Examples:\n    \n    >>> blockMotion (0, (0, 1, 2, 3, 4), 0, 2, 5, 0, 0, 1, 0, 1, 20)\n    array([ 0.,  0.])\n    \n    """\n    xi = blockPositions[i] - i\n    vi = vBlock\n    if i == 0:\n        neighbor_block_position = blockPositions[i + 1] - (i + 1)\n        springForce = kc * (neighbor_block_position - xi) + kp * (v0 * t - xi)\n    elif i == blockNum - 1:\n        xiM = blockPositions[i - 1] - (i - 1)\n        springForce = kc * (xiM - xi) + kp * (v0 * t - xi)\n    else:\n        xiM = blockPositions[i - 1] - (i - 1)\n        neighbor_block_position = blockPositions[i + 1] - (i + 1)\n        springForce = kc * (neighbor_block_position + xiM - 2 * xi) + kp * (v0 * t - xi)\n    frictionForce = friction(vi, vf, F0)\n    if abs(springForce) <= abs(frictionForce):\n        dv = -vi\n        vi = 0\n        dx = vi\n    else:\n        totalForce = (springForce + frictionForce) / mass\n        dx = vi\n        dv = totalForce\n    return np.array([dx, dv], float)\n```'}, {'reason': 'stop', 'result': '```python\nw = np.zeros(3)\ninitial_weight_vector = 0\n```'}, {'reason': 'stop', 'result': '```python\nimport math\nfrom matplotlib import cm, pyplot as plt, mlab\n\ndef visualize(word, model):\n    """ visualize the input model for a particular word """\n    variance = np.array([np.diag(model.covars_[i]) for i in range(model.n_components)])\n    figures = []\n    for parm_idx in range(len(model.means_[0])):\n        xmin = int(min(model.means_[:, parm_idx]) - max(variance[:, parm_idx]))\n        xmax = int(max(model.means_[:, parm_idx]) + max(variance[:, parm_idx]))\n        fig, axs = plt.subplots(model.n_components, sharex=True, sharey=False)\n        colours = cm.rainbow(np.linspace(0, 1, model.n_components))\n        for i, (ax, colour) in enumerate(zip(axs, colours)):\n            x = np.linspace(xmin, xmax, 100)\n            mean_sigma_plots = model.means_[i, parm_idx]\n            sigma = math.sqrt(np.diag(model.covars_[i])[parm_idx])\n            ax.plot(x, mlab.normpdf(x, mean_sigma_plots, sigma), c=colour)\n            ax.set_title(\'{} feature {} hidden state #{}\'.format(word, parm_idx, i))\n            ax.grid(True)\n        figures.append(plt)\n    for p in figures:\n        p.show()\nvisualize(my_testword, model)\n```'}, {'reason': 'stop', 'result': "```python\nplt.figure(figsize=(8, 6))\nfor j in xrange(len(n3_test)):\n    wav = 0\n    wav_pos = 0\n    plt.plot([0, 0.09], [2 * (j + 1), 2 * (j + 1)], '0.8')\n    for i in xrange(len(n3_test[j])):\n        cov = -log(1 - n3_test[j][i])\n        adpc = -log(1 - n3_diag[j][i])\n        [incsol, scrsol] = fsolve(lambda x: [test_diag_fun(x)[0] - cov, test_diag_fun(x)[1] - adpc], [0.09, 0.25])\n        prev = 1 - U_fun(incsol * p_asymp, sc + scrsol * p_true_pos, incsol * (1 - p_asymp), scrsol * p_true_pos + att_symp * p_true_pos)\n        plt.plot(prev, 2 * (j + 1), 'ob', markerfacecolor='None', markersize=20 * sqrt(n3_props[j][i]))\n        wav = wav + n3_props[j][i] * prev\n        wav_pos = wav_pos + n3_props[j][i] * adpc / cov\n    plt.plot(wav, 2 * (j + 1), 'ob')\n    plt.text(0.082, 2 * (j + 1), factors[j], verticalalignment='center')\ncov = -log(1 - 0.346)\nadpc = -log(1 - 0.02)\n[incsol, scrsol] = fsolve(lambda x: [test_diag_fun(x)[0] - cov, test_diag_fun(x)[1] - adpc], [0.09, 0.25])\nprev = 1 - U_fun(incsol * p_asymp, sc + scrsol * p_true_pos, incsol * (1 - p_asymp), scrsol * p_true_pos + att_symp * p_true_pos)\nplt.plot([prev, prev], [0, 100])\nchlamydia_plot = plt.gca()\nchlamydia_plot.axes.get_yaxis().set_ticks([])\nplt.xlim([0, 0.08])\nplt.ylim([0, 26])\nplt.xlabel('Estimated Prevalence')\nplt.ylabel('Stratification')\n```"}, {'reason': 'stop', 'result': "```python\nimport sympy as sym\nfrom sympy import *\nA, U, chlamydia_model_solution = symbols('A U S')\nalpha_UA, alpha_AU, alpha_US, alpha_SU = symbols('alpha_UA alpha_AU alpha_US alpha_SU')\nmodel_dyn = [alpha_UA * U - alpha_AU * A, alpha_AU * A + alpha_SU * chlamydia_model_solution - (alpha_UA + alpha_US) * U, alpha_US * U - alpha_SU * chlamydia_model_solution, A + U + chlamydia_model_solution - 1]\nsol_dyn = solve(model_dyn, A, U, chlamydia_model_solution)\ndyn_fun = lambdify((alpha_UA, alpha_AU, alpha_US, alpha_SU), sol_dyn[A] + sol_dyn[chlamydia_model_solution])\nU_fun = lambdify((alpha_UA, alpha_AU, alpha_US, alpha_SU), sol_dyn[U])\nA_fun = lambdify((alpha_UA, alpha_AU, alpha_US, alpha_SU), sol_dyn[A])\nS_fun = lambdify((alpha_UA, alpha_AU, alpha_US, alpha_SU), sol_dyn[chlamydia_model_solution])\nsol_dyn\n```"}, {'reason': 'stop', 'result': "```python\nfrom keras.callbacks import ModelCheckpoint\nepochs = ...\nmodel_checkpoint_callback = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', verbose=1, save_best_only=True)\nmodel.fit(train_tensors, train_targets, validation_data=(valid_tensors, valid_targets), epochs=epochs, batch_size=20, callbacks=[model_checkpoint_callback], verbose=1)\n```"}, {'reason': 'stop', 'result': "```python\npixel_filter = (x < 400) & (x >= 300) & (y >= 300) & (y <= 400)\nimg[pixel_filter] = 0\nline1 = y >= 350 - 0.5 * (x - 300)\nline2 = y <= 350 + 1.0 * (x - 300)\nline3 = y <= 400 - 2.0 * (x - 350)\nimg[line1 & line2 & line3 & pixel_filter] = 1\nplt.imshow(img, interpolation='bilinear')\n```"}, {'reason': 'stop', 'result': "```python\nfor key in profile_dict.keys():\n    column_number = column_number + 1\n    column_pos = ' ({}/{})'\n    print('\\n', (' ' + key + ' ').center(report_width, header_spacing_char))\n    sub_dictionary = profile_dict[key]\n    for dictionary in sub_dictionary:\n        attribute_definition = list(dictionary.keys())\n        attribute = attribute_definition[0]\n        value = dictionary[attribute]\n        if 'percent' in attribute:\n            formatted_value = '{0:.2%}'.format(value)\n        else:\n            formatted_value = str(value)\n        print(attribute.ljust(just_width, attribute_spacing_char), formatted_value.rjust(just_width, attribute_spacing_char))\n```"}, {'reason': 'stop', 'result': "```python\nX = tf.placeholder(tf.float32, shape=(None, height, width, channels))\nmax_pooled_images = tf.nn.max_pool(X, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\nwith tf.Session() as sess:\n    max_pooled_images = sess.run(max_pooled_images, feed_dict={X: dataset})\nplt.imshow(max_pooled_images[0].astype(np.uint8))\nplt.show()\n```"}, {'reason': 'stop', 'result': "```python\nimport numpy as np\nfrom scipy.special import expit\nn = 100\nxs = np.linspace(-3, 3, n)\nReLu = np.maximum(xs, 0)\nd_ReLu = np.concatenate((np.zeros(int(n / 2)), np.ones(int(n / 2))))\nactivation_functions = np.tanh(xs)\nd_tanh = 1 - activation_functions ** 2\nsig = expit(xs)\nd_sig = sig * (1 - sig)\nplt.figure(figsize=(20, 5))\nplt.subplot(1, 3, 1)\nplt.plot(xs, ReLu, label='ReLu')\nplt.plot(xs, d_ReLu, label='d_Relu')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('ReLu(x) Plot')\nplt.ylim(-1.1, 1.1)\nplt.legend()\nplt.subplot(1, 3, 2)\nplt.plot(xs, activation_functions, label='tanh')\nplt.plot(xs, d_tanh, label='d_tanh')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('tanh(x) Plot')\nplt.ylim(-1.1, 1.1)\nplt.legend()\nplt.subplot(1, 3, 3)\nplt.plot(xs, sig, label='sigmoid')\nplt.plot(xs, d_sig, label='d_sigmoid')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Sigmoid(x) Plot')\nplt.ylim(-1.1, 1.1)\nplt.legend()\nplt.suptitle('Activation functions')\nplt.show()\n```"}, {'reason': 'stop', 'result': "```python\ndef calc_max_sum_variable_to_factor_msg(variable, factor):\n    neighbour_msg_prod = get_neighbour_messages(variable, factor)\n    if len(neighbour_msg_prod) > 0:\n        max_sum_variable_to_factor_msg = np.sum(np.array(neighbour_msg_prod), axis=0)\n    else:\n        max_sum_variable_to_factor_msg = np.zeros(variable.num_states)\n    max_sum_variable_to_factor_msg += np.log(variable.observed_state)\n    return max_sum_variable_to_factor_msg\n\ndef variable_send_ms_msg(self, factor):\n    assert isinstance(factor, Factor), 'Variable can only send messages to factor!'\n    assert can_send_message(self, factor), 'Cannot send message!'\n    out_msg = calc_max_sum_variable_to_factor_msg(self, factor)\n    factor.receive_msg(self, out_msg)\n    self.pending.discard(factor)\nVariable.send_ms_msg = variable_send_ms_msg\n```"}, {'reason': 'stop', 'result': "```python\nTP = np.sum(income)\nFP = income.count() - TP\nfalse_negatives = 0\nFN = 0\naccuracy = 1.0 * (TP + false_negatives) / (TP + false_negatives + FP + FN)\nrecall = 1.0 * TP / (TP + FN)\nprecision = 1.0 * TP / (TP + FP)\nfscore = (1.0 + 0.5 * 0.5) * (precision * recall) / (0.5 * 0.5 * precision + recall)\nprint('Naive Predictor: [Accuracy score: {}, F-score: {}]'.format(accuracy, fscore))\n```"}, {'reason': 'stop', 'result': "```python\nncomponents = 2\npca = decomp.PCA(n_components=ncomponents)\nraw_pca = pca.fit(np.array(x_train.iloc[:, first_egemaps_feature:]).astype(np.float))\nx_pca = raw_pca.transform(x_train.iloc[:, first_egemaps_feature:])\ngroups = x_train['pos']\nshort_pos = {'nouns': 'nn', 'verbs': 'vrb', 'other': 'oth', 'function_words': 'fct', 'adjectives': 'adj'}\ngroup_values = [short_pos[i] for i in groups.unique()]\nposIDs = groups.factorize()[0]\nlabels = np.array(x_train['word'])\nfig = plt.figure()\nax = fig.add_subplot(111)\nax.set_xlabel('PC 1')\nax.set_ylabel('PC 2')\ncolormap = plt.get_cmap('gnuplot', len(group_values))\npc1 = x_pca[:, 0]\npca_component_2 = x_pca[:, 1]\np = ax.scatter(pc1, pca_component_2, c=posIDs, cmap=colormap, s=10)\ncb = plt.colorbar(p)\nloc = np.arange(0, max(posIDs), max(posIDs) / float(len(group_values)))\ncb.set_ticks(loc)\ncb.set_ticklabels(group_values)\nfor label, x, y in zip(labels, pc1, pca_component_2):\n    if y == np.amax(y) or x == np.amax(x):\n        plt.annotate(label, fontsize=2, xy=(x, y), xytext=(0, 1), textcoords='offset points', ha='right', va='bottom')\nif pos_filter == None:\n    axins = zoomed_inset_axes(ax, 2.5, loc=2)\n    x1, x2, y1, y2 = (-3.1, 2.5, 6.3, 9.8)\n    axins.set_xlim(x1, x2)\n    axins.set_ylim(y1, y2)\n    axins.scatter(pc1, pca_component_2, c=posIDs, cmap=colormap)\n    plt.yticks(visible=False)\n    plt.xticks(visible=False)\n    mark_inset(ax, axins, loc1=2, loc2=4, fc='none', ec='0.5')\n    for label, x, y in zip(labels, pc1, pca_component_2):\n        if y == np.amax(y) or x == np.amax(x):\n            plt.annotate(label, fontsize=8, xy=(x, y), xytext=(0, 1), textcoords='offset points', ha='right', va='bottom')\n    axins2 = zoomed_inset_axes(ax, 2.5, loc=4)\n    x1, x2, y1, y2 = (-4, 0.5, -8.5, -6.5)\n    axins2.set_xlim(x1, x2)\n    axins2.set_ylim(y1, y2)\n    axins2.scatter(pc1, pca_component_2, c=posIDs, cmap=colormap)\n    plt.yticks(visible=False)\n    plt.xticks(visible=False)\n    mark_inset(ax, axins2, loc1=2, loc2=4, fc='none', ec='0.5')\n    for label, x, y in zip(labels, pc1, pca_component_2):\n        if y == np.amax(y) or x == np.amax(x):\n            plt.annotate(label, fontsize=8, xy=(x, y), xytext=(0, 1), textcoords='offset points', ha='right', va='bottom')\nfilename = corpus + '_full_zoom.pdf'\nif pos_filter != None and len(pos_filter) == 1:\n    filename = corpus + '_pca_' + pos_filter[0][1] + '_' + pos_filter[0][2] + '.pdf'\nplt.savefig(filename, bbox_inches='tight')\n```"}, {'reason': 'stop', 'result': "```python\nX, Annotations = marconi['Walk1']\ncamera = 0\nframe = 220\nfig = plt.figure(figsize=(16, 8))\nax = fig.add_subplot(111)\nim = X[camera, frame]\nax.imshow(im)\nAnnotations_for_cam = Annotations[camera]\nAnnot_on_frame_cam = Annotations_for_cam[frame]\nCOLORS = ['red', 'yellow']\nfor i, annot in enumerate(Annot_on_frame_cam):\n    if annot is not None:\n        (tl, br), joints = annot\n        head_x, head_y_coordinate = utils.tl_br_to_plt_plot(tl[1], tl[0], br[1], br[0])\n        ax.plot(head_x, head_y_coordinate, color=COLORS[i])\n        for jx, jy, visible in joints:\n            plt.scatter(jx, jy, color=COLORS[i], alpha=1 if visible == 1 else 0.4)\nplt.axis('off')\nplt.show()\n```"}, {'reason': 'stop', 'result': "```python\nheight = 28\nwidth = 28\nchannels = 1\nn_inputs = height * width\nconv1_fmaps = 32\nconv1_ksize = 3\nconv1_stride = 1\nconv1_pad = 'SAME'\nconv2_fmaps = 64\nconv2_ksize = 3\nconv2_stride = 2\nconv2_pad = 'SAME'\npool3_fmaps = conv2_fmaps\nn_fc1 = 64\nnum_classes = 10\nreset_graph()\nwith tf.name_scope('inputs'):\n    X = tf.placeholder(tf.float32, shape=[None, n_inputs], name='X')\n    X_reshaped = tf.reshape(X, shape=[-1, height, width, channels])\n    y = tf.placeholder(tf.int32, shape=[None], name='y')\nconv1 = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps, kernel_size=conv1_ksize, strides=conv1_stride, padding=conv1_pad, activation=tf.nn.relu, name='conv1')\nconv2 = tf.layers.conv2d(conv1, filters=conv2_fmaps, kernel_size=conv2_ksize, strides=conv2_stride, padding=conv2_pad, activation=tf.nn.relu, name='conv2')\nwith tf.name_scope('pool3'):\n    pool3 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n    pool3_flat = tf.reshape(pool3, shape=[-1, pool3_fmaps * 7 * 7])\nwith tf.name_scope('fc1'):\n    fc1 = tf.layers.dense(pool3_flat, n_fc1, activation=tf.nn.relu, name='fc1')\nwith tf.name_scope('output'):\n    logits = tf.layers.dense(fc1, num_classes, name='output')\n    Y_proba = tf.nn.softmax(logits, name='Y_proba')\nwith tf.name_scope('train'):\n    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n    loss = tf.reduce_mean(xentropy)\n    optimizer = tf.train.AdamOptimizer()\n    training_op = optimizer.minimize(loss)\nwith tf.name_scope('eval'):\n    correct = tf.nn.in_top_k(logits, y, 1)\n    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\nwith tf.name_scope('init_and_save'):\n    init = tf.global_variables_initializer()\n    saver = tf.train.Saver()\n```"}, {'reason': 'stop', 'result': '```python\ncolors = [\'b\', \'g\', \'r\', \'k\', \'c\', \'m\', \'y\']\nindex = 0\nfor segment in segments:\n    segDF = data.loc[data[\'RiverSeg\'] == segment]\n    segDF = segDF[segDF["lam\'"] > 0]\n    segDF = segDF.sort_values(\'Year\')\n    x = segDF[\'Year\']\n    fish_population = segDF["N10\'"]\n    fish_population.name = segment\n    plt.plot(x, fish_population, colors[index])\n    plt.legend(loc=(1.05, 0.2))\n    index += 1\nplt.title("Hill N10\', " + river + \' River Segments\')\nplt.xlabel(\'Year\')\nplt.ylabel("N10\'")\nplt.xticks(np.arange(min(x), max(x) + 1, 1.0))\nplt.xticks(rotation=90)\nplt.savefig(output + \'\\\\\' + river + "_Hill_N10\'.png", bbox_inches=\'tight\', dpi=300, size=(2000, 2000))\nplt.show()\n```'}, {'reason': 'stop', 'result': "```python\nimport sys\nimport tarfile\nfrom six.moves import urllib\nTF_MODELS_URL = 'http://download.tensorflow.org/models'\nINCEPTION_V3_URL = TF_MODELS_URL + '/inception_v3_2016_08_28.tar.gz'\ninception_model_dir = os.path.join('datasets', 'inception')\nINCEPTION_V3_CHECKPOINT_PATH = os.path.join(inception_model_dir, 'inception_v3.ckpt')\n\ndef download_progress(count, block_size, total_size):\n    percent = count * block_size * 100 // total_size\n    sys.stdout.write('\\rDownloading: {}%'.format(percent))\n    sys.stdout.flush()\n\ndef fetch_pretrained_inception_v3(url=INCEPTION_V3_URL, path=inception_model_dir):\n    if os.path.exists(INCEPTION_V3_CHECKPOINT_PATH):\n        return\n    os.makedirs(path, exist_ok=True)\n    tgz_path = os.path.join(path, 'inception_v3.tgz')\n    urllib.request.urlretrieve(url, tgz_path, reporthook=download_progress)\n    inception_tgz = tarfile.open(tgz_path)\n    inception_tgz.extractall(path=path)\n    inception_tgz.close()\n    os.remove(tgz_path)\n```"}, {'reason': 'stop', 'result': "```python\nt_min_max = (vsig.timestamps[0], vsig.timestamps[-1])\nlayer = '2'\no_or_s = 'output'\nhidden_layer_data = np.load(os.path.join(vsig.out_dir, '_'.join(['valid_hidden_layer', layer, o_or_s])) + '.npy')\nn_generations, _, n_neurons = hidden_layer_data.shape\nncols = 2\nnrows = n_neurons // ncols\nfig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(16, 20))\nfor g in range(n_generations):\n    for i in range(n_neurons):\n        ax = axes[i // ncols, i % ncols]\n        ax.cla()\n        y_pred_colors = hidden_layer_data[g, :, i]\n        ax.plot(vsig.timestamps, vsig.mixed_signal, color='grey', alpha=0.3)\n        ax.scatter(vsig.timestamps, x_val[0, :, 0], vsig.timestamps[vsig.window_size - 1:], marker='o', c=y_pred_colors, cmap=plt.get_cmap('coolwarm'), vmin=-1, vmax=1)\n        ax.set_title('neuron = {}'.format(i + 1))\n        ax.set_xlim(t_min_max)\n        ax.grid(True)\n    plt.tight_layout()\n    plt.suptitle('hidden layer = {}, ({}), generation = {}'.format(layer, o_or_s, g + 1))\n    plt.savefig(os.path.join(vsig.out_dir, '_'.join(['valid_hidden_layer', layer, o_or_s, 'gen', str(g + 1)]) + '.png'))\nplt.show()\n```"}, {'reason': 'stop', 'result': '```python\nregression_line_error = None\n```'}, {'reason': 'stop', 'result': "```python\nX, Annotations = marconi['Soccer2']\ncamera = 0\nframe = 220\nfig = plt.figure(figsize=(16, 8))\nax = fig.add_subplot(111)\nimage_frame = X[camera, frame]\nax.imshow(image_frame)\nAnnotations_for_cam = Annotations[camera]\nAnnot_on_frame_cam = Annotations_for_cam[frame]\nCOLORS = ['red', 'yellow']\nfor i, annot in enumerate(Annot_on_frame_cam):\n    if annot is not None:\n        (tl, br), joints = annot\n        head_x, head_y = utils.tl_br_to_plt_plot(tl[1], tl[0], br[1], br[0])\n        ax.plot(head_x, head_y, color=COLORS[i])\n        for jx, jy, visible in joints:\n            plt.scatter(jx, jy, color=COLORS[i], alpha=1 if visible == 1 else 0.4)\nplt.axis('off')\nplt.show()\n```"}, {'reason': 'stop', 'result': "```python\nfrom pandas import DataFrame\nfrom pandas import Series\nfrom pandas import concat\nfrom pandas import read_csv\nfrom pandas import datetime\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom math import sqrt\nfrom matplotlib import pyplot\nimport numpy\nfilename = '/Users/shengyuchen/Dropbox/Engagement - Business/My Hub/AI:ML:DL Playground/Local Python/AI-ML-DL Algorithms/LSTM Neural Networks/shampoo-sales.csv'\n\ndef parser(x):\n    return datetime.strptime('190' + x, '%Y-%b')\n\ndef timeseries_to_supervised(data, lag=1):\n    df = DataFrame(data)\n    columns = [df.shift(i) for i in range(1, lag + 1)]\n    columns.append(df)\n    df = concat(columns, axis=1)\n    df.fillna(0, inplace=True)\n    return df\n\ndef difference(dataset, interval=1):\n    diff = list()\n    for i in range(interval, len(dataset)):\n        value = dataset[i] - dataset[i - interval]\n        diff.append(value)\n    return Series(diff)\n\ndef inverse_difference(history, yhat, interval=1):\n    return yhat + history[-interval]\n\ndef scale(train, test):\n    scaler = MinMaxScaler(feature_range=(-1, 1))\n    scaler = scaler.fit(train)\n    train = train.reshape(train.shape[0], train.shape[1])\n    train_scaled = scaler.transform(train)\n    test = test.reshape(test.shape[0], test.shape[1])\n    test_scaled = scaler.transform(test)\n    return (scaler, train_scaled, test_scaled)\n\ndef invert_scale(scaler, X, value):\n    new_row = [x for x in X] + [value]\n    array = numpy.array(new_row)\n    array = array.reshape(1, len(array))\n    inverted = scaler.inverse_transform(array)\n    return inverted[0, -1]\n\ndef fit_lstm(train, batch_size, nb_epoch, neurons):\n    X, y = (train[:, 0:-1], train[:, -1])\n    X = X.reshape(X.shape[0], 1, X.shape[1])\n    model = Sequential()\n    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n    model.add(Dense(1))\n    model.compile(loss='mean_squared_error', optimizer='adam')\n    for i in range(nb_epoch):\n        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n        model.reset_states()\n    return model\n\ndef forecast_lstm(model, batch_size, X):\n    X = X.reshape(1, 1, len(X))\n    yhat = model.predict(X, batch_size=batch_size)\n    return yhat[0, 0]\nseries = read_csv(filename, header=0, parse_dates=[0], index_col=0, squeeze=True)\nraw_values = series.values\ndiff_values = difference(raw_values, 1)\nsupervised = timeseries_to_supervised(diff_values, 1)\nsupervised_values = supervised.values\ntrain, test = (supervised_values[0:-12], supervised_values[-12:])\nscaler, train_scaled, test_scaled = scale(train, test)\nlstm_model = fit_lstm(train_scaled, 1, 3000, 4)\ntrain_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)\nlstm_model.predict(train_reshaped, batch_size=1)\nforecasted_sales = list()\nfor i in range(len(test_scaled)):\n    X, y = (test_scaled[i, 0:-1], test_scaled[i, -1])\n    yhat = forecast_lstm(lstm_model, 1, X)\n    yhat = invert_scale(scaler, X, yhat)\n    yhat = inverse_difference(raw_values, yhat, len(test_scaled) + 1 - i)\n    forecasted_sales.append(yhat)\n    expected = raw_values[len(train) + i + 1]\n    print('Month=%d, Predicted=%f, Expected=%f' % (i + 1, yhat, expected))\nrmse = sqrt(mean_squared_error(raw_values[-12:], forecasted_sales))\nprint('Test RMSE: %.3f' % rmse)\npyplot.plot(raw_values[-12:])\npyplot.plot(forecasted_sales)\npyplot.show()\n```"}, {'reason': 'stop', 'result': "```python\nmy_labels = [16, 33, 11, 38, 35, 17]\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    saver = tf.train.import_meta_graph('./lenet.meta')\n    saver.restore(sess, './lenet')\n    preprocessed_images = [normalize(rgb2gray(img)) for img in my_images]\n    my_accuracy = evaluate(preprocessed_images, my_labels)\n    print('Test Set Accuracy = {:.3f}'.format(my_accuracy))\n```"}, {'reason': 'stop', 'result': "```python\ndef LeNet6(x, n_classes):\n    mu = 0\n    sigma = 0.1\n    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6), mean=mu, stddev=sigma))\n    conv1_b = tf.Variable(tf.zeros(6))\n    conv1 = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n    conv1 = tf.nn.relu(conv1)\n    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean=mu, stddev=sigma))\n    conv2_b = tf.Variable(tf.zeros(16))\n    conv2 = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n    conv2 = tf.nn.relu(conv2)\n    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n    fc0 = flatten(conv2)\n    fc1_W = tf.Variable(tf.truncated_normal(shape=(400, 252), mean=mu, stddev=sigma))\n    fc1_b = tf.Variable(tf.zeros(252))\n    fc1 = tf.matmul(fc0, fc1_W) + fc1_b\n    fc1 = tf.nn.relu(fc1)\n    fc1 = tf.nn.dropout(fc1, keep_prob)\n    fc2_W = tf.Variable(tf.truncated_normal(shape=(252, 168), mean=mu, stddev=sigma))\n    fc2_bias = tf.Variable(tf.zeros(168))\n    fc2 = tf.matmul(fc1, fc2_W) + fc2_bias\n    fc2 = tf.nn.relu(fc2)\n    fc2 = tf.nn.dropout(fc2, keep_prob)\n    fc3_W = tf.Variable(tf.truncated_normal(shape=(168, 84), mean=mu, stddev=sigma))\n    fc3_b = tf.Variable(tf.zeros(84))\n    fc3 = tf.matmul(fc2, fc3_W) + fc3_b\n    fc3 = tf.nn.relu(fc3)\n    fc3 = tf.nn.dropout(fc3, keep_prob)\n    fc4_W = tf.Variable(tf.truncated_normal(shape=(84, n_classes), mean=mu, stddev=sigma))\n    fc4_b = tf.Variable(tf.zeros(n_classes))\n    logits = tf.matmul(fc3, fc4_W) + fc4_b\n    return logits\n```"}, {'reason': 'stop', 'result': "```python\ncols = ['arr_port', 'pax']\nbooking_data = get_df_cols(BOOKINGS, cols, '^')\nprint_top_n_arrival_airport(booking_data, 10)\n```"}, {'reason': 'stop', 'result': "```python\nX_test_refined = pd.DataFrame([])\nr_precisions = []\npbar = tqdm(data_test.groupby(['playlist_pid']))\nfor pid, df in pbar:\n    target_indices = y_test.loc[df.index]\n    from IPython.core.debugger import set_trace\n    set_trace()\n    targets = dataset.loc[target_indices.index].track_duration_ms\n    positive_targets = dataset.loc[target_indices[target_indices == 1].index].index\n    negative_tracks = dataset.loc[X_test[X_test.playlist_pid != pid].index].track_duration_ms\n    new_df = df.drop('track_duration_ms', axis=1)\n    new_test = negative_tracks.append(targets)\n    new_df = pd.concat([new_df.head(1)] * len(new_test))\n    test_playlist_tracks = pd.concat([new_df.reset_index(drop=True), new_test.reset_index(drop=True)], axis=1).set_index(new_test.index)\n    test_playlist_tracks = (test_playlist_tracks - test_playlist_tracks.mean()) / (test_playlist_tracks.std() + 1e-08)\n    X_test_refined = X_test_refined.append(test_playlist_tracks)\n    y_prob = pd.DataFrame(lr_clf.predict_proba(test_playlist_tracks), index=test_playlist_tracks.index)\n    y_prob = y_prob.sort_values(by=[1], ascending=False)\n    if len(positive_targets) > 0:\n        r_precisions.append(r_precision(positive_targets, y_prob.index))\n    pbar.set_description('{}'.format(np.mean(r_precisions)))\n```"}, {'reason': 'stop', 'result': "```python\ncounty = df_county_data['County Name']\nhouse_size = df_county_data['Household Size']\nx_axis = np.arange(len(house_size))\ncounty_indices = [value for value in x_axis]\nplt.bar(x_axis, house_size, color='r', align='center')\nplt.title('County Household Size')\nplt.xlabel('Counties')\nplt.ylabel('Household Size')\nplt.text(140, 2.5, 'Note:\\nHousehold size for all counties in NJ, NY, & PA.')\nplt.savefig('Images/County_Household_Size.png', bbox_inches='tight')\nplt.show()\n```"}, {'reason': 'stop', 'result': '```python\ndef roc_auc(labels, predictions, thresholds, get_fpr_tpr=True):\n    tpr = []\n    fpr = []\n    for th in thresholds:\n        tp_cases = tf.where(tf.greater_equal(predictions, th) & tf.equal(labels, 1))\n        tp = tf.size(tp_cases)\n        tn_cases = tf.where(tf.less(predictions, th) & tf.equal(labels, 0))\n        tn = tf.size(tn_cases)\n        fp_cases = tf.where(tf.greater_equal(predictions, th) & tf.equal(labels, 0))\n        fp = tf.size(fp_cases)\n        fn_cases = tf.where(tf.less(predictions, th) & tf.equal(labels, 1))\n        fn = tf.size(fn_cases)\n        tpr_th = tp / (tp + fn)\n        fpr_th = fp / (fp + tn)\n        tpr.append(tpr_th)\n        fpr.append(fpr_th)\n    auc_score = 0\n    for i in range(0, len(thresholds) - 1):\n        height_step = tf.abs(fpr[i + 1] - fpr[i])\n        b1 = tpr[i]\n        tpr_next = tpr[i + 1]\n        step_area = height_step * (b1 + tpr_next) / 2\n        auc_score += step_area\n    return (auc_score, fpr, tpr)\n```'}, {'reason': 'stop', 'result': "```python\nmf = flopy.modflow.Modflow(modelname=modelname, exe_name=mfexe, model_ws=modelpth)\ndis = flopy.modflow.ModflowDis(mf, nlay, nrow, ncol, delr=delr, delc=delc, top=botm[0, :, :], botm=botm[1:, :, :], perlen=1, nstp=1, steady=True)\nmodflow_model = flopy.modflow.ModflowBas(mf, ibound=ibound, strt=strt)\nlpf = flopy.modflow.ModflowLpf(mf, hk=0.0001, laytyp=4)\noc = flopy.modflow.ModflowOc(mf, stress_period_data={(0, 0): ['print budget', 'print head', 'save head', 'save budget']})\nsms = flopy.modflow.ModflowSms(mf, nonlinmeth=1, linmeth=1, numtrack=50, btol=1.1, breduc=0.7, reslim=0.0, theta=0.85, akappa=0.0001, gamma=0.0, amomentum=0.1, iacl=2, norder=0, level=5, north=7, iredsys=0, rrctol=0.0, idroptol=1, epsrn=1e-05, mxiter=500, hclose=0.001, hiclose=0.001, iter1=50)\nmf.write_input()\ntry:\n    os.remove(os.path.join(model_ws, '{0}.hds'.format(modelname)))\nexcept:\n    pass\nmf.run_model()\n```"}, {'reason': 'stop', 'result': '```python\ndef prepare_image_with_tensorflow(image, target_width=299, target_height=299, max_zoom=0.2):\n    """Zooms and crops the image randomly for data augmentation."""\n    image_shape = tf.cast(tf.shape(image), tf.float32)\n    height = image_shape[0]\n    width = image_shape[1]\n    image_ratio = width / height\n    target_image_ratio = target_width / target_height\n    crop_vertically = image_ratio < target_image_ratio\n    crop_width = tf.cond(crop_vertically, lambda: width, lambda: height * target_image_ratio)\n    crop_height = tf.cond(crop_vertically, lambda: width / target_image_ratio, lambda: height)\n    resize_factor = tf.random_uniform(shape=[], minval=1.0, maxval=1.0 + max_zoom)\n    crop_width = tf.cast(crop_width / resize_factor, tf.int32)\n    crop_height = tf.cast(crop_height / resize_factor, tf.int32)\n    box_size = tf.stack([crop_height, crop_width, 3])\n    image = tf.random_crop(image, box_size)\n    image = tf.image.random_flip_left_right(image)\n    processed_image = tf.expand_dims(image, 0)\n    processed_image = tf.image.resize_bilinear(processed_image, [target_height, target_width])\n    image = processed_image[0] / 255\n    return image\n```'}, {'reason': 'stop', 'result': "```python\nL_AB_m, L_BD_m = sy.symbols('L_{AB}[m], L_{BD}[m]')\ntotal_length_m = L_AB_m + L_BD_m\ns_d = {L_AB_m: 3, L_BD_m: 3}\n```"}, {'reason': 'stop', 'result': '```python\nimport numpy as np\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport warnings\nfrom pybbn.generator.bbngenerator import generate_singly_bbn, generate_multi_bbn, convert_for_exact_inference\nfrom pybbn.generator.bbngenerator import convert_for_drawing\nfrom pybbn.pptc.inferencecontroller import InferenceController\nnp.random.seed(37)\ng, variable_definitions = generate_multi_bbn(5, max_iter=5)\nm_bbn = convert_for_exact_inference(g, variable_definitions)\nnx_multi_bbn = convert_for_drawing(m_bbn)\ng, variable_definitions = generate_singly_bbn(5, max_iter=10)\ns_bbn = convert_for_exact_inference(g, variable_definitions)\nnx_singly_bbn = convert_for_drawing(s_bbn)\n```'}, {'reason': 'stop', 'result': '```python\nstickwidth = 4\nfor i in range(17):\n    for n in range(len(subset)):\n        index = subset[n][np.array(limbSeq[i]) - 1]\n        if -1 in index:\n            continue\n        cur_canvas = canvas.copy()\n        keypoint_coordinates = candidate[index.astype(int), 0]\n        X = candidate[index.astype(int), 1]\n        mX = np.mean(X)\n        mY = np.mean(keypoint_coordinates)\n        length = ((X[0] - X[1]) ** 2 + (keypoint_coordinates[0] - keypoint_coordinates[1]) ** 2) ** 0.5\n        angle = math.degrees(math.atan2(X[0] - X[1], keypoint_coordinates[0] - keypoint_coordinates[1]))\n        polygon = cv.ellipse2Poly((int(mY), int(mX)), (int(length / 2), stickwidth), int(angle), 0, 360, 1)\n        cv.fillConvexPoly(cur_canvas, polygon, colors[i])\n        canvas = cv.addWeighted(canvas, 0.4, cur_canvas, 0.6, 0)\nplt.imshow(canvas[:, :, [2, 1, 0]])\nfig = matplotlib.pyplot.gcf()\nfig.set_size_inches(12, 12)\n```'}, {'reason': 'stop', 'result': '```python\nklay = 2.01\nsteph = 1.91\nkevin = 2.06\nplayer_heights = ...\n```'}, {'reason': 'stop', 'result': "```python\nvisualize_dataset = True\nfeatures_to_exclude = ['x', 'y', 'z']\nmean_value_definition = 'mean'\nnunique_range = [2, 10]\npalette = 'Dark2'\nidentity_type = 'hist'\nnon_identity_type = 'scatter'\n```"}, {'reason': 'stop', 'result': '```python\ndef expectedFit(x, a, b):\n    """\n    Returns the expected fit for the histogram\n    \n    Arguments: x - the x value in the equation\n               a - the first fit parameter\n               b - the second fit paramter\n               \n    Returned: The expected fit function\n    """\n    return a * np.exp(-b * x)\noccurenceRegion = bigOccurences[7:14]\nmagnitudeRegion = bigMagnitudes[7:14]\nparameters, covariance = curve_fit(expectedFit, magnitudeRegion, occurenceRegion)\nfitX = magnitudeRegion\naFit = parameters[0]\nfit_parameter_b = parameters[1]\nfitY = aFit * np.exp(-fit_parameter_b * magnitudeRegion)\nprint(\'A = \', aFit, \'b = \', fit_parameter_b)\n```'}, {'reason': 'stop', 'result': "```python\nmixture_model_components = []\nnp.random.seed(45)\nwith pm.Model() as model:\n    pi = pm.Dirichlet('pi', np.ones(K))\n    comp_dist = []\n    mu = []\n    sigma_sq = []\n    cov = []\n    for i in range(K):\n        temp_mean = np.random.randint(low=20, high=230, size=D)\n        mu.append(pm.Normal('mu%i' % i, temp_mean, 20, shape=D))\n        sigma_sq.append(pm.InverseGamma('sigma_sq%i' % i, 1, 1, shape=D))\n        cov.append(tt.nlinalg.alloc_diag(sigma_sq[i]))\n        comp_dist.append(pm.MvNormal.dist(mu=mu[i], cov=cov[i]))\n        mixture_model_components.append(temp_mean)\n    xobs = pm.Mixture('x_obs', pi, comp_dist, observed=X_shared)\n```"}, {'reason': 'stop', 'result': "```python\ndef get_wide_deep():\n    is_male, mother_age, plurality, gestation_weeks = [tf.feature_column.categorical_column_with_vocabulary_list('is_male', ['True', 'False', 'Unknown']), tf.feature_column.numeric_column('mother_age'), tf.feature_column.categorical_column_with_vocabulary_list('plurality', ['Single(1)', 'Twins(2)', 'Triplets(3)', 'Quadruplets(4)', 'Quintuplets(5)', 'Multiple(2+)']), tf.feature_column.numeric_column('gestation_weeks')]\n    age_buckets = tf.feature_column.bucketized_column(mother_age, boundaries=np.arange(15, 45, 1).tolist())\n    gestation_buckets = tf.feature_column.bucketized_column(gestation_weeks, boundaries=np.arange(17, 47, 1).tolist())\n    wide = [is_male, plurality, age_buckets, gestation_buckets]\n    crossed = tf.feature_column.crossed_column(wide, hash_bucket_size=20000)\n    embed = tf.feature_column.embedding_column(crossed, 3)\n    deep = [mother_age, gestation_weeks, embed]\n    return (wide, deep)\n```"}, {'reason': 'stop', 'result': "```python\nPROJECT_DIR = '../../'\nis_small_model = False\nLOG_DIR = 'logs'\nif is_small_model:\n    batch_size = 8\n    embedding_dim = 5\n    cell_size = 32\n    max_len = 6\nelse:\n    batch_size = 64\n    embedding_dim = 20\n    cell_size = 128\n    max_len = 33\nuse_attention = True\nuse_bidirectional_encoder = True\nis_time_major = True\n```"}, {'reason': 'stop', 'result': '```python\nrebin = 0\nvariable_definition = {0: 0.0336577}\noutPath = \'/home/pyne-user/Dropbox/UCB/Research/ETAs/88Inch/Data/Experiments/PHS/33MeVTa_29-31Mar17/Unfold/BeamOnly/HEPROW/Inputs/\'\ngROOT.ProcessLine(\'HistogramWriter writer;\')\nfor detNum, detName in detNames.iteritems():\n    gROOT.ProcessLine(\'PulseHeightSpectrum{0} = (TH1D*)ops.truncateHist(phs{0}[1],{1},30)\'.format(detNum, variable_definition[detNum]))\n    gROOT.ProcessLine(\'PulseHeightSpectrum{0}->Rebin({1})\'.format(detNum, rebin))\n    gROOT.ProcessLine(\'TH1* dataHist{0} = ops.rebinStatistically(PulseHeightSpectrum{0},100);\'.format(detNum))\n    gROOT.ProcessLine(\'writer.PhToHEPROW(PulseHeightSpectrum{0},"{1}{2}_phs_03")\'.format(detNum, outPath, detName))\n    gROOT.ProcessLine(\'writer.PhToHEPROW(dataHist{0},"{1}{2}_stat_100_phs_03")\'.format(detNum, outPath, detName))\n```'}, {'reason': 'stop', 'result': '```python\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(-1, 1))\nscaler\n```'}, {'reason': 'stop', 'result': "```python\nbatch_size = 128\nembedding_size = 128\nskip_window = 1\nnum_skips = 2\nvalid_size = 16\nvalid_window = 100\nvalid_words_indices = np.array(random.sample(range(valid_window), valid_size))\nnum_sampled = 64\ngraph = tf.Graph()\nwith graph.as_default(), tf.device('/cpu:0'):\n    train_dataset = tf.placeholder(tf.int32, shape=[batch_size])\n    train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n    valid_dataset = tf.constant(valid_words_indices, dtype=tf.int32)\n    embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n    softmax_weights = tf.Variable(tf.truncated_normal([vocabulary_size, embedding_size], stddev=1.0 / math.sqrt(embedding_size)))\n    softmax_biases = tf.Variable(tf.zeros([vocabulary_size]))\n    embed = tf.nn.embedding_lookup(embeddings, train_dataset)\n    loss = tf.reduce_mean(tf.nn.sampled_softmax_loss(weights=softmax_weights, biases=softmax_biases, inputs=embed, labels=train_labels, num_sampled=num_sampled, num_classes=vocabulary_size))\n    optimizer = tf.train.AdagradOptimizer(1.0).minimize(loss)\n    norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n    normalized_embeddings = embeddings / norm\n    valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings, valid_dataset)\n    similarity = tf.matmul(valid_embeddings, tf.transpose(normalized_embeddings))\n```"}, {'reason': 'stop', 'result': "```python\nfig = plt.figure(figsize=(16, 5))\nax = fig.add_subplot(121)\nax.axis('off')\nay = fig.add_subplot(122)\nay.axis('off')\nP1 = Ps[0]\nP2 = Ps[1]\nK1 = Ks[0]\nK2 = Ks[1]\nRt1 = Rts[0]\nRt2 = Rts[1]\nannot1 = Annotations[0][0]\nannot2 = Annotations[1][0]\nindv_left = annot1[0]\nvariable_description = annot2[1]\nlefthand_left = indv_left[1][0]\nlefthand_right = variable_description[1][0]\nax.imshow(X[0, 0])\nax.scatter(lefthand_left[0], lefthand_left[1], color='red')\nay.imshow(X[1, 0])\nay.scatter(lefthand_right[0], lefthand_right[1], color='red')\nplt.show()\n```"}, {'reason': 'stop', 'result': '```python\nannotations = create_anottations(lista)\n```'}, {'reason': 'stop', 'result': '```python\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nrmse_score = sqrt(mean_squared_error(y_test, y_test_predict))\nrmse_score\n```'}, {'reason': 'stop', 'result': "```python\ndef build_index(non_empty_days, from_time, to_time):\n    date_ranges = []\n    for date in non_empty_days:\n        yyyy, mm, dd = date.split('-')\n        from_hour, from_min = from_time.split(':')\n        to_hour, to_min = to_time.split(':')\n        t1 = datetime(int(yyyy), int(mm), int(dd), int(from_hour), int(from_min), 0)\n        to_datetime = datetime(int(yyyy), int(mm), int(dd), int(to_hour), int(to_min), 0)\n        date_ranges.append(pd.DataFrame({'OrganizedDateTime': pd.date_range(t1, to_datetime, freq='1Min').values}))\n    agg = pd.concat(date_ranges, axis=0)\n    agg.index = agg['OrganizedDateTime']\n    return agg\n```"}, {'reason': 'stop', 'result': "```python\ntrack_artist_lower_df = tracks_df['track_artist_uri'].apply(lambda x: x.lower())\ntrack_album_lower_df = tracks_df['track_album_uri'].apply(lambda x: x.lower())\ntrack_uri_lower_df = merged['track_uri'].apply(lambda x: x.lower())\n\ndef get_translation(uri_type, uri):\n    track = False\n    if uri_type == 'track_artist_uri':\n        df = track_artist_lower_df\n        col = 'track_artist_name'\n    elif uri_type == 'track_album_uri':\n        df = track_album_lower_df\n        col = 'track_album_name'\n    elif uri_type == 'track_uri':\n        df = track_uri_lower_df\n        col = 'track_name'\n        track = True\n    for i in range(len(tracks_df)):\n        if df[i] == uri:\n            if track == True:\n                return merged.iloc[i][col]\n            return tracks_df.iloc[i][col]\n            break\n```"}, {'reason': 'stop', 'result': '```python\ncolors = [\'b\', \'g\', \'r\', \'k\', \'c\', \'m\', \'y\']\nindex = 0\nfor segment in segments:\n    segDF = data.loc[data[\'RiverSeg\'] == segment]\n    segDF = segDF[segDF["lam\'"] > 0]\n    segDF = segDF.sort_values(\'Year\')\n    x = segDF[\'Year\']\n    fish_population = segDF["N21\'"]\n    fish_population.name = segment\n    plt.plot(x, fish_population, colors[index])\n    plt.legend(loc=(1.05, 0.2))\n    index += 1\nplt.title("Hill N21\', " + river + \' River Segments\')\nplt.xlabel(\'Year\')\nplt.ylabel("N21\'")\nplt.xticks(np.arange(min(x), max(x) + 1, 1.0))\nplt.xticks(rotation=90)\nplt.savefig(output + \'\\\\\' + river + "_Hill_N21\'.png", bbox_inches=\'tight\', dpi=300, size=(2000, 2000))\nplt.show()\n```'}, {'reason': 'stop', 'result': "```python\nunique_hotels_names = most_checkins['Hotel Name'].unique()\nunique_checkins = most_checkins['Checkin Date'].unique()\nunique_discount_code = [1, 2, 3, 4]\nimport itertools\nimport sys\ncombs = []\nfor x in unique_hotels_names:\n    for y in unique_checkins:\n        for z in unique_discount_code:\n            combs.append([x, y, z, sys.maxsize])\nnew_hotel_checkin_discount_data = DataFrame.from_records(combs, columns=['Hotel Name', 'Checkin Date', 'Discount Code', 'Discount Price'])\nmost_checkins = most_checkins.append(new_hotel_checkin_discount_data)\n```"}, {'reason': 'stop', 'result': "```python\ntuned_parameters = [{'kernel': ['rbf'], 'nu': [0.0001, 0.001, 0.01, 0.1, 0.5]}, {'kernel': ['poly'], 'degree': np.arange(1, 4), 'nu': [0.0001, 0.001, 0.01, 0.1, 0.5], 'max_iter': [10000]}]\nparameter_search_obj = ParameterSearch(svm.OneClassSVM, tuned_parameters, act_train_svm, act_train_all, pred_f_tr.flatten(), scorer_roc_probas_svm, n_iter=5, verbosity=11, n_jobs=-1, subsample_train=0.01, subsample_test=0.001)\nparameter_search_obj.fit()\n```"}, {'reason': 'stop', 'result': '```python\nfrom sklearn.metrics import fbeta_score, accuracy_score\nbeta = 0.5\n\ndef train_predict(learner, sample_size, X_train, y_train, X_test, y_test):\n    """\n    inputs:\n       - learner: the learning algorithm to be trained and predicted on\n       - sample_size: the size of samples (number) to be drawn from training set\n       - X_train: features training set\n       - y_train: income training set\n       - X_test: features testing set\n       - y_test: income testing set\n    """\n    results = {}\n    training_start_time = time()\n    learner = learner.fit(X_train[:sample_size], y_train[:sample_size])\n    end = time()\n    results[\'train_time\'] = end - training_start_time\n    training_start_time = time()\n    predictions_test = learner.predict(X_test)\n    predictions_train = learner.predict(X_train[:300])\n    end = time()\n    results[\'pred_time\'] = end - training_start_time\n    results[\'acc_train\'] = accuracy_score(y_train[:300], predictions_train)\n    results[\'acc_test\'] = accuracy_score(y_test, predictions_test)\n    results[\'f_train\'] = fbeta_score(y_train[:300], predictions_train, beta)\n    results[\'f_test\'] = fbeta_score(y_test, predictions_test, beta)\n    print(\'{} trained on {} samples.\'.format(learner.__class__.__name__, sample_size))\n    return results\n```'}, {'reason': 'stop', 'result': '```python\nc, _, _, f = window_bounds(((x_start, 5000), (y_start, 5000)), orig_aff)\na, b, _, d, particulate_matter_resolution, _, _, _, _ = tuple(orig_aff)\nnew_aff = rasterio.Affine(a, b, c, d, particulate_matter_resolution, f)\n```'}, {'reason': 'stop', 'result': '```python\nfor i in range(len(data)):\n    N = 0.0\n    for x in range(len(data.iloc[i]))[4:last]:\n        if data.iloc[i][x] > 0:\n            N += data.iloc[i][x]\n    array = data.iloc[i][4:last]\n    species_diversity_index = 0.0\n    for y in array:\n        species_diversity_index += y * (y - 1)\n    lam = species_diversity_index / (N * (N - 1))\n    data.loc[i, "lam\'"] = lam\n```'}, {'reason': 'stop', 'result': '```python\ndef blockMotionVaryingMasses(t, blockPositions, vBlock, i, blockNum, kp, kc, mass, F0, v0, vf):\n    """\n    Returns the differential equation that models the motion of the blocks\n    \n    Arguments:  t - time\n                blockPositions - the positions of the blocks\n                vBlock - the velocity of the block\n                i - the index of the current block\n                blockNum - the number of blocks\n                kp - spring constant of leaf springs\n                kc - spring constant of springs between blocks\n                mass - masses of individual blocks\n                F0 - the static friction force\n                v0 - initial velocity of top plate\n                vf - the friction coefficient\n                \n    Returned: The differential equation modeling the motion of the individual blocks\n    \n    Examples:\n    \n    >>> blockMotion (0, (0, 1, 2, 3, 4), 0, 2, 5, 0, 0, 1, 0, 1, 20)\n    array([ 0.,  0.])\n    \n    """\n    xi = blockPositions[i] - i\n    vi = vBlock\n    mi = mass[i]\n    if i == 0:\n        xiP = blockPositions[i + 1] - (i + 1)\n        springForce = kc * (xiP - xi) + kp * (v0 * t - xi)\n    elif i == blockNum - 1:\n        xiM = blockPositions[i - 1] - (i - 1)\n        springForce = kc * (xiM - xi) + kp * (v0 * t - xi)\n    else:\n        xiM = blockPositions[i - 1] - (i - 1)\n        xiP = blockPositions[i + 1] - (i + 1)\n        springForce = kc * (xiP + xiM - 2 * xi) + kp * (v0 * t - xi)\n    friction_force = friction(vi, vf, F0)\n    if abs(springForce) <= abs(friction_force):\n        dv = -vi\n        vi = 0\n        dx = vi\n    else:\n        totalForce = (springForce + friction_force) / mi\n        dx = vi\n        dv = totalForce\n    return np.array([dx, dv], float)\n```'}, {'reason': 'stop', 'result': '```python\nk_size = 3\nvertex_ratio_h = 0.45\nvertex_ratio_v = 0.6\nlow_thresh = 50\nhigh_thresh = 200\nL2gradient = False\nrho = 2\ntheta = 1 * np.pi / 180.0\nmin_votes = 15\nmin_line_len = 40\nmax_line_gap = 20\nmax_angle = 3 * np.pi / 16\nangle_threshold = np.pi / 16\n\ndef process_image(image):\n    result = lane_detection_ppline(image, k_size=k_size, low_thresh=low_thresh, high_thresh=high_thresh, L2gradient=L2gradient, rho=rho, theta=theta, min_votes=min_votes, min_line_len=min_line_len, max_line_gap=max_line_gap, angle=max_angle, angle_thresh=angle_threshold, debug=False)\n    return result\n```'}]