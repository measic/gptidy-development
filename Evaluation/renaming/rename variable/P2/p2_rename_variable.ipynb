{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nShot prompt\\n4-shot prompt\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Shot prompt\n",
    "4-shot prompt\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables\n",
    "NUM_FILES = 361\n",
    "FOLDER_NAME = '../../determining_files_rename/random_samples_variables'\n",
    "GPT_SAVED_FILE_NAME = 'rename_variable_gpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in files from folder random_cells \n",
    "random_cells = []\n",
    "\n",
    "# read in cells\n",
    "for i in range(NUM_FILES):\n",
    "    file_name = f'{FOLDER_NAME}/{i}.py'\n",
    "    with open(file_name, 'r') as f:\n",
    "        random_cells.append(f.read())\n",
    "\n",
    "# read in readmes\n",
    "with open(f'{FOLDER_NAME}/readmes.txt', 'r') as f:\n",
    "    readmes = eval(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"Rename the variable specified in the code delimited by triple backticks to a more meaningful name that reflects its usage and/or aligns with the project's purpose. Do not add, remove, or change anything else. Structure your response under the following headings: 'New variable name' (only one new variable name), 'Updated code' (the full code cell with the variable renamed), and 'Explanation' (a 1-2 sentence explanation of the new variable name).\"\n",
    "\n",
    "ex1_input = \"\"\"Project purpose:\n",
    "This project is about analyzing top movie genre trends from 2000 to 2010. We will look at the top genres and top movies for each year.\n",
    "\n",
    "Variable to rename:\n",
    "'dat'\n",
    "\n",
    "Code:\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "dat = pd.read_csv('data.csv')\n",
    "dat.head()\n",
    "```\"\"\"\n",
    "\n",
    "ex1_output = \"\"\"New variable name:\n",
    "'movie_data_df'\n",
    "\n",
    "Updated code:\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "movie_data_df = pd.read_csv('data.csv')\n",
    "movie_data_df.head()\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "The new variable name 'movie_data_df' reflects its usage as a dataframe containing movie data.\"\"\"\n",
    "\n",
    "ex2_input = \"\"\"Project purpose:\n",
    "The focus of this project is determining the most common crime types in LA.\n",
    "\n",
    "Variable to rename:\n",
    "'group'\n",
    "\n",
    "Code:\n",
    "```python\n",
    "group = df.groupby('gender')\n",
    "\n",
    "for gender, grouped_data in group:\n",
    "    print(f\"Gender: {gender}\")\n",
    "    print(grouped_data['crime_type'].value_counts())\n",
    "    print(\"\\n\")\n",
    "```\"\"\"\n",
    "\n",
    "ex2_output = \"\"\"New variable name:\n",
    "'gender_crime_groups'\n",
    "\n",
    "Updated code:\n",
    "```python\n",
    "gender_crime_groups = df.groupby('gender')\n",
    "\n",
    "for gender, grouped_data in gender_crime_groups:\n",
    "    print(f\"Gender: {gender}\")\n",
    "    print(grouped_data['crime_type'].value_counts())\n",
    "    print(\"\\n\")\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "The new variable name 'gender_crime_groups' aligns with its purpose of grouping crime data by gender.\"\"\"\n",
    "\n",
    "ex3_input = \"\"\"Project purpose:\n",
    "This repository contains a collection of graph theory assignments for MAT381.\n",
    "\n",
    "Variable to rename:\n",
    "'queue'\n",
    "\n",
    "Code:\n",
    "```python\n",
    "queue[0] = queue[0].lower()\n",
    "while queue:\n",
    "    vertex = queue.popleft()\n",
    "    print(vertex, end=' ')\n",
    "\n",
    "    for neighbor in graph[vertex]:\n",
    "        if neighbor not in visited:\n",
    "            queue.append(neighbor)\n",
    "            visited.add(neighbor)\n",
    "```\"\"\"\n",
    "\n",
    "ex3_output = \"\"\"New variable name:\n",
    "'vertex_queue'\n",
    "\n",
    "Updated code:\n",
    "```python\n",
    "vertex_queue[0] = vertex_queue[0].lower()\n",
    "while vertex_queue:\n",
    "    vertex = vertex_queue.popleft()\n",
    "    print(vertex, end=' ')\n",
    "\n",
    "    for neighbor in graph[vertex]:\n",
    "        if neighbor not in visited:\n",
    "            vertex_queue.append(neighbor)\n",
    "            visited.add(neighbor)\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "By renaming 'queue' to 'vertex_queue', it's now clearer that the variable is being used to store vertices.\"\"\"\n",
    "\n",
    "ex4_input = \"\"\"Project purpose:\n",
    "This project is for analyzing the relationship between the number of hours studied and the exam scores of students.\n",
    "\n",
    "Variable to rename:\n",
    "'result'\n",
    "\n",
    "Code:\n",
    "```python\n",
    "result, info = pearsonr(queue['Hours'], queue['Scores'])\n",
    "print(result)\n",
    "```\"\"\"\n",
    "\n",
    "ex4_output = \"\"\"New variable name:\n",
    "'hours_scores_correlation'\n",
    "\n",
    "Updated code:\n",
    "```python\n",
    "hours_scores_correlation, info = pearsonr(queue['Hours'], queue['Scores'])\n",
    "print(hours_scores_correlation)\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "The variable name 'hours_scores_correlation' reflects the purpose of the variable, which is to store the correlation between the number of hours studied and the exam scores of students.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7451805"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimate cost\n",
    "import sys\n",
    "sys.path.append(\"../../..\")\n",
    "import utils\n",
    "\n",
    "def estimate_tokens():\n",
    "    in_tok = ''\n",
    "    out_tok = ''\n",
    "    for i, cell_src in enumerate(random_cells):\n",
    "        # estimate prompt\n",
    "        in_tok += task + ex1_input + ex1_output + ex2_input + ex2_output + ex3_input + ex3_output + ex4_input + ex4_output\n",
    "        in_tok += f\"Project purpose:\\n{readmes[i]}\\n\\nVariable to rename:\\n'variable_def'\\n\\nCode:\\n```python\\n{cell_src}\\n```\"\n",
    "        # estimate response\n",
    "        out_tok += cell_src\n",
    "    return in_tok, out_tok\n",
    "\n",
    "in_tok, out_tok = estimate_tokens()\n",
    "\n",
    "utils.gpt_35_turbo_token_dollar_cost(in_tok, out_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rename using GPT\n",
    "# import openai\n",
    "# openai.api_key = my_key\n",
    "\n",
    "# # GPT\n",
    "# def rename(purpose, cell_src, name):\n",
    "#     while True:\n",
    "#         try:\n",
    "#             completion = openai.ChatCompletion.create(\n",
    "#                 model=\"gpt-3.5-turbo\",\n",
    "#                 temperature=0,\n",
    "#                 messages = [\n",
    "#                     {\"role\" : \"user\", \"content\" : task},\n",
    "#                     {\"role\" : \"user\", \"content\" : ex1_input},\n",
    "#                     {\"role\" : \"assistant\", \"content\" : ex1_output},\n",
    "#                     {\"role\" : \"user\", \"content\" : ex2_input},\n",
    "#                     {\"role\" : \"assistant\", \"content\" : ex2_output},\n",
    "#                     {\"role\" : \"user\", \"content\" : ex3_input},\n",
    "#                     {\"role\" : \"assistant\", \"content\" : ex3_output},\n",
    "#                     {\"role\" : \"user\", \"content\" : ex4_input},\n",
    "#                     {\"role\" : \"assistant\", \"content\" : ex4_output},\n",
    "#                     {\"role\" : \"user\", \"content\" : f\"Project purpose:\\n{purpose}\\n\\nVariable to rename:\\n'{name}'\\n\\nCode:\\n```python\\n{cell_src}\\n```\"}\n",
    "#                 ]\n",
    "#             )\n",
    "#         except Exception as e:\n",
    "#             if 'maximum context length' in str(e):\n",
    "#                 print('...Error.. too long...' + str(e))\n",
    "#                 return 'length', None\n",
    "#             else:\n",
    "#                 print('...Error.. trying again...' + str(e))\n",
    "#         else:\n",
    "#             break\n",
    "#     return completion.choices[0].finish_reason, completion.choices[0].message[\"content\"]\n",
    "\n",
    "# gpt_results = []\n",
    "# for i, cell_src in enumerate(random_cells):\n",
    "#     print(f'Processing file {i}')\n",
    "#     finish_reason, result = rename(readmes[i], cell_src, 'variable_def')\n",
    "#     print(f'File {i} - {finish_reason}')\n",
    "#     gpt_results.append({'reason': finish_reason, 'result': result})\n",
    "\n",
    "# # save the results to a file\n",
    "# with open(GPT_SAVED_FILE_NAME, 'w') as f:\n",
    "#     f.write(str(gpt_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in gpt result from file\n",
    "with open(GPT_SAVED_FILE_NAME, 'r') as f:\n",
    "    gpt_results = eval(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now split the data into files\n",
    "gpt_new_names = []\n",
    "gpt_new_code = []\n",
    "gpt_explanation = []\n",
    "\n",
    "for i, result in enumerate(gpt_results):\n",
    "    if result['reason'] == 'stop':\n",
    "        # split the result\n",
    "        first_split = result['result'].split('New variable name:')[1].split('Updated code:')\n",
    "        updated_name = first_split[0].strip()\n",
    "        second_split = first_split[1].split('Explanation:')\n",
    "        updated_code = second_split[0].strip()\n",
    "        explanation = second_split[1].strip()\n",
    "\n",
    "        # update name\n",
    "        if len(updated_name.split('\\'')) == 3:\n",
    "            updated_name = updated_name.split('\\'')[1]\n",
    "\n",
    "        # update name\n",
    "        if len(updated_name.split('`')) == 3:\n",
    "            updated_name = updated_name.split('`')[1]\n",
    "\n",
    "        # get the updated code\n",
    "        updated_code = updated_code.split('```')[1]\n",
    "        if updated_code.startswith('python'):\n",
    "            updated_code = updated_code[6:]\n",
    "        updated_code = updated_code.strip('\\n')\n",
    "        \n",
    "        # store\n",
    "        gpt_new_names.append(updated_name)\n",
    "        gpt_new_code.append(updated_code)\n",
    "        gpt_explanation.append(explanation)\n",
    "    else:\n",
    "        # if we error we assume nothing\n",
    "        gpt_new_names.append(None)\n",
    "        gpt_new_code.append(None)\n",
    "        gpt_explanation.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write gpt new names to a file\n",
    "with open('gpt_new_names.txt', 'w') as f:\n",
    "    for name in gpt_new_names:\n",
    "        f.write(f'{name}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 0\n",
      "0 pass\n",
      "Processing file 1\n",
      "1 pass\n",
      "Processing file 2\n",
      "2 pass\n",
      "Processing file 3\n",
      "3 pass\n",
      "Processing file 4\n",
      "4 pass\n",
      "Processing file 5\n",
      "5 pass\n",
      "Processing file 6\n",
      "6 pass\n",
      "Processing file 7\n",
      "7 pass\n",
      "Processing file 8\n",
      "8 pass\n",
      "Processing file 9\n",
      "9 pass\n",
      "Processing file 10\n",
      "10 pass\n",
      "Processing file 11\n",
      "11 pass\n",
      "Processing file 12\n",
      "12 pass\n",
      "Processing file 13\n",
      "13 pass\n",
      "Processing file 14\n",
      "14 pass\n",
      "Processing file 15\n",
      "15 pass\n",
      "Processing file 16\n",
      "16 pass\n",
      "Processing file 17\n",
      "17 pass\n",
      "Processing file 18\n",
      "18 pass\n",
      "Processing file 19\n",
      "19 pass\n",
      "Processing file 20\n",
      "20 pass\n",
      "Processing file 21\n",
      "21 pass\n",
      "Processing file 22\n",
      "22 pass\n",
      "Processing file 23\n",
      "23 pass\n",
      "Processing file 24\n",
      "24 pass\n",
      "Processing file 25\n",
      "25 pass\n",
      "Processing file 26\n",
      "26 pass\n",
      "Processing file 27\n",
      "27 pass\n",
      "Processing file 28\n",
      "28 pass\n",
      "Processing file 29\n",
      "29 pass\n",
      "Processing file 30\n",
      "30 pass\n",
      "Processing file 31\n",
      "31 pass\n",
      "Processing file 32\n",
      "32 pass\n",
      "Processing file 33\n",
      "33 pass\n",
      "Processing file 34\n",
      "34 second fail\n",
      "Processing file 35\n",
      "35 pass\n",
      "Processing file 36\n",
      "36 pass\n",
      "Processing file 37\n",
      "37 pass\n",
      "Processing file 38\n",
      "38 pass\n",
      "Processing file 39\n",
      "39 pass\n",
      "Processing file 40\n",
      "40 pass\n",
      "Processing file 41\n",
      "41 pass\n",
      "Processing file 42\n",
      "42 pass\n",
      "Processing file 43\n",
      "43 pass\n",
      "Processing file 44\n",
      "44 pass\n",
      "Processing file 45\n",
      "45 pass\n",
      "Processing file 46\n",
      "46 second fail\n",
      "Processing file 47\n",
      "47 pass\n",
      "Processing file 48\n",
      "48 pass\n",
      "Processing file 49\n",
      "49 pass\n",
      "Processing file 50\n",
      "50 pass\n",
      "Processing file 51\n",
      "51 pass\n",
      "Processing file 52\n",
      "52 pass\n",
      "Processing file 53\n",
      "53 pass\n",
      "Processing file 54\n",
      "54 pass\n",
      "Processing file 55\n",
      "55 pass\n",
      "Processing file 56\n",
      "56 pass\n",
      "Processing file 57\n",
      "57 pass\n",
      "Processing file 58\n",
      "58 pass\n",
      "Processing file 59\n",
      "59 pass\n",
      "Processing file 60\n",
      "60 pass\n",
      "Processing file 61\n",
      "61 pass\n",
      "Processing file 62\n",
      "62 pass\n",
      "Processing file 63\n",
      "63 pass\n",
      "Processing file 64\n",
      "64 pass\n",
      "Processing file 65\n",
      "65 pass\n",
      "Processing file 66\n",
      "66 pass\n",
      "Processing file 67\n",
      "67 pass\n",
      "Processing file 68\n",
      "68 pass\n",
      "Processing file 69\n",
      "69 pass\n",
      "Processing file 70\n",
      "70 second fail\n",
      "Processing file 71\n",
      "71 pass\n",
      "Processing file 72\n",
      "72 pass\n",
      "Processing file 73\n",
      "73 pass\n",
      "Processing file 74\n",
      "74 pass\n",
      "Processing file 75\n",
      "75 pass\n",
      "Processing file 76\n",
      "76 pass\n",
      "Processing file 77\n",
      "77 pass\n",
      "Processing file 78\n",
      "78 pass\n",
      "Processing file 79\n",
      "79 pass\n",
      "Processing file 80\n",
      "80 pass\n",
      "Processing file 81\n",
      "81 pass\n",
      "Processing file 82\n",
      "82 pass\n",
      "Processing file 83\n",
      "83 pass\n",
      "Processing file 84\n",
      "84 pass\n",
      "Processing file 85\n",
      "85 pass\n",
      "Processing file 86\n",
      "86 pass\n",
      "Processing file 87\n",
      "87 pass\n",
      "Processing file 88\n",
      "88 pass\n",
      "Processing file 89\n",
      "89 pass\n",
      "Processing file 90\n",
      "90 pass\n",
      "Processing file 91\n",
      "91 pass\n",
      "Processing file 92\n",
      "92 pass\n",
      "Processing file 93\n",
      "93 pass\n",
      "Processing file 94\n",
      "94 pass\n",
      "Processing file 95\n",
      "95 pass\n",
      "Processing file 96\n",
      "96 pass\n",
      "Processing file 97\n",
      "97 pass\n",
      "Processing file 98\n",
      "98 pass\n",
      "Processing file 99\n",
      "99 pass\n",
      "Processing file 100\n",
      "100 second fail\n",
      "Processing file 101\n",
      "101 pass\n",
      "Processing file 102\n",
      "102 second fail\n",
      "Processing file 103\n",
      "103 pass\n",
      "Processing file 104\n",
      "104 pass\n",
      "Processing file 105\n",
      "105 pass\n",
      "Processing file 106\n",
      "106 pass\n",
      "Processing file 107\n",
      "107 pass\n",
      "Processing file 108\n",
      "108 pass\n",
      "Processing file 109\n",
      "109 pass\n",
      "Processing file 110\n",
      "110 pass\n",
      "Processing file 111\n",
      "111 pass\n",
      "Processing file 112\n",
      "112 pass\n",
      "Processing file 113\n",
      "113 pass\n",
      "Processing file 114\n",
      "114 pass\n",
      "Processing file 115\n",
      "115 pass\n",
      "Processing file 116\n",
      "116 pass\n",
      "Processing file 117\n",
      "117 pass\n",
      "Processing file 118\n",
      "118 pass\n",
      "Processing file 119\n",
      "119 pass\n",
      "Processing file 120\n",
      "120 pass\n",
      "Processing file 121\n",
      "121 pass\n",
      "Processing file 122\n",
      "122 pass\n",
      "Processing file 123\n",
      "123 pass\n",
      "Processing file 124\n",
      "124 pass\n",
      "Processing file 125\n",
      "125 pass\n",
      "Processing file 126\n",
      "126 pass\n",
      "Processing file 127\n",
      "127 pass\n",
      "Processing file 128\n",
      "128 pass\n",
      "Processing file 129\n",
      "129 pass\n",
      "Processing file 130\n",
      "130 pass\n",
      "Processing file 131\n",
      "131 pass\n",
      "Processing file 132\n",
      "132 pass\n",
      "Processing file 133\n",
      "133 pass\n",
      "Processing file 134\n",
      "134 pass\n",
      "Processing file 135\n",
      "135 pass\n",
      "Processing file 136\n",
      "136 pass\n",
      "Processing file 137\n",
      "137 pass\n",
      "Processing file 138\n",
      "138 second fail\n",
      "Processing file 139\n",
      "139 pass\n",
      "Processing file 140\n",
      "140 second fail\n",
      "Processing file 141\n",
      "141 pass\n",
      "Processing file 142\n",
      "142 pass\n",
      "Processing file 143\n",
      "143 pass\n",
      "Processing file 144\n",
      "144 pass\n",
      "Processing file 145\n",
      "145 pass\n",
      "Processing file 146\n",
      "146 pass\n",
      "Processing file 147\n",
      "147 pass\n",
      "Processing file 148\n",
      "148 pass\n",
      "Processing file 149\n",
      "149 pass\n",
      "Processing file 150\n",
      "150 pass\n",
      "Processing file 151\n",
      "151 pass\n",
      "Processing file 152\n",
      "152 pass\n",
      "Processing file 153\n",
      "153 pass\n",
      "Processing file 154\n",
      "154 pass\n",
      "Processing file 155\n",
      "155 pass\n",
      "Processing file 156\n",
      "156 pass\n",
      "Processing file 157\n",
      "157 pass\n",
      "Processing file 158\n",
      "158 pass\n",
      "Processing file 159\n",
      "159 pass\n",
      "Processing file 160\n",
      "160 pass\n",
      "Processing file 161\n",
      "161 pass\n",
      "Processing file 162\n",
      "162 pass\n",
      "Processing file 163\n",
      "163 pass\n",
      "Processing file 164\n",
      "164 pass\n",
      "Processing file 165\n",
      "165 pass\n",
      "Processing file 166\n",
      "166 pass\n",
      "Processing file 167\n",
      "167 pass\n",
      "Processing file 168\n",
      "168 pass\n",
      "Processing file 169\n",
      "169 pass\n",
      "Processing file 170\n",
      "170 pass\n",
      "Processing file 171\n",
      "171 pass\n",
      "Processing file 172\n",
      "172 pass\n",
      "Processing file 173\n",
      "173 pass\n",
      "Processing file 174\n",
      "174 pass\n",
      "Processing file 175\n",
      "175 pass\n",
      "Processing file 176\n",
      "176 pass\n",
      "Processing file 177\n",
      "177 second fail\n",
      "Processing file 178\n",
      "178 pass\n",
      "Processing file 179\n",
      "179 pass\n",
      "Processing file 180\n",
      "180 pass\n",
      "Processing file 181\n",
      "181 pass\n",
      "Processing file 182\n",
      "182 pass\n",
      "Processing file 183\n",
      "183 pass\n",
      "Processing file 184\n",
      "184 pass\n",
      "Processing file 185\n",
      "185 second fail\n",
      "Processing file 186\n",
      "186 pass\n",
      "Processing file 187\n",
      "187 pass\n",
      "Processing file 188\n",
      "188 pass\n",
      "Processing file 189\n",
      "189 pass\n",
      "Processing file 190\n",
      "190 second fail\n",
      "Processing file 191\n",
      "191 pass\n",
      "Processing file 192\n",
      "192 pass\n",
      "Processing file 193\n",
      "193 pass\n",
      "Processing file 194\n",
      "194 pass\n",
      "Processing file 195\n",
      "195 pass\n",
      "Processing file 196\n",
      "196 pass\n",
      "Processing file 197\n",
      "197 pass\n",
      "Processing file 198\n",
      "198 pass\n",
      "Processing file 199\n",
      "199 second fail\n",
      "Processing file 200\n",
      "200 pass\n",
      "Processing file 201\n",
      "201 second fail\n",
      "Processing file 202\n",
      "202 pass\n",
      "Processing file 203\n",
      "203 pass\n",
      "Processing file 204\n",
      "204 pass\n",
      "Processing file 205\n",
      "205 pass\n",
      "Processing file 206\n",
      "206 pass\n",
      "Processing file 207\n",
      "207 pass\n",
      "Processing file 208\n",
      "208 second fail\n",
      "Processing file 209\n",
      "209 pass\n",
      "Processing file 210\n",
      "210 pass\n",
      "Processing file 211\n",
      "211 pass\n",
      "Processing file 212\n",
      "212 pass\n",
      "Processing file 213\n",
      "213 pass\n",
      "Processing file 214\n",
      "214 pass\n",
      "Processing file 215\n",
      "215 pass\n",
      "Processing file 216\n",
      "216 second fail\n",
      "Processing file 217\n",
      "217 second fail\n",
      "Processing file 218\n",
      "218 pass\n",
      "Processing file 219\n",
      "219 pass\n",
      "Processing file 220\n",
      "220 pass\n",
      "Processing file 221\n",
      "221 pass\n",
      "Processing file 222\n",
      "222 pass\n",
      "Processing file 223\n",
      "223 pass\n",
      "Processing file 224\n",
      "224 pass\n",
      "Processing file 225\n",
      "225 pass\n",
      "Processing file 226\n",
      "226 pass\n",
      "Processing file 227\n",
      "227 pass\n",
      "Processing file 228\n",
      "228 pass\n",
      "Processing file 229\n",
      "229 pass\n",
      "Processing file 230\n",
      "230 pass\n",
      "Processing file 231\n",
      "231 pass\n",
      "Processing file 232\n",
      "232 pass\n",
      "Processing file 233\n",
      "233 pass\n",
      "Processing file 234\n",
      "234 pass\n",
      "Processing file 235\n",
      "235 first fail\n",
      "Processing file 236\n",
      "236 second fail\n",
      "Processing file 237\n",
      "237 pass\n",
      "Processing file 238\n",
      "238 second fail\n",
      "Processing file 239\n",
      "239 pass\n",
      "Processing file 240\n",
      "240 pass\n",
      "Processing file 241\n",
      "241 pass\n",
      "Processing file 242\n",
      "242 pass\n",
      "Processing file 243\n",
      "243 pass\n",
      "Processing file 244\n",
      "244 pass\n",
      "Processing file 245\n",
      "245 pass\n",
      "Processing file 246\n",
      "246 pass\n",
      "Processing file 247\n",
      "247 pass\n",
      "Processing file 248\n",
      "248 pass\n",
      "Processing file 249\n",
      "249 pass\n",
      "Processing file 250\n",
      "250 pass\n",
      "Processing file 251\n",
      "251 pass\n",
      "Processing file 252\n",
      "252 pass\n",
      "Processing file 253\n",
      "253 pass\n",
      "Processing file 254\n",
      "254 pass\n",
      "Processing file 255\n",
      "255 pass\n",
      "Processing file 256\n",
      "256 pass\n",
      "Processing file 257\n",
      "257 pass\n",
      "Processing file 258\n",
      "258 pass\n",
      "Processing file 259\n",
      "259 pass\n",
      "Processing file 260\n",
      "260 pass\n",
      "Processing file 261\n",
      "261 pass\n",
      "Processing file 262\n",
      "262 second fail\n",
      "Processing file 263\n",
      "263 pass\n",
      "Processing file 264\n",
      "264 pass\n",
      "Processing file 265\n",
      "265 pass\n",
      "Processing file 266\n",
      "266 second fail\n",
      "Processing file 267\n",
      "267 pass\n",
      "Processing file 268\n",
      "268 pass\n",
      "Processing file 269\n",
      "269 pass\n",
      "Processing file 270\n",
      "270 pass\n",
      "Processing file 271\n",
      "271 pass\n",
      "Processing file 272\n",
      "272 pass\n",
      "Processing file 273\n",
      "273 pass\n",
      "Processing file 274\n",
      "274 pass\n",
      "Processing file 275\n",
      "275 pass\n",
      "Processing file 276\n",
      "276 second fail\n",
      "Processing file 277\n",
      "277 pass\n",
      "Processing file 278\n",
      "278 pass\n",
      "Processing file 279\n",
      "279 pass\n",
      "Processing file 280\n",
      "280 pass\n",
      "Processing file 281\n",
      "281 pass\n",
      "Processing file 282\n",
      "282 pass\n",
      "Processing file 283\n",
      "283 pass\n",
      "Processing file 284\n",
      "284 second fail\n",
      "Processing file 285\n",
      "285 pass\n",
      "Processing file 286\n",
      "286 pass\n",
      "Processing file 287\n",
      "287 pass\n",
      "Processing file 288\n",
      "288 pass\n",
      "Processing file 289\n",
      "289 second fail\n",
      "Processing file 290\n",
      "290 pass\n",
      "Processing file 291\n",
      "291 pass\n",
      "Processing file 292\n",
      "292 pass\n",
      "Processing file 293\n",
      "293 pass\n",
      "Processing file 294\n",
      "294 pass\n",
      "Processing file 295\n",
      "295 pass\n",
      "Processing file 296\n",
      "296 pass\n",
      "Processing file 297\n",
      "297 pass\n",
      "Processing file 298\n",
      "298 pass\n",
      "Processing file 299\n",
      "299 pass\n",
      "Processing file 300\n",
      "300 pass\n",
      "Processing file 301\n",
      "301 pass\n",
      "Processing file 302\n",
      "302 pass\n",
      "Processing file 303\n",
      "303 pass\n",
      "Processing file 304\n",
      "304 pass\n",
      "Processing file 305\n",
      "305 pass\n",
      "Processing file 306\n",
      "306 pass\n",
      "Processing file 307\n",
      "307 second fail\n",
      "Processing file 308\n",
      "308 pass\n",
      "Processing file 309\n",
      "309 second fail\n",
      "Processing file 310\n",
      "310 pass\n",
      "Processing file 311\n",
      "311 pass\n",
      "Processing file 312\n",
      "312 pass\n",
      "Processing file 313\n",
      "313 pass\n",
      "Processing file 314\n",
      "314 pass\n",
      "Processing file 315\n",
      "315 pass\n",
      "Processing file 316\n",
      "316 pass\n",
      "Processing file 317\n",
      "317 pass\n",
      "Processing file 318\n",
      "318 pass\n",
      "Processing file 319\n",
      "319 pass\n",
      "Processing file 320\n",
      "320 pass\n",
      "Processing file 321\n",
      "321 pass\n",
      "Processing file 322\n",
      "322 pass\n",
      "Processing file 323\n",
      "323 pass\n",
      "Processing file 324\n",
      "324 pass\n",
      "Processing file 325\n",
      "325 pass\n",
      "Processing file 326\n",
      "326 pass\n",
      "Processing file 327\n",
      "327 pass\n",
      "Processing file 328\n",
      "328 pass\n",
      "Processing file 329\n",
      "329 pass\n",
      "Processing file 330\n",
      "330 pass\n",
      "Processing file 331\n",
      "331 pass\n",
      "Processing file 332\n",
      "332 pass\n",
      "Processing file 333\n",
      "333 pass\n",
      "Processing file 334\n",
      "334 pass\n",
      "Processing file 335\n",
      "335 pass\n",
      "Processing file 336\n",
      "336 pass\n",
      "Processing file 337\n",
      "337 pass\n",
      "Processing file 338\n",
      "338 pass\n",
      "Processing file 339\n",
      "339 pass\n",
      "Processing file 340\n",
      "340 pass\n",
      "Processing file 341\n",
      "341 pass\n",
      "Processing file 342\n",
      "342 pass\n",
      "Processing file 343\n",
      "343 pass\n",
      "Processing file 344\n",
      "344 pass\n",
      "Processing file 345\n",
      "345 pass\n",
      "Processing file 346\n",
      "346 pass\n",
      "Processing file 347\n",
      "347 pass\n",
      "Processing file 348\n",
      "348 pass\n",
      "Processing file 349\n",
      "349 second fail\n",
      "Processing file 350\n",
      "350 pass\n",
      "Processing file 351\n",
      "351 pass\n",
      "Processing file 352\n",
      "352 pass\n",
      "Processing file 353\n",
      "353 pass\n",
      "Processing file 354\n",
      "354 pass\n",
      "Processing file 355\n",
      "355 pass\n",
      "Processing file 356\n",
      "356 pass\n",
      "Processing file 357\n",
      "357 pass\n",
      "Processing file 358\n",
      "358 pass\n",
      "Processing file 359\n",
      "359 pass\n",
      "Processing file 360\n",
      "360 pass\n",
      "Pass count: 335, 92.797783933518%\n",
      "Fail count: 26, 7.202216066481995%\n",
      "Average length of failed files: 1645.8461538461538\n",
      "Average length of passed files: 850.7432835820896\n"
     ]
    }
   ],
   "source": [
    "# Count the number of times the variable name is/isn't successfully changed\n",
    "import sys\n",
    "sys.path.append('../../determining_files_rename')\n",
    "from ast_determine_usable_items import compare_code\n",
    "\n",
    "pass_count = 0\n",
    "fail_count = 0\n",
    "\n",
    "failed_ids = []\n",
    "length_failed = 0\n",
    "length_passed = 0\n",
    "\n",
    "for i in range(NUM_FILES):\n",
    "    print(\"Processing file\", i)\n",
    "    if gpt_new_names[i] is None or gpt_new_code[i] is None or gpt_explanation[i] is None:\n",
    "        fail_count += 1\n",
    "        failed_ids.append(i)\n",
    "        length_failed += len(random_cells[i])\n",
    "        print(i, \"first fail\")\n",
    "    elif compare_code(random_cells[i], gpt_new_code[i], 'variable_def', gpt_new_names[i]):\n",
    "        pass_count += 1\n",
    "        print(i, \"pass\")\n",
    "        length_passed += len(random_cells[i])\n",
    "    else:\n",
    "        fail_count += 1\n",
    "        print(i, \"second fail\")\n",
    "        length_failed += len(random_cells[i])\n",
    "        failed_ids.append(i)\n",
    "\n",
    "print(f'Pass count: {pass_count}, {pass_count / (pass_count + fail_count) * 100}%')\n",
    "print(f'Fail count: {fail_count}, {fail_count / (pass_count + fail_count) * 100}%')\n",
    "\n",
    "print(f'Average length of failed files: {length_failed / fail_count}')\n",
    "print(f'Average length of passed files: {length_passed / pass_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[34,\n",
       " 46,\n",
       " 70,\n",
       " 100,\n",
       " 102,\n",
       " 138,\n",
       " 140,\n",
       " 177,\n",
       " 185,\n",
       " 190,\n",
       " 199,\n",
       " 201,\n",
       " 208,\n",
       " 216,\n",
       " 217,\n",
       " 235,\n",
       " 236,\n",
       " 238,\n",
       " 262,\n",
       " 266,\n",
       " 276,\n",
       " 284,\n",
       " 289,\n",
       " 307,\n",
       " 309,\n",
       " 349]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'final_layer_output'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_new_names[46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from tensorflow.contrib.layers import flatten\n",
      "\n",
      "def LeNet(x):\n",
      "    mu = 0\n",
      "    sigma = 0.1\n",
      "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 3, 6), mean=mu, stddev=sigma))\n",
      "    conv1_b = tf.Variable(tf.zeros(6))\n",
      "    conv1 = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
      "    conv1 = tf.nn.relu(conv1)\n",
      "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
      "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean=mu, stddev=sigma))\n",
      "    conv2_b = tf.Variable(tf.zeros(16))\n",
      "    conv2 = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
      "    conv2 = tf.nn.relu(conv2)\n",
      "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
      "    fc0 = flatten(conv2)\n",
      "    fc1_W = tf.Variable(tf.truncated_normal(shape=(400, 120), mean=mu, stddev=sigma))\n",
      "    fc1_b = tf.Variable(tf.zeros(120))\n",
      "    fc1 = tf.matmul(fc0, fc1_W) + fc1_b\n",
      "    fc1 = tf.nn.relu(fc1)\n",
      "    fc2_W = tf.Variable(tf.truncated_normal(shape=(120, 84), mean=mu, stddev=sigma))\n",
      "    fc2_b = tf.Variable(tf.zeros(84))\n",
      "    fc2 = tf.matmul(fc1, fc2_W) + fc2_b\n",
      "    fc2 = tf.nn.relu(fc2)\n",
      "    fc3_W = tf.Variable(tf.truncated_normal(shape=(84, 43), mean=mu, stddev=sigma))\n",
      "    fc3_b = tf.Variable(tf.zeros(43))\n",
      "    logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
      "    return logits\n",
      "\n",
      "def model_arc(x):\n",
      "    mu = 0\n",
      "    sigma = 0.1\n",
      "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 3, 9), mean=mu, stddev=sigma))\n",
      "    conv1_b = tf.Variable(tf.zeros(9))\n",
      "    conv1 = tf.nn.bias_add(tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID'), conv1_b)\n",
      "    conv1 = tf.nn.relu(conv1)\n",
      "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
      "    conv2_W = tf.Variable(tf.truncated_normal(shape=(3, 3, 9, 27), mean=mu, stddev=sigma))\n",
      "    conv2_b = tf.Variable(tf.zeros(27))\n",
      "    conv2 = tf.nn.bias_add(tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID'), conv2_b)\n",
      "    conv2 = tf.nn.relu(conv2)\n",
      "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
      "    conv3_W = tf.Variable(tf.truncated_normal(shape=(1, 1, 27, 81), mean=mu, stddev=sigma))\n",
      "    conv3_b = tf.Variable(tf.zeros(81))\n",
      "    conv3 = tf.nn.bias_add(tf.nn.conv2d(conv2, conv3_W, strides=[1, 1, 1, 1], padding='VALID'), conv3_b)\n",
      "    conv3 = tf.nn.relu(conv3)\n",
      "    conv3 = tf.nn.dropout(conv3, keep_prob=0.5)\n",
      "    conv3 = tf.nn.relu(conv3)\n",
      "    fc0 = flatten(conv3)\n",
      "    fc1_W = tf.Variable(tf.truncated_normal(shape=(2916, 972), mean=mu, stddev=sigma))\n",
      "    fc1_b = tf.Variable(tf.zeros(972))\n",
      "    fc1 = tf.nn.xw_plus_b(fc0, fc1_W, fc1_b)\n",
      "    fc1 = tf.nn.relu(fc1)\n",
      "    fc2_W = tf.Variable(tf.truncated_normal(shape=(972, 324), mean=mu, stddev=sigma))\n",
      "    fc2_b = tf.Variable(tf.zeros(324))\n",
      "    fc2 = tf.nn.xw_plus_b(fc1, fc2_W, fc2_b)\n",
      "    fc2 = tf.nn.relu(fc2)\n",
      "    fc3_W = tf.Variable(tf.truncated_normal(shape=(324, 108), mean=mu, stddev=sigma))\n",
      "    fc3_b = tf.Variable(tf.zeros(108))\n",
      "    variable_def = tf.nn.xw_plus_b(fc2, fc3_W, fc3_b)\n",
      "    variable_def = tf.nn.relu(variable_def)\n",
      "    fc4_W = tf.Variable(tf.truncated_normal(shape=(108, 43), mean=mu, stddev=sigma))\n",
      "    fc4_b = tf.Variable(tf.zeros(43))\n",
      "    logits = tf.nn.xw_plus_b(variable_def, fc4_W, fc4_b)\n",
      "    return logits\n"
     ]
    }
   ],
   "source": [
    "print(random_cells[46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def model_arc(x):\n",
      "    mu = 0\n",
      "    sigma = 0.1\n",
      "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 3, 9), mean=mu, stddev=sigma))\n",
      "    conv1_b = tf.Variable(tf.zeros(9))\n",
      "    conv1 = tf.nn.bias_add(tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID'), conv1_b)\n",
      "    conv1 = tf.nn.relu(conv1)\n",
      "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
      "    conv2_W = tf.Variable(tf.truncated_normal(shape=(3, 3, 9, 27), mean=mu, stddev=sigma))\n",
      "    conv2_b = tf.Variable(tf.zeros(27))\n",
      "    conv2 = tf.nn.bias_add(tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID'), conv2_b)\n",
      "    conv2 = tf.nn.relu(conv2)\n",
      "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
      "    conv3_W = tf.Variable(tf.truncated_normal(shape=(1, 1, 27, 81), mean=mu, stddev=sigma))\n",
      "    conv3_b = tf.Variable(tf.zeros(81))\n",
      "    conv3 = tf.nn.bias_add(tf.nn.conv2d(conv2, conv3_W, strides=[1, 1, 1, 1], padding='VALID'), conv3_b)\n",
      "    conv3 = tf.nn.relu(conv3)\n",
      "    conv3 = tf.nn.dropout(conv3, keep_prob=0.5)\n",
      "    conv3 = tf.nn.relu(conv3)\n",
      "    fc0 = flatten(conv3)\n",
      "    fc1_W = tf.Variable(tf.truncated_normal(shape=(2916, 972), mean=mu, stddev=sigma))\n",
      "    fc1_b = tf.Variable(tf.zeros(972))\n",
      "    fc1 = tf.nn.xw_plus_b(fc0, fc1_W, fc1_b)\n",
      "    fc1 = tf.nn.relu(fc1)\n",
      "    fc2_W = tf.Variable(tf.truncated_normal(shape=(972, 324), mean=mu, stddev=sigma))\n",
      "    fc2_b = tf.Variable(tf.zeros(324))\n",
      "    fc2 = tf.nn.xw_plus_b(fc1, fc2_W, fc2_b)\n",
      "    fc2 = tf.nn.relu(fc2)\n",
      "    fc3_W = tf.Variable(tf.truncated_normal(shape=(324, 108), mean=mu, stddev=sigma))\n",
      "    fc3_b = tf.Variable(tf.zeros(108))\n",
      "    final_layer_output = tf.nn.xw_plus_b(fc2, fc3_W, fc3_b)\n",
      "    final_layer_output = tf.nn.relu(final_layer_output)\n",
      "    fc4_W = tf.Variable(tf.truncated_normal(shape=(108, 43), mean=mu, stddev=sigma))\n",
      "    fc4_b = tf.Variable(tf.zeros(43))\n",
      "    logits = tf.nn.xw_plus_b(final_layer_output, fc4_W, fc4_b)\n",
      "    return logits\n"
     ]
    }
   ],
   "source": [
    "print(gpt_new_code[46])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
