{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Shot prompt\n",
    "4-shot prompt\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "from utils import print_check_gpt_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables\n",
    "NUM_FILES = 20\n",
    "FOLDER_NAME = '../../determining_files_rename/random_samples_functions'\n",
    "GPT_SAVED_FILE_NAME = 'rename_function_gpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in files from folder random_cells \n",
    "random_cells = []\n",
    "\n",
    "# read in cells\n",
    "for i in range(NUM_FILES):\n",
    "    file_name = f'{FOLDER_NAME}/{i}.py'\n",
    "    with open(file_name, 'r') as f:\n",
    "        random_cells.append(f.read())\n",
    "\n",
    "# read in readmes\n",
    "with open(f'{FOLDER_NAME}/readmes.txt', 'r') as f:\n",
    "    readmes = eval(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"Rename the function specified in the code delimited by triple backticks to a more meaningful name that reflects its usage and/or aligns with the project's purpose. Do not add, remove, or change anything else. Structure your response under the following headings: 'New function name' (the new function name), 'Updated code' (the code with the function renamed), and 'Explanation' (a 1-2 sentence explanation of the new function name).\"\n",
    "\n",
    "ex1_input = \"\"\"Project purpose:\n",
    "This project is about analyzing top movie genre trends from 2000 to 2010. We will look at the top genres and top movies for each year.\n",
    "\n",
    "Function to rename:\n",
    "dat\n",
    "\n",
    "Code:\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "def dat(file_name):\n",
    "    data = pd.read_csv(file_name)\n",
    "    return data.head()\n",
    "\n",
    "dat('data.csv')\n",
    "```\"\"\"\n",
    "\n",
    "ex1_output = \"\"\"New function name:\n",
    "get_movie_data_df\n",
    "\n",
    "Updated code:\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "def get_movie_data_df(file_name):\n",
    "    data = pd.read_csv(file_name)\n",
    "    return data.head()\n",
    "\n",
    "get_movie_data_df('data.csv')\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "The new function name 'get_movie_data_df' reflects its usage to get a dataframe containing movie data.\"\"\"\n",
    "\n",
    "ex2_input = \"\"\"Project purpose:\n",
    "The focus of this project is determining the most common crime types in LA.\n",
    "\n",
    "Function to rename:\n",
    "group\n",
    "\n",
    "Code:\n",
    "```python\n",
    "groups = df.groupby('gender')\n",
    "\n",
    "def group(groups):\n",
    "    for gender, grouped_data in groups:\n",
    "        print(f\"Gender: {gender}\")\n",
    "        print(grouped_data['crime_type'].value_counts())\n",
    "        print(\"\\n\")\n",
    "```\"\"\"\n",
    "\n",
    "ex2_output = \"\"\"New function name:\n",
    "print_group_crime_by_gender\n",
    "\n",
    "Updated code:\n",
    "```python\n",
    "groups = df.groupby('gender')\n",
    "\n",
    "def print_group_crime_by_gender(groups):\n",
    "    for gender, grouped_data in groups:\n",
    "        print(f\"Gender: {gender}\")\n",
    "        print(grouped_data['crime_type'].value_counts())\n",
    "        print(\"\\n\")\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "The new function name 'print_group_crime_by_gender' aligns with its purpose of printing the crime data grouped by gender.\"\"\"\n",
    "\n",
    "ex3_input = \"\"\"Project purpose:\n",
    "This repository contains a collection of graph theory assignments for MAT381.\n",
    "\n",
    "Function to rename:\n",
    "visit\n",
    "\n",
    "Code:\n",
    "```python\n",
    "def visit(graph, vertex):\n",
    "    for neighbor in graph[vertex]:\n",
    "        if neighbor not in visited:\n",
    "            queue.append(neighbor)\n",
    "            visited.add(neighbor)\n",
    "\n",
    "while queue:\n",
    "    vertex = queue.popleft()\n",
    "    print(vertex, end=' ')\n",
    "    visit(graph, vertex)\n",
    "```\"\"\"\n",
    "\n",
    "ex3_output = \"\"\"New function name:\n",
    "visit_vertex\n",
    "\n",
    "Updated code:\n",
    "```python\n",
    "def visit_vertex(graph, vertex):\n",
    "    for neighbor in graph[vertex]:\n",
    "        if neighbor not in visited:\n",
    "            queue.append(neighbor)\n",
    "            visited.add(neighbor)\n",
    "\n",
    "while queue:\n",
    "    vertex = queue.popleft()\n",
    "    print(vertex, end=' ')\n",
    "    visit_vertex(graph, vertex)\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "By renaming visit to visit_vertex, it is now clearer that the function is being used to visit vertices.\"\"\"\n",
    "\n",
    "ex4_input = \"\"\"Project purpose:\n",
    "This project is for analyzing the relationship between the number of hours studied and the exam scores of students.\n",
    "\n",
    "Function to rename:\n",
    "get\n",
    "\n",
    "Code:\n",
    "```python\n",
    "def get(x, y):\n",
    "    return x.corr(y)\n",
    "\n",
    "result, info = get(queue['Hours'], queue['Scores'])\n",
    "print(result)\n",
    "```\"\"\"\n",
    "\n",
    "ex4_output = \"\"\"New function name:\n",
    "calc_hours_scores_correlation\n",
    "\n",
    "Updated code:\n",
    "```python\n",
    "def calc_hours_scores_correlation(x, y):\n",
    "    return x.corr(y)\n",
    "\n",
    "result, info = calc_hours_scores_correlation(queue['Hours'], queue['Scores'])\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "The function name 'calc_hours_scores_correlation' reflects the purpose of the function, which is to calculate the correlation between the number of hours studied and the exam scores of students.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 0\n",
      "File 0 - stop\n",
      "Processing file 1\n",
      "File 1 - stop\n",
      "Processing file 2\n",
      "File 2 - stop\n",
      "Processing file 3\n",
      "File 3 - stop\n",
      "Processing file 4\n",
      "File 4 - stop\n",
      "Processing file 5\n",
      "File 5 - stop\n",
      "Processing file 6\n",
      "File 6 - stop\n",
      "Processing file 7\n",
      "File 7 - stop\n",
      "Processing file 8\n",
      "File 8 - stop\n",
      "Processing file 9\n",
      "File 9 - stop\n",
      "Processing file 10\n",
      "File 10 - stop\n",
      "Processing file 11\n",
      "File 11 - stop\n",
      "Processing file 12\n",
      "File 12 - stop\n",
      "Processing file 13\n",
      "File 13 - stop\n",
      "Processing file 14\n",
      "File 14 - stop\n",
      "Processing file 15\n",
      "File 15 - stop\n",
      "Processing file 16\n",
      "File 16 - stop\n",
      "Processing file 17\n",
      "File 17 - stop\n",
      "Processing file 18\n",
      "File 18 - stop\n",
      "Processing file 19\n",
      "File 19 - stop\n"
     ]
    }
   ],
   "source": [
    "# rename using GPT\n",
    "import openai\n",
    "openai.api_key = my_key\n",
    "\n",
    "# GPT\n",
    "def rename(purpose, cell_src, name):\n",
    "    while True:\n",
    "        try:\n",
    "            completion = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                temperature=0,\n",
    "                messages = [\n",
    "                    {\"role\" : \"user\", \"content\" : task},\n",
    "                    {\"role\" : \"user\", \"content\" : ex1_input},\n",
    "                    {\"role\" : \"assistant\", \"content\" : ex1_output},\n",
    "                    {\"role\" : \"user\", \"content\" : ex2_input},\n",
    "                    {\"role\" : \"assistant\", \"content\" : ex2_output},\n",
    "                    {\"role\" : \"user\", \"content\" : ex3_input},\n",
    "                    {\"role\" : \"assistant\", \"content\" : ex3_output},\n",
    "                    {\"role\" : \"user\", \"content\" : ex4_input},\n",
    "                    {\"role\" : \"assistant\", \"content\" : ex4_output},\n",
    "                    {\"role\" : \"user\", \"content\" : f\"Project purpose:\\n{purpose}\\n\\Function to rename:\\n{name}\\n\\nCode:\\n```python\\n{cell_src}\\n```\"}\n",
    "                ]\n",
    "            )\n",
    "        except Exception as e:\n",
    "            if 'maximum context length' in str(e):\n",
    "                print('...Error.. too long...' + str(e))\n",
    "                return 'length', ''\n",
    "            else:\n",
    "                print('...Error.. trying again...' + str(e))\n",
    "        else:\n",
    "            break\n",
    "    return completion.choices[0].finish_reason, completion.choices[0].message[\"content\"]\n",
    "\n",
    "gpt_results = []\n",
    "for i, cell_src in enumerate(random_cells):\n",
    "    print(f'Processing file {i}')\n",
    "    finish_reason, result = rename(readmes[i], cell_src, 'function_def')\n",
    "    print(f'File {i} - {finish_reason}')\n",
    "    gpt_results.append({'reason': finish_reason, 'result': result})\n",
    "\n",
    "# save the results to a file\n",
    "with open(GPT_SAVED_FILE_NAME, 'w') as f:\n",
    "    f.write(str(gpt_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in gpt result from file\n",
    "with open(GPT_SAVED_FILE_NAME, 'r') as f:\n",
    "    gpt_results = eval(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop: 20\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print_check_gpt_results(gpt_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now split the data into files\n",
    "gpt_new_names = []\n",
    "gpt_new_code = []\n",
    "gpt_explanation = []\n",
    "\n",
    "for i, result in enumerate(gpt_results):\n",
    "    if result['reason'] == 'stop':\n",
    "        # split the result\n",
    "        first_split = result['result'].split('New function name:')[1].split('Updated code:')\n",
    "        updated_name = first_split[0].strip()\n",
    "        second_split = first_split[1].split('Explanation:')\n",
    "        updated_code = second_split[0].strip()\n",
    "        explanation = second_split[1].strip()\n",
    "\n",
    "        # update name\n",
    "        if len(updated_name.split('`')) == 3:\n",
    "            updated_name = updated_name.split('`')[1]\n",
    "\n",
    "        # get the updated code\n",
    "        updated_code = updated_code.split('```')[1]\n",
    "        if updated_code.startswith('python'):\n",
    "            updated_code = updated_code[6:]\n",
    "        updated_code = updated_code.strip('\\n')\n",
    "        \n",
    "        # store\n",
    "        gpt_new_names.append(updated_name)\n",
    "        gpt_new_code.append(updated_code)\n",
    "        gpt_explanation.append(explanation)\n",
    "    else:\n",
    "        # if we error we assume nothing\n",
    "        gpt_new_names.append(None)\n",
    "        gpt_new_code.append(None)\n",
    "        gpt_explanation.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed on file 3\n",
      "Failed on file 15\n",
      "Pass count: 18, 90.0%\n",
      "Fail count: 2, 10.0%\n"
     ]
    }
   ],
   "source": [
    "# Count the number of times the variable name is/isn't successfully changed\n",
    "import sys\n",
    "sys.path.append('../../determining_files_rename')\n",
    "from ast_determine_usable_items import compare_code\n",
    "\n",
    "pass_count = 0\n",
    "fail_count = 0\n",
    "\n",
    "for i in range(NUM_FILES):\n",
    "    if compare_code(random_cells[i], gpt_new_code[i], 'function_def', gpt_new_names[i]):\n",
    "        pass_count += 1\n",
    "    else:\n",
    "        fail_count += 1\n",
    "        print(f'Failed on file {i}')\n",
    "\n",
    "print(f'Pass count: {pass_count}, {pass_count / (pass_count + fail_count) * 100}%')\n",
    "print(f'Fail count: {fail_count}, {fail_count / (pass_count + fail_count) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def highlight_column_matches(data, column='', color='yellow'):\n",
      "    \"\"\"\n",
      "    highlight the maximum in a Series or DataFrame\n",
      "    \"\"\"\n",
      "    attr = 'background-color: {}'.format(color)\n",
      "    if data.ndim == 1:\n",
      "        is_mixed = data == data[column]\n",
      "        return [attr if v else '' for v in is_mixed]\n",
      "    else:\n",
      "        is_mixed = data == data[column]\n",
      "        return pd.DataFrame(np.where(is_mixed, attr, ''), index=data.index, columns=data.columns)\n",
      "\n",
      "def function_def(csv_filename, columns=['total_reward'], **kwargs):\n",
      "    \"\"\"Plot specified columns from CSV file.\"\"\"\n",
      "    df_stats = pd.read_csv(csv_filename)\n",
      "    df_stats[columns].plot(**kwargs)\n",
      "\n",
      "def save_rnn_layers(hidden_layers, output_layers):\n",
      "    for i, layer in hidden_layers.items():\n",
      "        np.save(os.path.join(vsig.out_dir, 'valid_hidden_layer_' + i + '_output'), hidden_layers[i]['output'])\n",
      "        np.save(os.path.join(vsig.out_dir, 'valid_hidden_layer_' + i + '_state'), hidden_layers[i]['state'])\n",
      "    np.save(os.path.join(vsig.out_dir, 'valid_output_layer'), output_layers)\n",
      "\n",
      "def save_mlp_layers(hidden_layers, output_layers):\n",
      "    for i, layer in hidden_layers.items():\n",
      "        np.save(os.path.join(vsig.out_dir, 'valid_hidden_layer_' + i + '_output'), layer)\n",
      "    np.save(os.path.join(vsig.out_dir, 'valid_output_layer'), output_layers)\n",
      "\n",
      "def glance_at_tensor(tensor):\n",
      "    if len(tensor.shape) == 3:\n",
      "        print(tensor[:10, 0, 0])\n",
      "        print(tensor[0, :10, 0])\n",
      "        print(tensor[0, 0, :10])\n",
      "        print('')\n",
      "        print(tensor[-10:, -1, -1])\n",
      "        print(tensor[-1, -10:, -1])\n",
      "        print(tensor[-1, -1, -10:])\n",
      "    elif len(tensor.shape) == 4:\n",
      "        print(tensor[:10, 0, 0, 0])\n",
      "        print(tensor[0, :10, 0, 0])\n",
      "        print(tensor[0, 0, :10, 0])\n",
      "        print(tensor[0, 0, 0, :10])\n",
      "        print('')\n",
      "        print(tensor[-10:, -1, -1, -1])\n",
      "        print(tensor[-1, -10:, -1, -1])\n",
      "        print(tensor[-1, -1, -10:, -1])\n",
      "        print(tensor[-1, -1, -1, -10:])\n",
      "classifier_activation = {'binary': 'sigmoid', 'categorical': 'softmax'}\n"
     ]
    }
   ],
   "source": [
    "print(random_cells[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def plot_csv_columns(csv_filename, columns=['total_reward'], **kwargs):\n",
      "    \"\"\"Plot specified columns from CSV file.\"\"\"\n",
      "    df_stats = pd.read_csv(csv_filename)\n",
      "    df_stats[columns].plot(**kwargs)\n",
      "\n",
      "def save_rnn_layers(hidden_layers, output_layers):\n",
      "    for i, layer in hidden_layers.items():\n",
      "        np.save(os.path.join(vsig.out_dir, 'valid_hidden_layer_' + i + '_output'), hidden_layers[i]['output'])\n",
      "        np.save(os.path.join(vsig.out_dir, 'valid_hidden_layer_' + i + '_state'), hidden_layers[i]['state'])\n",
      "    np.save(os.path.join(vsig.out_dir, 'valid_output_layer'), output_layers)\n",
      "\n",
      "def save_mlp_layers(hidden_layers, output_layers):\n",
      "    for i, layer in hidden_layers.items():\n",
      "        np.save(os.path.join(vsig.out_dir, 'valid_hidden_layer_' + i + '_output'), layer)\n",
      "    np.save(os.path.join(vsig.out_dir, 'valid_output_layer'), output_layers)\n",
      "\n",
      "def glance_at_tensor(tensor):\n",
      "    if len(tensor.shape) == 3:\n",
      "        print(tensor[:10, 0, 0])\n",
      "        print(tensor[0, :10, 0])\n",
      "        print(tensor[0, 0, :10])\n",
      "        print('')\n",
      "        print(tensor[-10:, -1, -1])\n",
      "        print(tensor[-1, -10:, -1])\n",
      "        print(tensor[-1, -1, -10:])\n",
      "    elif len(tensor.shape) == 4:\n",
      "        print(tensor[:10, 0, 0, 0])\n",
      "        print(tensor[0, :10, 0, 0])\n",
      "        print(tensor[0, 0, :10, 0])\n",
      "        print(tensor[0, 0, 0, :10])\n",
      "        print('')\n",
      "        print(tensor[-10:, -1, -1, -1])\n",
      "        print(tensor[-1, -10:, -1, -1])\n",
      "        print(tensor[-1, -1, -10:, -1])\n",
      "        print(tensor[-1, -1, -1, -10:])\n",
      "classifier_activation = {'binary': 'sigmoid', 'categorical': 'softmax'}\n"
     ]
    }
   ],
   "source": [
    "print(gpt_new_code[15])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
