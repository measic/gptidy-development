[{'identified': [], 'updated_code': 'class two_layer_nn(tf.keras.Model):\n    def __init__(self, output_size=2, loss_type=\'cross-entropy\'):\n        super(two_layer_nn, self).__init__()\n        """ Define here the layers used during the forward-pass \n            of the neural network.     \n            Args:\n                output_size: int (default=2). \n                loss_type: string, \'cross-entropy\' or \'regression\' (default=\'cross-entropy\')\n        """   \n        # First hidden layer\n        self.dense_1 = tf.layers.Dense(20, activation=tf.nn.relu)\n        # Second hidden layer\n        self.dense_2 = tf.layers.Dense(10, activation=tf.nn.relu)\n        # Output layer. Unscaled log probabilities\n        self.dense_out = tf.layers.Dense(output_size, activation=None)     \n        # Initialize loss type\n        self.loss_type = loss_type\n    \n    def predict(self, input_data):\n        """ Runs a forward-pass through the network.     \n            Args:\n                input_data: 2D tensor of shape (n_samples, n_features).   \n            Returns:\n                logits: unnormalized predictions.\n        """\n        layer_1 = self.dense_1(input_data)\n        layer_2 = self.dense_2(layer_1)\n        logits = self.dense_out(layer_2)\n        return logits\n    \n    def loss_fn(self, input_data, target):\n        """ Defines the loss function used during \n            training.         \n        """\n        preds = self.predict(input_data)\n        if self.loss_type==\'cross-entropy\':\n            loss = tf.losses.sparse_softmax_cross_entropy(labels=target, logits=preds)\n        else:\n            loss = tf.losses.mean_squared_error(target, preds)\n        return loss\n    \n    def grads_fn(self, input_data, target):\n        """ Dynamically computes the gradients of the loss value\n            with respect to the parameters of the model, in each\n            forward pass.\n        """\n        with tfe.GradientTape() as tape:\n            loss = self.loss_fn(input_data, target)\n        return tape.gradient(loss, self.variables)\n    \n    def fit(self, input_data, target, optimizer, num_epochs=500, \n            verbose=50, track_accuracy=True):\n        """ Function to train the model, using the selected optimizer and\n            for the desired number of epochs. It also stores the accuracy\n            of the model after each epoch.\n        """   \n        \n        if track_accuracy:\n            # Initialize list to store the accuracy of the model\n            self.hist_accuracy = []     \n            # Initialize class to compute the accuracy metric\n            accuracy = tfe.metrics.Accuracy()\n\n        for i in range(num_epochs):\n            # Take a step of gradient descent\n            grads = self.grads_fn(input_data, target)\n            optimizer.apply_gradients(zip(grads, self.variables))\n            if track_accuracy:\n                # Predict targets after taking a step of gradient descent\n                logits = self.predict(X)\n                preds = tf.argmax(logits, axis=1)\n                # Compute the accuracy\n                accuracy(preds, target)\n                # Get the actual result and add it to our list\n                self.hist_accuracy.append(accuracy.result())\n                # Reset accuracy value (we don\'t want to track the running mean accuracy)\n                accuracy.init_variables()\n'}, {'identified': [], 'updated_code': 'def precision(labels, predictions, weights=None):\n    conf_matrix = tf.confusion_matrix(labels, predictions, num_classes=3)\n    tp_and_fp = tf.reduce_sum(conf_matrix, axis=0)\n    tp = tf.diag_part(conf_matrix)\n    precision_scores = tp/(tp_and_fp)\n    if weights:\n        precision_score = tf.multiply(precision_scores, weights)/tf.reduce_sum(weights)\n    else:\n        precision_score = tf.reduce_mean(precision_scores)        \n    return precision_score'}, {'identified': [], 'updated_code': 'def recall(labels, predictions, weights=None):\n    conf_matrix = tf.confusion_matrix(labels, predictions, num_classes=3)\n    tp_and_fn = tf.reduce_sum(conf_matrix, axis=1)\n    tp = tf.diag_part(conf_matrix)\n    recall_scores = tp/(tp_and_fn)\n    if weights:\n        recall_score = tf.multiply(recall_scores, weights)/tf.reduce_sum(weights)\n    else:\n        recall_score = tf.reduce_mean(recall_scores)        \n    return recall_score'}, {'identified': [], 'updated_code': 'def roc_auc(labels, predictions, thresholds, get_fpr_tpr=True):\n    tpr = []\n    fpr = []\n    for th in thresholds:    \n        # Compute number of true positives\n        tp_cases = tf.where((tf.greater_equal(predictions, th)) & \n                            (tf.equal(labels, 1)))\n        tp = tf.size(tp_cases)\n        \n        # Compute number of true negatives\n        tn_cases = tf.where((tf.less(predictions, th)) & \n                            (tf.equal(labels, 0)))\n        tn = tf.size(tn_cases)\n        \n        # Compute number of false positives\n        fp_cases = tf.where((tf.greater_equal(predictions, th)) & \n                            (tf.equal(labels,0)))\n        fp = tf.size(fp_cases)\n        \n        # Compute number of false negatives\n        fn_cases = tf.where((tf.less(predictions, th)) & \n                            (tf.equal(labels,1)))\n        fn = tf.size(fn_cases)\n        \n        # Compute True Positive Rate for this threshold\n        tpr_th = tp/(tp + fn)\n        \n        # Compute the False Positive Rate for this threshold\n        fpr_th = fp/(fp + tn)\n        \n        # Append to the entire True Positive Rate list\n        tpr.append(tpr_th)\n        \n        # Append to the entire False Positive Rate list\n        fpr.append(fpr_th)\n        \n    # Approximate area under the curve using Riemann sums and the trapezoidal rule\n    auc_score = 0\n    for i in range(0, len(thresholds)-1):\n        height_step = tf.abs(fpr[i+1]-fpr[i])\n        b1 = tpr[i]\n        b2 = tpr[i+1]\n        step_area = height_step*(b1+b2)/2\n        auc_score += step_area\n    return auc_score, fpr, tpr'}, {'identified': [], 'updated_code': 'def read_s3_csv (dates):\n    s3 = boto3.resource(\'s3\')\n    deutsche_boerse_bucket = \'deutsche-boerse-xetra-pds\'\n    \n    bucket = s3.Bucket(deutsche_boerse_bucket)\n    \n    dataframes = []\n    \n    for date in dates:\n        objs_count = 0\n        csv_objects = bucket.objects.filter(Prefix=date)\n        for csv_obj in csv_objects:\n            csv_key = csv_obj.key\n            if csv_key[-4:] == \'.csv\':\n                objs_count += 1\n                csv_body = csv_obj.get()[\'Body\']\n                df = pd.read_csv(csv_body)\n                dataframes.append(df)\n        \n        print ("Loaded {} data objects for {}".format (objs_count, date))\n    return pd.concat(dataframes)'}, {'identified': [], 'updated_code': 'def build_index(non_empty_days, from_time, to_time):\n    date_ranges = []\n    for date in non_empty_days:\n        yyyy, mm, dd = date.split(\'-\')\n        from_hour, from_min = from_time.split(\':\')\n        to_hour, to_min = to_time.split(\':\')    \n        t1 = datetime(int(yyyy), int(mm), int(dd), int(from_hour),int(from_min),0)\n        t2 = datetime(int(yyyy), int(mm), int(dd), int(to_hour),int(to_min),0) \n        date_ranges.append(pd.DataFrame({"OrganizedDateTime": pd.date_range(t1, t2, freq=\'1Min\').values}))\n    agg = pd.concat(date_ranges, axis=0) \n    agg.index = agg["OrganizedDateTime"]\n    return agg'}, {'identified': ['basic_stock_features'], 'updated_code': ''}, {'identified': ['clean_data'], 'updated_code': ''}, {'identified': ['create_xgb_target'], 'updated_code': ''}, {'identified': ['create_xgb_features'], 'updated_code': ''}, {'identified': [], 'updated_code': 'def engineer_date_range (dates):\n    unprocessed_df = read_s3_csv (dates)\n    print ("Loaded CSV data set from S3")\n    \n    cleaned_df = clean_data (unprocessed_df, inplace = True)\n    print ("Cleaned CSV data set")\n     \n    xgb_data = create_xgb_features (cleaned_df, 5, inplace=True)\n    xgb_data[\'NextMaxPrice\'] = create_xgb_target (xgb_data)\n    print ("Engineered CSV data set")\n    \n    train_data, validate_data = train_test_split (xgb_data, train_size=0.8, test_size=0.2, shuffle=True)\n\n    cols = list(train_data.columns.values)\n    cols.remove (\'NextMaxPrice\')\n    cols = [\'NextMaxPrice\'] + cols\n\n    train_data = pd.get_dummies (train_data[cols])\n    validate_data = pd.get_dummies (validate_data[cols])\n    print ("Data split for training purposes")\n    \n    return (train_data, validate_data)'}, {'identified': [], 'updated_code': 'def plot_image(image):\n    plt.imshow(image, cmap="gray", interpolation="nearest")\n    plt.axis("off")\n\ndef plot_color_image(image):\n    plt.imshow(image.astype(np.uint8),interpolation="nearest")\n    plt.axis("off")'}, {'identified': [], 'updated_code': 'def get_model_params():\n    gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n    return {gvar.op.name: value for gvar, value in zip(gvars, tf.get_default_session().run(gvars))}\n\ndef restore_model_params(model_params):\n    gvar_names = list(model_params.keys())\n    assign_ops = {gvar_name: tf.get_default_graph().get_operation_by_name(gvar_name + "/Assign")\n                  for gvar_name in gvar_names}\n    init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}\n    feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n    tf.get_default_session().run(assign_ops, feed_dict=feed_dict)'}, {'identified': ['fetch_pretrained_inception_v3'], 'updated_code': 'import sys\nimport tarfile\nfrom six.moves import urllib\n\nTF_MODELS_URL = "http://download.tensorflow.org/models"\nINCEPTION_V3_URL = TF_MODELS_URL + "/inception_v3_2016_08_28.tar.gz"\nINCEPTION_PATH = os.path.join("datasets", "inception")\nINCEPTION_V3_CHECKPOINT_PATH = os.path.join(INCEPTION_PATH, "inception_v3.ckpt")\n\ndef download_progress(count, block_size, total_size):\n    percent = count * block_size * 100 // total_size\n    sys.stdout.write("\\rDownloading: {}%".format(percent))\n    sys.stdout.flush()\n\nif os.path.exists(INCEPTION_V3_CHECKPOINT_PATH):\n    pass\nos.makedirs(path, exist_ok=True)\ntgz_path = os.path.join(path, "inception_v3.tgz")\nurllib.request.urlretrieve(url, tgz_path, reporthook=download_progress)\ninception_tgz = tarfile.open(tgz_path)\ninception_tgz.extractall(path=path)\ninception_tgz.close()\nos.remove(tgz_path)'}, {'identified': [], 'updated_code': 'import re\n\nCLASS_NAME_REGEX = re.compile(r"^n\\d+\\s+(.*)\\s*$", re.M | re.U)\n\ndef load_class_names():\n    with open(os.path.join("datasets", "inception", "imagenet_class_names.txt"), "rb") as f:\n        content = f.read().decode("utf-8")\n        return CLASS_NAME_REGEX.findall(content)'}, {'identified': ['fetch_flowers'], 'updated_code': 'import sys\nimport tarfile\nfrom six.moves import urllib\n\nFLOWERS_URL = "http://download.tensorflow.org/example_images/flower_photos.tgz"\nFLOWERS_PATH = os.path.join("datasets", "flowers")\n\nif os.path.exists(FLOWERS_PATH):\n    pass\nos.makedirs(FLOWERS_PATH, exist_ok=True)\ntgz_path = os.path.join(FLOWERS_PATH, "flower_photos.tgz")\nurllib.request.urlretrieve(FLOWERS_URL, tgz_path, reporthook=download_progress)\nflowers_tgz = tarfile.open(tgz_path)\nflowers_tgz.extractall(path=FLOWERS_PATH)\nflowers_tgz.close()\nos.remove(tgz_path)'}, {'identified': [], 'updated_code': 'from scipy.misc import imresize\n\ndef prepare_image(image, target_width = 299, target_height = 299, max_zoom = 0.2):\n    """Zooms and crops the image randomly for data augmentation."""\n\n    # First, let\'s find the largest bounding box with the target size ratio that fits within the image\n    height = image.shape[0]\n    width = image.shape[1]\n    image_ratio = width / height\n    target_image_ratio = target_width / target_height\n    crop_vertically = image_ratio < target_image_ratio\n    crop_width = width if crop_vertically else int(height * target_image_ratio)\n    crop_height = int(width / target_image_ratio) if crop_vertically else height\n        \n    # Now let\'s shrink this bounding box by a random factor (dividing the dimensions by a random number\n    # between 1.0 and 1.0 + `max_zoom`.\n    resize_factor = np.random.rand() * max_zoom + 1.0\n    crop_width = int(crop_width / resize_factor)\n    crop_height = int(crop_height / resize_factor)\n    \n    # Next, we can select a random location on the image for this bounding box.\n    x0 = np.random.randint(0, width - crop_width)\n    y0 = np.random.randint(0, height - crop_height)\n    x1 = x0 + crop_width\n    y1 = y0 + crop_height\n    \n    # Let\'s crop the image using the random bounding box we built.\n    image = image[y0:y1, x0:x1]\n\n    # Let\'s also flip the image horizontally with 50% probability:\n    if np.random.rand() < 0.5:\n        image = np.fliplr(image)\n\n    # Now, let\'s resize the image to the target dimensions.\n    image = imresize(image, (target_width, target_height))\n    \n    # Finally, let\'s ensure that the colors are represented as\n    # 32-bit floats ranging from 0.0 to 1.0 (for now):\n    return image.astype(np.float32) / 255'}, {'identified': [], 'updated_code': 'def prepare_image_with_tensorflow(image, target_width = 299, target_height = 299, max_zoom = 0.2):\n    """Zooms and crops the image randomly for data augmentation."""\n\n    # First, let\'s find the largest bounding box with the target size ratio that fits within the image\n    image_shape = tf.cast(tf.shape(image), tf.float32)\n    height = image_shape[0]\n    width = image_shape[1]\n    image_ratio = width / height\n    target_image_ratio = target_width / target_height\n    crop_vertically = image_ratio < target_image_ratio\n    crop_width = tf.cond(crop_vertically,\n                         lambda: width,\n                         lambda: height * target_image_ratio)\n    crop_height = tf.cond(crop_vertically,\n                          lambda: width / target_image_ratio,\n                          lambda: height)\n\n    # Now let\'s shrink this bounding box by a random factor (dividing the dimensions by a random number\n    # between 1.0 and 1.0 + `max_zoom`.\n    resize_factor = tf.random_uniform(shape=[], minval=1.0, maxval=1.0 + max_zoom)\n    crop_width = tf.cast(crop_width / resize_factor, tf.int32)\n    crop_height = tf.cast(crop_height / resize_factor, tf.int32)\n    box_size = tf.stack([crop_height, crop_width, 3])   # 3 = number of channels\n\n    # Let\'s crop the image using a random bounding box of the size we computed\n    image = tf.random_crop(image, box_size)\n\n    # Let\'s also flip the image horizontally with 50% probability:\n    image = tf.image.random_flip_left_right(image)\n\n    # The resize_bilinear function requires a 4D tensor (a batch of images)\n    # so we need to expand the number of dimensions first:\n    image_batch = tf.expand_dims(image, 0)\n\n    # Finally, let\'s resize the image to the target dimensions. Note that this function\n    # returns a float32 tensor.\n    image_batch = tf.image.resize_bilinear(image_batch, [target_height, target_width])\n    image = image_batch[0] / 255  # back to a single image, and scale the colors from 0.0 to 1.0\n    return image'}, {'identified': [], 'updated_code': 'from random import sample\n\ndef prepare_batch(flower_paths_and_classes, batch_size):\n    batch_paths_and_classes = sample(flower_paths_and_classes, batch_size)\n    images = [mpimg.imread(path)[:, :, :channels] for path, labels in batch_paths_and_classes]\n    prepared_images = [prepare_image(image) for image in images]\n    X_batch = 2 * np.stack(prepared_images) - 1 # Inception expects colors ranging from -1 to 1\n    y_batch = np.array([labels for path, labels in batch_paths_and_classes], dtype=np.int32)\n    return X_batch, y_batch'}, {'identified': [], 'updated_code': '#apply style function to highlight profit losses\ndef color_negative_red(val):\n    """\n    Takes a scalar and returns a string with\n    the css property `\'color: red\'` for negative\n    strings, black otherwise.\n    """\n    color = \'red\' if val < 0 else \'black\'\n    return \'color: %s\' % color'}]