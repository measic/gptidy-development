[{'reason': 'stop', 'result': 'def Lectura(ux,uy,uz):\n    Ux = np.loadtxt(ux, unpack = True)\n    Uy = np.loadtxt(uy, unpack = True)\n    Uz = np.loadtxt(uz, unpack = True)\n    return Ux,Uy,Uz\n\n\n\ndef Grafica(udat,vdat,xdat,ydat,linea):\n    u = np.loadtxt(udat, unpack = True)\n    v = np.loadtxt(vdat, unpack = True)\n    x = np.loadtxt(xdat, unpack = True)\n    y = np.loadtxt(ydat, unpack = True)\n\n    X = np.linspace(0,1,50)\n\n    f, axarr = plt.subplots(1,2, figsize=(24,6))\n    st = f.suptitle("$\\\\tau = 0.6$", fontsize=25)\n    st.set_y(1.0)\n    pasos = 12\n    M= np.hypot(u, v)\n    im=axarr[0].quiver(x,y,u,v,M , cmap=plt.cm.jet,width=0.022,scale=1/0.1)\n    axarr[0].set_title("Campos",fontsize = 20)\n    axarr[0].set_xlim(-0.01,1)\n    axarr[0].set_xlabel("$x[m]$",fontsize = 20)\n    axarr[0].set_ylabel("$y[m]$",fontsize = 20)\n    axarr[0].tick_params(axis="x", labelsize=20)\n    axarr[0].tick_params(axis="y", labelsize=20)\n    \n    axarr[1].plot(x,v[linea,:],"b", label = "Simulacion")\n    axarr[1].legend()\n    axarr[1].grid(True)\n    axarr[1].set_title(\'Perfil de Velocidad\',fontsize = 20,y=1.0)\n    axarr[1].set_xlabel("$x[m]$",fontsize = 20)\n    axarr[1].set_ylabel("$v[m/s]$",fontsize =20)\n    axarr[1].tick_params(axis="x", labelsize=20)\n    axarr[1].tick_params(axis="y", labelsize=20)\n    \n    cbar = f.colorbar(im, ax=axarr, shrink = 1.0)\n    cbar.set_label(\'$v[m/s]$\',fontsize =20)\n    cbar.ax.tick_params(labelsize=20)\n```\n\nUnused variables:\n- `Ux`\n- `Uy`\n- `Uz`'}, {'reason': 'stop', 'result': 'def get_mean_band(data):\n    \n    final_variances = []\n    for d in data:\n        variances = []\n        skewnesses = []\n        kurtosises = []\n        for channel in d:\n            var = channel.var()\n            variances.append(var)\n            \n            skewness = skew(channel, axis=0)\n            skewnesses.append(skewness)\n\n            kurt = kurtosis(channel)\n            kurtosises.append(kurt)\n        \n        final_variances.append([variances, skewnesses, kurtosises])\n    \n    return np.array(final_variances)```\n\nUnused variables:\n- stats'}, {'reason': 'stop', 'result': 'def run_episode_neural_network(show_renderer=False):    \n    with tf.Session() as sess:\n        init.run()\n        obs = env.reset()\n        obs_pretty = obs.reshape(1, nb_neurons_input)\n        done = False\n        final_score = 0\n        while not done:\n            if show_renderer:\n                env.render()\n            proba_move_to_left = output.eval(feed_dict={X: obs_pretty})        \n            if random.uniform(0, 1) < proba_move_to_left:\n                action = 0  # move to left\n            else:\n                action = 1       \n            obs, reward, done, info = env.step(action) \n            if done:\n                break\n            final_score += reward\n    env.reset()\n    env.close()\n    return final_score\n```\n\nUnused variables: None'}, {'reason': 'stop', 'result': 'def plot_categorical_count(df, column, title=\'\', limit=2, xtick_rotation=\'horizontal\'):\n    column_count = df[column].value_counts()[:limit]\n    \n    fig = plt.figure(figsize=(14, 8))\n    sns.barplot(x=column_count.index, y=column_count.values, palette=\'Paired\')\n    sns.despine(left=True)\n    plt.title(title, fontsize=16)\n    plt.xticks(rotation=xtick_rotation)\n\ndef plot_heatmap(df, variable):\n    l = []\n    for name, group in top10_df.groupby(\'Country\'):\n        dff = pd.DataFrame(group[variable].value_counts() / group[variable].count()) \n        dff[\'Country\'] = name\n        dff[\'rate\'] = dff.index\n        l.append(dff)\n    fig = plt.figure(figsize=(14, 8))\n    df_2 = pd.concat(l)\n    dff = df_2.pivot_table(index=\'Country\', columns=\'rate\')\n    sns.heatmap(dff, cmap="YlGnBu", linewidths=.3)```\n\nUnused variables:\n- None'}, {'reason': 'stop', 'result': "# do the reduction but in a different way\ncov = X.T @ X /(X.shape[0] - 1)\nval, vec = np.linalg.eigh(cov)\nidx = np.argsort(val)[::-1]\nval = val[idx]\nvec = vec[:,idx]\nproject_X = X @ vec\nproject_V = vec.T @ vec\n\ninversed_vec = np.linalg.inv(vec)\ninversed_vec = inversed_vec - inversed_vec.mean(1)\nrevert_X = project_X @ inversed_vec\nrevertedV = project_V @ inversed_vec.T\n\n\ndef plot():\n    plt.figure(figsize=(15,5)); \n\n    plt.subplot(131); \n    plt.scatter(X[y==0, 0], X[y==0, 1], color='red', alpha=0.5)\n    plt.scatter(X[y==1, 0], X[y==1, 1], color='blue', alpha=0.5)\n    pca11 = plt.arrow(0, 0, *vec[:,0] * val[0], head_width=0.05, head_length=0.05, color='Green', label='First PC')\n    pca12 = plt.arrow(0, 0, *vec[:,1] * val[1], head_width=0.05, head_length=0.05, color='magenta', label='Second PC')\n    plt.grid(True); \n\n    plt.subplot(132); \n    plt.scatter(project_X[y==0, 0], project_X[y==0, 1], color='red', alpha=0.5)\n    plt.scatter(project_X[y==1, 0], project_X[y==1, 1], color='blue', alpha=0.5)\n    pca21 = plt.arrow(0, 0, *project_V[:,0] * val_reduced[0], head_width=0.05, head_length=0.05, color='Green', label='First PC')\n    pca22 = plt.arrow(0, 0, *project_V[:,1] * val_reduced[1], head_width=0.05, head_length=0.05, color='magenta', label='Second PC')\n    plt.grid(True); \n\n    plt.subplot(133); \n    plt.scatter(revert_X[y==0, 0], revert_X[y==0, 1], color='red', alpha=0.5)\n    plt.scatter(revert_X[y==1, 0], revert_X[y==1, 1], color='blue', alpha=0.5)\n    pca21 = plt.arrow(0, 0, *revertedV[:,0] * val[0], head_width=0.05, head_length=0.05, color='Green', label='First PC')\n    pca22 = plt.arrow(0, 0, *revertedV[:,1] * val[1], head_width=0.05, head_length=0.05, color='magenta', label='Second PC')\n    plt.grid(True); \n\n    plt.show()\nplot()```\n\nUnused variables:\n- idx"}, {'reason': 'stop', 'result': "def value_iteration(V_init, PI_init, P, R, states, actions, next_states, gamma, epsilon=1e-4):\n    \n    #1. INITIALIZATION\n    V_k = copy.deepcopy(V_init)  # V(s) ... our value function estimate for PI\n    PI = copy.deepcopy(PI_init)  # PI(s) ... our greedy policy\n        \n    # 2. POLICY EVALUATION (makes only 1 sweep before taking the max over the actions)\n    k = 0\n    V_kplus1 = copy.deepcopy(V_k)\n    delta = epsilon + 1\n    \n    while delta > epsilon:\n\n        delta = 0\n        \n        Q = {0: {0: 0,   # state0, action0\n                 1: 0},  # state0, action1\n             1: {2: 0}}  # state1, action2\n        for s in states:\n            for a in actions[s]:\n                for n in next_states:\n                \n                    # Bellman's optimality update rule\n                    Q[s][a] += P[n,s,a] * (R[s,a] + gamma * V_k[n])\n\n            # This step replaces the poilicy improvement step (gets the maximal value)\n            V_kplus1[s] = max(Q[s].items(), key=operator.itemgetter(1))[1]\n            \n            # Keeps biggest difference seen so far\n            delta = np.max([delta, np.abs(V_kplus1[s] - V_k[s])])\n\n        # Updates our current estimate\n        V_k = copy.deepcopy(V_kplus1)\n        k += 1\n    \n    # Updates the policy to be greedy with respect to the value function\n    for s in states:\n        PI[s] = max(Q[s].items(), key=operator.itemgetter(1))[0]\n    \n    return V_k, k, PI\n```\n\nUnused variables:\n- `v`"}, {'reason': 'stop', 'result': 'def plotImg(arr, **kwargs):\n    \n    avg = mean(arr.flatten())\n    std = stdev(arr.flatten())\n    \n    fig,ax = plt.subplots(1)\n    pl = plt.imshow(arr, origin=\'lower\', interpolation=\'nearest\', cmap=\'gray\', \\\n                    vmin=np.percentile(arr, 10), vmax=np.percentile(arr, 90))\n    if \'window\' in kwargs:\n        window = kwargs.get(\'window\')\n        rect = patches.Rectangle(window[0], window[1][1], window[1][0], edgecolor=\'r\', facecolor=\'none\')\n        ax.add_patch(rect)\n    plt.colorbar().set_label(\'Detector Value (ADU)\')\n    plt.xlabel(\'pixels(x)\')\n    plt.ylabel(\'pixels(y)\')\n    if \'save_dir\' in kwargs:\n        save_dir = kwargs.get(\'save_dir\')\n        plt.savefig(save_dir + \'selection_window.png\')\n    plt.show()\n\ndef plotAll(array2D, **kwargs):\n    """\n    Input:  \'array2D\': 2D image array\n    Output: show plot of histogram and image\n    """\n    \n    arr = array2D.flatten()\n    \n    avg = mean(arr)\n    std = stdev(arr)\n    \n    sigma = kwargs.get(\'sigma\', 2)\n    low = int(np.round((avg-sigma*std)))\n    high = int(np.round((avg+sigma*std)))\n    rng = kwargs.get(\'rng\', [low, high])\n    exp = kwargs.get(\'exp\')\n    if \'nbins\' in kwargs:\n        nbins = kwargs.get(\'nbins\')\n        bin_size = (rng[1]-rng[0])/nbins\n    else:\n        bin_size = kwargs.get(\'bin_size\', 1)\n    \n    fig, (ax1, ax2) = plt.subplots(1,2, figsize=[18,6])\n    \n    # Histogram\n    #===========\n    hr = np.arange(rng[0], rng[1]+1, bin_size)\n    hist = []\n    for i in range(len(hr)):\n        try:\n            counts = len(np.where((arr >= hr[i]) & (arr < hr[i+1]))[0])\n        except:\n            counts = 0\n        hist.append(counts)\n    ax1.step(hr, hist, color=\'k\')\n\n    #mean and median lines\n    ax1.axvline(avg, color=\'b\', label=r\'$\\bar{x}=%s$\'%(np.round(avg,2)))\n#     ax1.axvline(med, color=\'b\', label=r\'$\\tilde{x}=%s$\'%(np.round(med,2)), linestyle=\'dashed\')\n    \n    #sigma levels\n    if kwargs.get(\'show_level\', True) == True:\n        for i in np.arange(1,sigma+1):\n            if i == 1:\n                ax1.axvspan(avg-i*std, avg+i*std, facecolor=\'g\', alpha=0.05, label=r\'$s=\\pm %s$\'%(np.round(std,2)))\n            else:\n                ax1.axvspan(avg-i*std, avg+i*std, facecolor=\'g\', alpha=0.05)\n                \n                \n    #poisson distribution\n    xarray = np.arange(rng[0]-10, rng[1]+10, 1)\n    pdist = poisson_approx(xarray, avg)\n    pdist = max(hist)/max(pdist)*pdist\n    ax1.plot(xarray, pdist, color=\'r\', label=r\'$P_{Poisson}(\\bar{x})$\')\n    std_expected = math.sqrt(avg)\n    ax1.axvspan(avg - std_expected, avg + std_expected, facecolor=\'r\', alpha=0.05, \\\n                label=r\'$\\sigma=\\pm %s$\'%(np.round(std_expected,2)))\n    \n    #gaussian distribution\n    gdist = gaussian(xarray, avg, std)\n    gdist = max(hist)/max(gdist)*gdist\n    ax1.plot(xarray, gdist, color=\'c\', label=r\'$P_{Gaussian}(\\bar{x}, s)$\')\n    \n    ax1.legend(loc=\'upper left\')\n    ax1.set_xlabel(\'Counts (ADU)\')\n    ax1.set_ylabel(\'Frequency\')\n    \n    if \'exp\' in kwargs:\n        ax1.set_title(\'Combined Histogram (Exposure Time: %s sec)\'%(exp))\n    ax1.set_xlim(rng)\n    \n    # Image\n    #===========\n    hrng = kwargs.get(\'hrng\', [np.percentile(arr, 10), np.percentile(arr, 90)])\n    pl = ax2.imshow(array2D, origin=\'lower\', interpolation=\'nearest\', cmap=\'gray\', vmin=hrng[0], vmax=hrng[1])\n    fig.colorbar(pl, ax=ax2, fraction=0.046, pad=0.04).set_label(\'Detector Value (ADU)\')\n    \n    ax2.set_xlabel(\'pixels(x)\')\n    ax2.set_ylabel(\'pixels(y)\')\n    ax2.set_title(\'Combined Image\')\n    \n    if \'save_dir\' in kwargs:\n        save_dir = kwargs.get(\'save_dir\')\n        plt.savefig(save_dir + \'exposure%s.png\'%(exp))\n    plt.show()```\n\nUnused variables:\n- std\n- med\n- Npix'}, {'reason': 'stop', 'result': 'class MyVectorizer(BaseEstimator, TransformerMixin):\n\n    def __init__(self, cols, hashing=None):\n        """\n        args:\n            cols: a list of column names of the categorical variables\n            hashing: \n                If None, then vectorization is a simple one-hot-encoding.\n                If an integer, then hashing is the number of features in the output.\n        """\n        self.cols = cols\n        self.hashing = hashing\n        \n    def fit(self, X, y=None):\n\n        data = X[self.cols]\n        \n        # Choose a vectorizer\n        if self.hashing is None:\n            self.myvec = DictVectorizer(sparse=False)\n        else:\n            self.myvec = FeatureHasher(n_features = self.hashing)\n    \n        self.myvec.fit(X[self.cols].to_dict(orient=\'records\'))\n        return self\n            \n    def transform(self, X):\n            \n        # Vectorize Input\n        if self.hashing is None:\n            return pd.DataFrame(\n                self.myvec.transform(X[self.cols].to_dict(orient=\'records\')),\n                columns = self.myvec.feature_names_\n            )\n        else:\n            return pd.DataFrame(\n                self.myvec.transform(X[self.cols].to_dict(orient=\'records\')).toarray()\n            )```\n\nUnused variables: None'}, {'reason': 'stop', 'result': 'def insert_and_time_filter_bloom_filter(capacity, percent_fill=0.9):\n    b_filter = CountingBloomFilter(capacity)\n    now = time.time()\n    for i in range(int(percent_fill*capacity)):\n        b_filter.add(str(i))\n    elapsed_insertion = time.time() - now\n    return b_filter, elapsed_insertion\n```\n\nUnused variables:\n- num_inserted'}, {'reason': 'stop', 'result': 'import warnings\n\n# evaluate an ARIMA model for a given order (p,d,q)\ndef evaluate_arima_model(X, arima_order):\n    # prepare training dataset\n    train = X.loc[:39,[\'client-ip-unique-count\']]\n    test= X.loc[40:,[\'client-ip-unique-count\']]\n    \n    history = [x for x in train]\n    # make predictions\n    predictions = list()\n    model = sm.tsa.ARIMA(train, order=arima_order).fit()\n    predictions = model.predict(40,42,dynamic=True)\n    error = mean_absolute_error(test, predictions)\n    return error\n\n\n# evaluate combinations of p, d and q values for an ARIMA model\ndef evaluate_models(dataset, p_values, d_values, q_values):\n    dataset = dataset.astype(\'float32\')\n    best_score, best_cfg = float("inf"), None\n    for p in p_values:\n        for d in d_values:\n            for q in q_values:\n                order = (p,d,q)\n                try:\n                    mae = evaluate_arima_model(dataset, order)\n                    if mae < best_score:\n                        best_score, best_cfg = mae, order\n                    print(\'ARIMA%s MAE=%.3f\' % (order,mae))\n                except:\n                    continue\n    print(\'Best ARIMA%s MAE=%.3f\' % (best_cfg, best_score))\n \n\n# load dataset\np_values = [0, 1, 2, 4,6,8,10]\nd_values = range(0, 3)\nq_values = range(0, 3)\nwarnings.filterwarnings("ignore")\nevaluate_models(log_and_placements_aggregated_per_week_df.loc[:,[\'client-ip-unique-count\']], p_values, d_values, q_values)```\n\nUnused variables:\n- history\n- predictions'}, {'reason': 'stop', 'result': 'import warnings\n\n# evaluate an ARIMA model for a given order (p,d,q)\ndef evaluate_arima_model(X, arima_order):\n    # prepare training dataset\n    train = X.loc[:39,[\'client-ip-unique-count-log\']]\n    test= X.loc[40:,[\'client-ip-unique-count-log\']]\n    \n    history = [x for x in train]\n    # make predictions\n    predictions = list()\n    model = sm.tsa.ARIMA(train, order=arima_order).fit()\n    predictions = model.predict(40,42,dynamic=True)\n    error = mean_absolute_error(np.exp(test), np.exp(predictions))\n    return error\n\n\n# evaluate combinations of p, d and q values for an ARIMA model\ndef evaluate_models(dataset, p_values, d_values, q_values):\n    dataset = dataset.astype(\'float32\')\n    best_score, best_cfg = float("inf"), None\n    for p in p_values:\n        for d in d_values:\n            for q in q_values:\n                order = (p,d,q)\n                try:\n                    mae = evaluate_arima_model(dataset, order)\n                    if mae < best_score:\n                        best_score, best_cfg = mae, order\n                    print(\'ARIMA%s MAE=%.3f\' % (order,mae))\n                except:\n                    continue\n    print(\'Best ARIMA%s MAE=%.3f\' % (best_cfg, best_score))\n \n\n# load dataset\np_values = [0, 1, 2, 4,6,8,10]\nd_values = range(0, 3)\nq_values = range(0, 3)\nwarnings.filterwarnings("ignore")\nevaluate_models(log_and_placements_aggregated_per_week_df.loc[:,[\'client-ip-unique-count-log\']], p_values, d_values, q_values)```\n\nUnused variables: None'}, {'reason': 'stop', 'result': "def kmeans_multiple_runs(data, k, maxiter, num_runs, seed_list=None, verbose=False):\n    heterogeneity = {}\n    \n    min_heterogeneity_achieved = float('inf')\n    best_seed = None\n    final_centroids = None\n    final_cluster_assignment = None\n    \n    for i in xrange(num_runs):\n        \n        # Use UTC time if no seeds are provided \n        if seed_list is not None: \n            seed = seed_list[i]\n            np.random.seed(seed)\n        else: \n            seed = int(time.time())\n            np.random.seed(seed)\n        \n        # Use k-means++ initialization\n        initial_centroids = get_initial_centroids(data, k, seed=0)\n        \n        # Run k-means\n        centroids, cluster_assignment = kmeans(data, k, initial_centroids, maxiter=400,\n                                       record_heterogeneity=None, verbose=True)\n        \n        # To save time, compute heterogeneity only once in the end\n        heterogeneity[seed] = compute_heterogeneity(data, k, centroids, cluster_assignment)\n        \n        if verbose:\n            print('seed={0:06d}, heterogeneity={1:.5f}'.format(seed, heterogeneity[seed]))\n            sys.stdout.flush()\n        \n        # if current measurement of heterogeneity is lower than previously seen,\n        # update the minimum record of heterogeneity.\n        if heterogeneity[seed] < min_heterogeneity_achieved:\n            min_heterogeneity_achieved = heterogeneity[seed]\n            best_seed = seed\n            final_centroids = centroids\n            final_cluster_assignment = cluster_assignment\n    \n    # Return the centroids and cluster assignments that minimize heterogeneity.\n    return final_centroids, final_cluster_assignment\n```\n\nUnused variables:\n- `heterogeneity` (not used after initialization)\n- `min_heterogeneity_achieved` (not used after initialization)\n- `best_seed` (not used after initialization)"}, {'reason': 'stop', 'result': "```python\ndef view_samples(epoch, samples):\n    fig, axes = plt.subplots(figsize=(7,7), nrows=4, ncols=4, sharey=True, sharex=True)\n    for ax, img in zip(axes.flatten(), samples[epoch]):\n        ax.xaxis.set_visible(False)\n        ax.yaxis.set_visible(False)\n        ax.imshow(img.reshape((28,28)), cmap='Greys_r')\n    \n    return fig, axes\n```\n\nUnused variables:\n- `im`"}, {'reason': 'stop', 'result': 'def generate_line(model, words, seed=None, rhymes=None):\n    syllables_left = 10\n    \n    line= []\n    start_probs = model.startprob_\n    emission_probs = model.emissionprob_\n    transition_probs = model.transmat_\n    \n    start_state = np.random.choice(len(start_probs), p = start_probs)\n    \n    if seed is not None:\n        possible_start_emissions = np.where(rhymes[seed] == 1)\n        probs = np.array(emission_probs[start_state][possible_start_emissions])\n\n        scaled_probs = probs / sum(probs)\n        while True:\n            start_emission = np.random.choice(possible_start_emissions[0], p=scaled_probs)\n            start_stress = poetrytools.stress(words[start_emission])\n            if len(start_stress) == 1 or int(start_stress[-1]) == 1 :\n                break\n    else:\n        while True:\n            start_emission = np.random.choice(len(emission_probs[start_state]), p=emission_probs[start_state])\n            start_stress = poetrytools.stress(words[start_emission])\n            if len(start_stress) == 1 or int(start_stress[-1]) == 1:\n                break\n    \n    line.append(start_emission)\n    start_stress = poetrytools.stress(words[start_emission])\n    syllables_left -= len(start_stress)\n    \n    if len(start_stress) == 1:\n        prev_starting_stress = 1\n    else:\n        prev_starting_stress = int(start_stress[0])\n\n    curr_state = start_state\n    while syllables_left > 0:\n        possible_transitions = transition_probs[curr_state]\n        curr_state = np.random.choice(len(possible_transitions), p=possible_transitions)\n        possible_emissions = emission_probs[curr_state]\n        while True:\n            curr_emission = np.random.choice(len(possible_emissions), p=possible_emissions)\n            curr_stress = poetrytools.stress(words[curr_emission])\n            if len(curr_stress) == 1:\n                prev_starting_stress = 1 - prev_starting_stress\n                syllables_left -= 1\n                break\n            elif len(curr_stress) > syllables_left or int(curr_stress[-1]) == prev_starting_stress:\n                continue\n            else:\n                prev_starting_stress = int(curr_stress[0])\n                syllables_left -= len(curr_stress)\n                break\n        line.append(curr_emission)\n\n    return line\n\ndef convert_line(sample, words):\n    ret = \'\'\n    i = 0\n    for word in reversed(sample):\n        curr_word = words[word]\n        if i == 0 or (curr_word == \'i\'):\n            ret += curr_word.title() + \' \'\n        else:\n            ret += curr_word + \' \'\n        i += 1\n    return ret\n\ndef generate_pair(model, words, rhymes):\n    while True:\n        a_line = generate_line(model, words)\n        seed = a_line[0]\n        if len(np.where(rhymes[seed] == 1)[0]) > 0:\n            b_line = generate_line(model, words, seed, rhymes)\n            return a_line, b_line\n        \ndef generate_rhyming_and_meter_sonnet():\n    sonnet = \'\'\n    a_lines = []\n    b_lines = []\n    \n    for _ in range(4):\n        a_line, b_line = generate_pair(reversed_quatrain_model, quatrain_words, quatrain_rhymes)\n        a_lines.append(a_line)\n        b_lines.append(b_line)\n    \n    for i in range(2):\n        sonnet += convert_line(a_lines[2 * i], quatrain_words) + \'\\n\'\n        sonnet += convert_line(a_lines[2 * i + 1], quatrain_words) + \'\\n\'\n        sonnet += convert_line(b_lines[2 * i], quatrain_words) + \'\\n\'\n        sonnet += convert_line(b_lines[2 * i + 1], quatrain_words) + \'\\n\'\n    \n    a_lines = []\n    b_lines = []\n    \n    for _ in range(2):\n        a_line, b_line = generate_pair(reversed_volta_model, volta_words, volta_rhymes)\n        a_lines.append(a_line)\n        b_lines.append(b_line)\n    \n    sonnet += convert_line(a_lines[0], volta_words) + \'\\n\'\n    sonnet += convert_line(a_lines[1], volta_words) + \'\\n\'\n    sonnet += convert_line(b_lines[0], volta_words) + \'\\n\'\n    sonnet += convert_line(b_lines[1], volta_words) + \'\\n\'\n    \n    a_line, b_line = generate_pair(reversed_couplet_model, couplet_words, couplet_rhymes)\n    sonnet += convert_line(a_line, couplet_words) + \'\\n\'\n    sonnet += convert_line(b_line, couplet_words) + \'\\n\'\n    \n    return sonnet\n\ndef generate_10_rhyming_and_meter_sonnets():\n    sonnets = \'\'\n    for i in range(10):\n        print(\'Generating Sonnet \' + str(i + 1))\n        sonnets += str(i) + \'\\n\' + generate_rhyming_and_meter_sonnet() + \'\\n\'\n    \n    f = open("project2data/rhyming_and_meter_shakespeare.txt","w")\n    f.write(sonnets)\n    return sonnets\n```\n\n\nUnused variables:\n- last_stress'}, {'reason': 'stop', 'result': 'from arcgis import geometry\nfrom arcgis import features\n\ndef create_feature(map1, g):\n    try:\n        pt = geometry.Point(g)\n        feat = features.Feature(geometry=pt, attributes={\'name\': \'name\',\n                                                        \'type\': \'park\',\n                                                        \'surface\': \'dirt\'})\n        feature_layer.edit_features(adds=[feat])\n        print(str(g))\n        map1.draw(g)\n    except:\n        print("Couldn\'t create the feature. Try again, please...")```\n\nUnused variables:\n- oid'}, {'reason': 'stop', 'result': 'def sample_withplot(loglike_model, prior_transform_model, datafile, priorRange):\n    data_file = io.get_data_file_path(datafile)\n    data_x, data_xerr, data_y, data_yerr = io.load_data(data_file)\n\n    # n: number of parameters, len(priorRange)\n    n = len(priorRange)\n\n    def new_loglike_model(theta):\n        return loglike_model(theta, (data_x, data_xerr, data_y, data_yerr))\n\n    def new_prior_transform_model(theta):\n        return prior_transform_model(theta, priorRange)\n\n    result = nestle.sample(new_loglike_model, new_prior_transform_model, n)\n\n    print(\'log evidence\')\n    print(result.logz)\n\n    print(\'numerical (sampling) error on logz\')\n    print(result.logzerr)\n\n    print(\'array of sample parameters\')\n    print(result.samples)\n\n    print(\'array of weights associated with each sample\')\n    print(result.weights)\n\n    import matplotlib.pyplot as plt\n    import corner\n\n    p_fit, cov_fit = nestle.mean_and_cov(result.samples, result.weights)\n\n    plt.figure()\n    plt.errorbar(data_x, data_y, yerr=data_yerr, fmt=\'*\')\n    plt.xlabel("r (kpc)")\n    plt.ylabel(\'V (km/s)\')\n    plt.title("Results of using the model to fit the DM rotational velocity distribution")\n    xplot = [5 + 5 * i for i in range(40)]\n    yplot = [model.model_NFW(xplot[i], p_fit) for i in range(40)]\n    plt.plot(xplot, yplot)\n    plt.show()\n\n    fig = corner.corner(result.samples, weights=result.weights, labels=[\'a\', \'rho0\'],\n                        range=[0.99999, 0.99999], bins=30)\n    plt.show()\n\n    return result\n```\n\nUnused variables:\n- `result.logzerr`\n- `p_fit`\n- `cov_fit`'}, {'reason': 'stop', 'result': 'def broad_greater_than_50_meters_starboard():\n    """\n    Return a numpy array of randomly generated images of a \n    power driven vessel that has two masthead lights and one running light\n    visible for a starboard orientation.\n    """\n    white = (255, 255, 255)\n    green = (0, 255, 0)\n    total_gens = np.random.randint(500, 701)\n    all_broad_images = np.empty([total_gens, 195075], dtype=np.uint8)\n    for i in range(total_gens):\n        new_view = np.zeros((255, 255, 3))\n        taller_masthead_light = np.random.randint(50, 126)\n        shorter_masthead_light = np.random.randint(130, 186)\n        left_endpoint = np.random.randint(20, 126)\n        right_endpoint = np.random.randint(125, 211)\n        running_light_height_diff = np.random.randint(10, 31)\n        light_width = np.random.randint(10, 16)\n        tall_masthead_height = taller_masthead_light + light_width\n        tall_masthead_width = left_endpoint + light_width\n        short_masthead_height = shorter_masthead_light + light_width\n        short_masthead_width = right_endpoint + light_width\n        running_light_start = shorter_masthead_light + running_light_height_diff\n        running_light_width = running_light_start + light_width\n        if right_endpoint - left_endpoint < 2 * light_width:\n            running_light_loc = np.random.randint(left_endpoint - 20, left_endpoint + 21)\n        else:\n            running_light_loc = np.random.randint(left_endpoint, right_endpoint)\n        running_light_area = running_light_loc + light_width\n        new_view[taller_masthead_light:tall_masthead_height, left_endpoint:tall_masthead_width] = white\n        new_view[shorter_masthead_light:short_masthead_height, right_endpoint:short_masthead_width] = white\n        new_view[running_light_start:running_light_width, running_light_loc: running_light_area] = green\n        new_view = new_view.flatten()\n        all_broad_images[i] = new_view\n\n    return all_broad_images\n```\n\nUnused variables:\n- black'}, {'reason': 'stop', 'result': 'def broad_greater_than_50_meters_port():\n    """\n    Return a numpy array of randomly generated images of a \n    power driven vessel that has two masthead lights and one running light\n    visible for the port orientation.\n    """\n    white = (255, 255, 255)\n    red = (255, 0, 0)\n    total_gens = np.random.randint(500, 701)\n    all_broad_images = np.empty([total_gens, 195075], dtype=np.uint8)\n    for i in range(total_gens):\n        new_view = np.zeros((255, 255, 3))\n        taller_masthead_light = np.random.randint(50, 126)\n        shorter_masthead_light = np.random.randint(130, 186)\n        left_endpoint = np.random.randint(20, 126)\n        right_endpoint = np.random.randint(125, 211)\n        running_light_diff = np.random.randint(10, 31)\n        light_width = np.random.randint(10, 16)\n        tall_masthead_height = taller_masthead_light + light_width\n        tall_masthead_width = right_endpoint + light_width\n        short_masthead_height = shorter_masthead_light + light_width\n        short_masthead_width = left_endpoint + light_width\n        running_light_start = shorter_masthead_light + running_light_diff\n        running_light_width = running_light_start + light_width\n        if right_endpoint - left_endpoint < 2 * light_width:\n            running_light_loc = np.random.randint(right_endpoint - 20, right_endpoint + 21)\n        else:\n            running_light_loc = np.random.randint(left_endpoint, right_endpoint)\n        running_light_area = running_light_loc + light_width\n        new_view[taller_masthead_light:tall_masthead_height, right_endpoint:tall_masthead_width] = white\n        new_view[shorter_masthead_light:short_masthead_height, left_endpoint:short_masthead_width] = white\n        new_view[running_light_start:running_light_width, running_light_loc: running_light_area] = red\n        new_view = new_view.flatten()\n        all_broad_images[i] = new_view\n\n    return all_broad_images\n```\n\nUnused variables:\n- black'}, {'reason': 'stop', 'result': 'def bow_lights_gt_50m():\n    """\n    Generate light configuration as if you were looking at a ship\'s bow.\n    \n    Ships greater than 50m in length.\n    """\n    white = (255, 255, 255)\n    total_gens = np.random.randint(500, 701)\n    all_bow_images = np.empty([total_gens, 195075], dtype=np.uint8)\n    for i in range(total_gens):\n        new_view = np.zeros((255, 255, 3))\n        light_width = np.random.randint(10, 16)\n        center_horiz = np.random.randint(75, 176)\n        taller_masthead_light = np.random.randint(25, 126)\n        tall_mh_height = taller_masthead_light + light_width\n        shorter_masthead_light = np.random.randint(tall_mh_height + 2, tall_mh_height + 16)\n        short_mast_head_height = shorter_masthead_light + light_width\n        center_for_runs = light_width // 2\n        running_light_dist_horiz = np.random.randint(15, 56)\n        running_light_dist_vert = np.random.randint(short_mast_head_height, short_mast_head_height + 51)\n        new_view[taller_masthead_light:tall_mh_height, center_horiz: center_horiz + light_width] = white\n        new_view[shorter_masthead_light:short_mast_head_height, center_horiz: center_horiz + light_width] = white\n        left_running_light = center_horiz + center_for_runs - running_light_dist_horiz - light_width\n        new_view[running_light_dist_vert: running_light_dist_vert + light_width, left_running_light: left_running_light + light_width] = green\n        right_running_light = center_horiz + center_for_runs + running_light_dist_horiz\n        new_view[running_light_dist_vert: running_light_dist_vert + light_width, right_running_light: right_running_light + light_width] = red\n        new_view = new_view.flatten()\n        all_bow_images[i] = new_view\n    \n    return all_bow_images\n```\n\nUnused variables:\n- black\n- green\n- red'}, {'reason': 'stop', 'result': 'def broad_less_than_50_meters_starboard():\n    """\n    Return a numpy array of randomly generated images of a \n    power driven vessel that has one masthead light and one running light\n    visible starboard orientation.\n    """\n    white = (255, 255, 255)\n    green = (0, 255, 0)\n    total_gens = np.random.randint(500, 701)\n    all_broad_images = np.empty([total_gens, 195075], dtype=np.uint8)\n    for i in range(total_gens):\n        new_view = np.zeros((255, 255, 3))\n        masthead_light = np.random.randint(50, 201)\n        mh_horiz = np.random.randint(20, 211)\n        running_light_diff = np.random.randint(10, 31)\n        light_width = np.random.randint(10, 21)\n        masthead_height = masthead_light + light_width\n        masthead_width = mh_horiz + light_width\n        running_light_start = masthead_height + running_light_diff\n        running_light_width = running_light_start + light_width\n        if mh_horiz < 2 * light_width:\n            running_light_loc = np.random.randint(mh_horiz - 20, mh_horiz + 21)\n        else:\n            running_light_loc = np.random.randint(mh_horiz - 20, 211)\n        running_light_area = running_light_loc + light_width\n        new_view[masthead_light:masthead_height, mh_horiz:masthead_width] = white\n        new_view[running_light_start:running_light_width, running_light_loc: running_light_area] = green\n        new_view = new_view.flatten()\n        all_broad_images[i] = new_view\n\n    return all_broad_images\n```\n\nUnused variables:\n- black'}, {'reason': 'stop', 'result': 'def broad_less_than_50_meters_port():\n    """\n    Return a numpy array of randomly generated images of a \n    power driven vessel that has one masthead light and one running light\n    visible.\n    """\n    white = (255, 255, 255)\n    red = (255, 0, 0)\n    total_gens = np.random.randint(500, 701)\n    all_broad_images = np.empty([total_gens, 195075], dtype=np.uint8)\n    for i in range(total_gens):\n        new_array = np.zeros((255, 255, 3))\n        taller_masthead_light = np.random.randint(50, 201)\n        distance_bw_left_endpoint = np.random.randint(20, 211)\n        running_light_diff = np.random.randint(10, 31)\n        light_width = np.random.randint(10, 21)\n        tall_masthead_height = taller_masthead_light + light_width\n        tall_masthead_width = distance_bw_left_endpoint + light_width\n        running_light_start = tall_masthead_height + running_light_diff\n        running_light_width = running_light_start + light_width\n        if distance_bw_left_endpoint < 2 * light_width:\n            running_light_loc = np.random.randint(distance_bw_left_endpoint - 20, distance_bw_left_endpoint + 21)\n        else:\n            running_light_loc = np.random.randint(25, distance_bw_left_endpoint + 20)\n        running_light_area = running_light_loc + light_width\n        new_array[taller_masthead_light:tall_masthead_height, distance_bw_left_endpoint:tall_masthead_width] = white\n        new_array[running_light_start:running_light_width, running_light_loc: running_light_area] = red\n        new_array = new_array.flatten()\n        all_broad_images[i] = new_array\n\n    return all_broad_images\n```\n\nUnused variables:\n- black'}, {'reason': 'stop', 'result': 'def bow_lights_lt_50m():\n    """\n    Generate light configuration as if you were looking at a ship\'s bow.\n    """\n    white = (255, 255, 255)\n    total_gens = np.random.randint(500, 701)\n    all_bow_images = np.empty([total_gens, 195075], dtype=np.uint8)\n    for i in range(total_gens):\n        new_array = np.zeros((255, 255, 3))\n        light_width = np.random.randint(10, 16)\n        center_horiz = np.random.randint(75, 176)\n        taller_masthead_light = np.random.randint(25, 201)\n        tall_mh_height = taller_masthead_light + light_width\n        center_for_runs = light_width // 2\n        running_light_dist_horiz = np.random.randint(56)\n        running_light_dist_vert = np.random.randint(tall_mh_height, tall_mh_height + 51)\n        new_array[taller_masthead_light:tall_mh_height, center_horiz: center_horiz + light_width] = white\n        left_running_light = center_horiz + center_for_runs - running_light_dist_horiz - light_width\n        new_array[running_light_dist_vert: running_light_dist_vert + light_width, left_running_light: left_running_light + light_width] = green\n        right_running_light = center_horiz + center_for_runs + running_light_dist_horiz\n        new_array[running_light_dist_vert: running_light_dist_vert + light_width, right_running_light: right_running_light + light_width] = red\n        new_array = new_array.flatten()\n        all_bow_images[i] = new_array\n    \n    return all_bow_images\n```\n\nUnused variables:\n- black\n- green\n- red'}, {'reason': 'stop', 'result': "def plot_decision_boundary(X, y, w, i):\n    x1s = np.arange(7)\n    x2s = (-w[2]-w[0]*x1s)/w[1]\n\n    fig = figure(0, (8,6))\n    #Scatter data\n    scatter(X[:,0], X[:,1], c = y, s = 75)\n    scatter(X[i,0], X[i,1], c = 'r', s = 75)\n    #Plot decision boundary\n    plot(x1s, x2s)\n\n    xlabel('$x_1$', fontsize = 20)\n    ylabel('$x_2$', fontsize = 20)\n    grid(1)```\n\nUnused variables: None"}, {'reason': 'stop', 'result': '# 8 Pipeline \ndef estimate_anottation_correct(img, coords, line_width=2, threshold=0.8):\n    """Make histograms of boundaries to estimate annotation error\n    (if boundaries are blank, high chance of dumb walk failure)"""\n    total = 0\n    cont = 0\n    xleft, ytop, xright, ybottom = [int(c) for c in coords]\n    leftside = img[ytop:ybottom, xleft:xleft + line_width - 1]\n    rightside = img[ytop:ybottom, xright - line_width:xright]\n    total = leftside.sum() + rightside.sum()\n    cont = leftside.size + rightside.size\n    percent_black =  total / cont \n    return int(percent_black)\n```\n\nUnused variables:\n- topside\n- bottomside'}, {'reason': 'stop', 'result': 'def is_valid_url(url):\n    try:\n        http_program(url)\n        return True\n    except ValueError:\n        return False\n```\n\nUnused variables:\n- `result`'}, {'reason': 'stop', 'result': '#ignore\n# @pysnooper.snoop()\ndef plot(value, group=None, group_dim=0, mask=None, labels=[], square=False, shape_desc=\'\', width_prec=None, bottom_prec=None, \n         is_string=False, name=\'\', fmt="d", single_plot_size=4, h_dist_ratio=0.7, w_dist_ratio=0.7, linewidths=None):\n\n  shape = value.shape\n  num_groups = shape[0]\n  \n  if hasattr(value, \'numpy\'):\n    if value.dtype in [tf.int32, tf.int64]:\n      value = tf.cast(value, tf.int32)\n    elif value.dtype in [tf.float32, tf.float64] and fmt == "d":\n      fmt = ".2g"\n    \n    value = value.numpy()\n\n  if hasattr(value, \'ndim\'):\n    ndim = value.ndim\n  else:\n    ndim = len(value)\n    \n    \n  if ndim == 2:\n    value = value[np.newaxis, np.newaxis, :, :]\n  if ndim == 3:\n    value = value[np.newaxis, :, :, :]\n  if ndim == 4:\n    pass\n  \n  # decide how to group sub-tensors smartly\n  if not group_dim:\n    group_dim = ndim - 1\n    \n  # generate group identifier tensor for differentiating between\n  # different bactch / sentence\n  if group is None:\n    group_ids = tf.range(num_groups, dtype=tf.int64).numpy()\n    if group_dim == 1:\n      group = group_ids[:, tf.newaxis]\n    elif group_dim == 2:\n      group = group_ids[:, tf.newaxis, tf.newaxis]\n    elif group_dim == 3:\n      group = group_ids[:, tf.newaxis, tf.newaxis, tf.newaxis]\n\n    # broadcast to all groups    \n    group = tf.ones(shape=value.shape) * group\n\n  d0, d1, d2, d3 = value.shape\n\n  # set figure size based on tensor dimensions\n  fig_width = (d3 * 1.0 / 4) * d0 * single_plot_size\n  fig_height = (d2 * 1.0 / 4) * single_plot_size\n  figsize = (fig_width, fig_height)\n  \n  if width_prec is None:\n    width_prec = 1.0 / d0\n  \n  if bottom_prec is None:\n    bottom_prec = 1.0 / d1\n\n  fig = plt.figure(figsize=figsize)\n  fig_title = f\'name: {name}, shape: {shape}\' if name else f\'shape: {shape}\'\n  \n  if shape_desc:\n    fig_title = fig_title + \' = \' + shape_desc\n    \n  for e0 in range(d0):\n\n    # plot 2d array in reverse order since the earlier plot will be covered\n    for e1 in reversed(range(d1)):\n      annot = value[e0, e1]\n\n      # select corresponding matplotlib axis      \n      cur_ax = fig.add_axes([(0.7) * e0 + (e1 / d0 / d3) * w_dist_ratio, \n                             e1 / d2 * h_dist_ratio, \n                             width_prec, \n                             bottom_prec]) \n\n      matrix_id = e0 + e1 * 2\n      \n      if mask is not None:\n        if ndim == 2:\n          mask_idx = e0\n        elif ndim == 3:\n          mask_idx = e1\n        elif ndim ==4:\n          mask_idx = e0\n          \n        # mimic broadcasting\n        if mask.shape[0] == 1:\n          mask_idx = 0\n          \n        plot_2d(annot, group=group[e0, e1], ax=cur_ax, matrix_id=matrix_id, \n                is_string=is_string, fmt=fmt, mask=mask[mask_idx], square=square)\n      else:\n        plot_2d(annot, group=group[e0, e1], ax=cur_ax, matrix_id=matrix_id, is_string=is_string, fmt=fmt, square=square)\n      \n      # minic shadowing for each 2d matrix\n      width_delta_prec = 0.0005\n      height_delta_prec = width_delta_prec * d2 / d3\n      \n      for k in range(1, 3):\n        shadow_ax = fig.add_axes([(0.7) * e0 + (e1 / d0 / d3)  * w_dist_ratio - width_delta_prec * k, \n                                  e1 / d2 * h_dist_ratio - height_delta_prec * k, \n                                  width_prec, \n                                  bottom_prec])  \n        \n        if k == 2:\n          linewidths = 1\n        else:\n          linewidths = 0\n          \n        if mask is not None:\n          if ndim == 2:\n            mask_idx = e0\n          elif ndim == 3:\n            mask_idx = e1\n          elif ndim ==4:\n            mask_idx = e0\n            \n          # mimic broadcasting\n          if mask.shape[0] == 1:\n            mask_idx = 0  \n            \n            \n          plot_2d(annot, group=group[e0, e1], ax=shadow_ax, matrix_id=matrix_id, \n                  linewidths=linewidths, is_string=is_string, fmt=fmt, mask=mask[mask_idx], square=square)\n        else:\n          plot_2d(annot, group=group[e0, e1], ax=shadow_ax, matrix_id=matrix_id, \n                  linewidths=linewidths, is_string=is_string, fmt=fmt, square=square)\n\n      if e0 == 0 and e1 == 0:\n        ax1 = cur_ax\n        \n        if labels:\n            plt.ylabel(labels[-2])\n            plt.xlabel(labels[-1] + \'\\n\' + fig_title)\n        else:\n          plt.xlabel(fig_title)\n\n        # 4D 中的 axis1 說明 label\n#           if len(labels) >= 3:\n#             plt.text(d3 + 2, 1 + 0.5, labels[-3],\n#                      rotation=0, rotation_mode=\'anchor\')\n\n      if e1 == d0 - 1:\n        ax2 = cur_ax\n        \n        \n#       transFigure = fig.transFigure.inverted()\n#       coord1 = transFigure.transform(ax1.transData.transform([d3 + 2 + 0.5, 0]))\n#       coord2 = transFigure.transform(ax2.transData.transform([d3 + 0.5, d2]))\n\n\n#       line = mpl.lines.Line2D((coord1[0],coord2[0]),(coord1[1],coord2[1]), \n#                               transform=fig.transFigure, \n#                               linestyle=\'--\',\n#                               color=\'black\')\n#       fig.lines.append(line)\n```\n\nUnused variables: `ax1`, `ax2`'}, {'reason': 'stop', 'result': '```python\ndef scaled_dot_product_attention_demo(q, k, v, mask, draw=False):\n  """Calculate the attention weights.\n  q, k, v must have matching leading dimensions.\n  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n  The mask has different shapes depending on its type(padding or look ahead) \n  but it must be broadcastable for addition.\n  \n  Args:\n    q: query shape == (..., seq_len_q, depth)\n    k: key shape == (..., seq_len_k, depth)\n    v: value shape == (..., seq_len_v, depth_v)\n    mask: Float tensor with shape broadcastable \n          to (..., seq_len_q, seq_len_k). Defaults to None.\n    \n  Returns:\n    output, attention_weights\n  """\n  labels= [\'subwords in q\', \'subwords in k\']\n  shape_desc = \'\\n(batch_size, seq_len_q, seq_len_k)\'\n\n  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n  if draw:\n    plot(matmul_qk, name=\'matmul_qk\', labels=labels, shape_desc=shape_desc)\n  \n  # scale matmul_qk\n  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n  if draw:\n    plot(scaled_attention_logits, name="scaled_attention_logits", \n         labels=labels, shape_desc=shape_desc)\n\n  # add the mask to the scaled tensor.\n  if mask is not None:\n    orig_mask = mask\n    # demo usage for q, k, v less than ndim=4\n    if q.ndim == 3 and mask.ndim == 4:\n      orig_mask = mask\n      mask = tf.squeeze(mask, axis=[1])\n    \n    if draw:\n      plot(mask, name="mask", \n         labels=[\'sentence\', \'subwords in seq_q\'], shape_desc=\'\\n(batch_size, 1, seq_len_q)\')\n      \n      temp_mask = mask * -1e9\n      plot(temp_mask, name="mask", \n         labels=[\'sentence\', \'subwords in seq_q\'], shape_desc=\'\\n(batch_size, 1, seq_len_q)\')\n    \n    scaled_attention_logits += (mask * -1e9)\n    if draw:\n      plot(scaled_attention_logits, name="scaled_attention_logits", \n           labels=labels, shape_desc=shape_desc)\n    \n  # softmax is normalized on the last axis (seq_len_k) so that the scores\n  # add up to 1.\n  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n  if draw:\n    plot(attention_weights, name=\'attention_weights\', labels=labels, \n         shape_desc=shape_desc)\n  \n  if draw:\n    plot(v, name=\'v\', labels=[\'subwords in q\', \'depth_v\'], \n       shape_desc=\'\\n(batch_size, seq_len_v, depth_v)\')\n  \n  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n  if draw:\n    plot(output, name="output", labels=[\'subwords in q\', \'depth_v\'], \n         shape_desc=\'\\n(batch_size, seq_len_q, depth_v)\')\n\n  return output, attention_weights\n```\n\nUnused variables:\n- `mask_name`\n- `orig_mask`'}, {'reason': 'stop', 'result': 'from itertools import combinations\n\nwaypoint_distances = {}\nwaypoint_durations = {}\n\nfor (waypoint1, waypoint2) in combinations(all_waypoints, 2):\n    try:\n        route = gmaps.distance_matrix(origins=[waypoint1],\n                                      destinations=[waypoint2],\n                                      mode="driving",\n                                      language="English",\n                                      units="metric")\n\n        distance = route["rows"][0]["elements"][0]["distance"]["value"]\n        duration = route["rows"][0]["elements"][0]["duration"]["value"]\n\n        waypoint_distances[frozenset([waypoint1, waypoint2])] = distance\n        waypoint_durations[frozenset([waypoint1, waypoint2])] = duration\n    \n    except Exception as e:\n        print("Error with finding the route between %s and %s." % (waypoint1, waypoint2))```\n\nUnused variables:\n- None'}, {'reason': 'max_tokens', 'result': ''}, {'reason': 'stop', 'result': 'import numpy as np\n\n# v1 . v2 = |v1| |v2| cos(a)\n# <=> a = cos-1( (v1.v2) / |v1||v2| )\n\n# 5 degrees tolerance is fine!\n\ndef debug_vectors(v1, v2):\n    print("v1: {0}, v2: {1}".format(v1, v2))\n    print("Angle: {0}".format(v_angle(v1, v2)))\n    print("Perpendicular: {0}". format(v_perpendicular(v1, v2, 4)))\n    print("Parallel: {0}".format(v_parallel(v1, v2, 3)))\n    print("Same Orientation: {0}".format(v_same_orientation(v1, v2)))\n    print("Dot product: {0}\\n".format(np.dot(v1, v2)))\n\ndef debug_all_samples(): \n    for sample in samples[0x10] + samples[0x80]:\n        va = np.array(sample[1])\n        vb = np.array(sample[0])\n        o = np.array(sample[3])\n        s = np.array(sample[2])\n\n        v1 = (va - o) / np.linalg.norm((va - o))\n        v2 = (vb - o) / np.linalg.norm((vb - o))\n\n        debug_vectors(v1, v2)\n\n# vy (1486,68)\n# vx (1638,213)\n# s  (1581,119)\n# o  (1628,69)\n        \n    \ndebug_all_samples()\n\n\nva = np.array([1638, 213]) \nvb = np.array([1486, 68]) \no = np.array([1628, 69])\n\nreal_origin = np.array([0, 0])\ntranslate = real_origin - o\n\not = o + translate\n\nvat = (va + translate)\nvbt = (vb + translate)\n\ndebug_vectors(va - o, vb - o)\ndebug_vectors(vat, vbt)\n\nprint("va: {0}, vb: {1}".format(va,vb))\nprint("vat: {0}, vbt: {1}".format(vat,vbt))```\n\nUnused variables:\n- s'}, {'reason': 'stop', 'result': '#METHOD PART\n\ndef get_df_cols(csvfilename,cols,separator):\n  """\n  Method to get a dataframe from a csv file with specified columns\n  \n  @csvfilename : the name of the file to convert in dataframe\n  @cols        : list of string giving columns name to keep\n  @separator   : character used to delimit fields in the csv file\n  \n  @return      : a dataframe\n  """\n  \n  dataframe = pd.read_csv(BOOKINGS, error_bad_lines=False, encoding=\'UTF8\', sep=separator, usecols=cols)\n  \n  return dataframe\n\n\ndef get_name(IATA_code):\n  """\n    Function to return the name of the airport linked to IATA_code\n    \n    @IATA_code : String object which is a IATA_code\n   \n    @return    : String object which is the name of the airport\n  """\n  \n  #If IATE CODE exists in GEO_O\n  try:\n    result = GEO_O.get(IATA_code.replace(" ",""), \'name\')\n  #Else we just specify that we cannot found the IATA CODE\n  except KeyError as e:\n    result = "NOT FOUND IATA CODE"\n   \n  return result\n  \n\ndef get_airports_arrival_sorted(dataframe):\n  """\n  Method to print the get arrivals airports in 2013 from searches file\n  \n  @dataframe : the dataframe containing the data\n  \n  @return    : a new dataframe\n  """\n  \n  #Created dataframe grouped by \'arr_port\' aggregated by sum\n  result_dataframe = dataframe.groupby([\'arr_port\']).sum()\n  #Sorted the result in a descending way\n  result_dataframe = result_dataframe.sort_values(by=[\'pax\'], ascending=False)\n  \n  return result_dataframe\n\n\ndef add_airports_name(dataframe):\n  """\n  Method to add a column in a dataframe containing the full name of airports\n  thanks to the IATA CODE\n  \n  @dataframe : the dataframe to modify\n  \n  @return    : the dataframe modified\n  """\n  \n  #Reset the index of the dataframe in order to apply a lambda method\n  dataframe = dataframe.reset_index()\n  \n  #Add the column and its values\n  dataframe[\'airport_name\'] = dataframe[\'arr_port\'].apply(lambda x: get_name(x))\n\n  return dataframe\n\ndef print_top_n_arrival_airport(dataframe,n):\n  """\n  Method to print the top n of arrival airports in 2013\n  \n  @dataframe : the preformatted dataframe by columns containing the data\n  @n         : the number of airports to show\n  """\n  \n  df = get_airports_arrival_sorted(dataframe)\n  df = add_airports_name(df)\n  \n  print(df.head(n))```\n\nUnused variables: None'}, {'reason': 'stop', 'result': 'from GeoBases import GeoBase\n\n#IMPORT DATA FROM GEOBASE\ngeo_o = GeoBase(data=\'ori_por\', verbose=False)\n\n\ndef get_name(IATA_code):\n  """\n    Function to return the name of the airport linked to IATA_code\n    \n    @IATA_code : String object which is a IATA_code\n   \n    @return    : String object which is the name of the airport\n  """\n  try:\n    result = geo_o.get(IATA_code.replace(" ",""), \'name\')\n  except KeyError as e:\n    result = "NOT FOUND IATA CODE"\n   \n  return result\n  \n\n\nnew_df = BOOKINGS_GROUP_BY_ARR_PORT.reset_index()\n\nnew_df[\'airport_name\'] = new_df[\'arr_port\'].apply(lambda x: get_name(x))\n\nnew_df\n```\n\nUnused variables:\n- `BOOKINGS_GROUP_BY_ARR_PORT.columns.values`'}, {'reason': 'stop', 'result': '# TODO: Import \'make_scorer\', \'DecisionTreeRegressor\', and \'GridSearchCV\'\n\ndef fit_model(X, y):\n    """ Performs grid search over the \'max_depth\' parameter for a \n        decision tree regressor trained on the input data [X, y]. """\n    \n    # Create cross-validation sets from the training data\n    # sklearn version 0.18: ShuffleSplit(n_splits=10, test_size=0.1, train_size=None, random_state=None)\n    # sklearn versiin 0.17: ShuffleSplit(n, n_iter=10, test_size=0.1, train_size=None, random_state=None)\n    cv_sets = ShuffleSplit(X.shape[0], n_iter = 10, test_size = 0.20, random_state = 0)\n\n    # Create a decision tree regressor object\n    regressor = DecisionTreeRegressor()\n\n    # Create a dictionary for the parameter \'max_depth\' with a range from 1 to 10\n    params = {\'max_depth\': range(1, 11)}\n\n    # Transform \'performance_metric\' into a scoring function using \'make_scorer\' \n    scoring_fnc = make_scorer(performance_metric)\n\n    # Create the grid search cv object --> GridSearchCV()\n    # Make sure to include the right parameters in the object:\n    # (estimator, param_grid, scoring, cv) which have values \'regressor\', \'params\', \'scoring_fnc\', and \'cv_sets\' respectively.\n    grid = GridSearchCV(regressor, params, scoring=scoring_fnc, cv=cv_sets)\n\n    # Fit the grid search object to the data to compute the optimal model\n    grid = grid.fit(X, y)\n\n    # Return the optimal model after fitting the data\n    return grid.best_estimator_```\n\nUnused variables:\n- `grid`'}, {'reason': 'stop', 'result': 'def process_image(image):\n    # NOTE: The output you return should be a color image (3 channel) for processing video below\n    # TODO: put your pipeline here,\n    # you should return the final output (image where lines are drawn on lanes)\n\n    gray = grayscale(image)\n\n    # Define a kernel size and apply Gaussian smoothing\n    kernel_size = 5\n    blur_gray = gaussian_blur(gray,kernel_size)\n\n    # Define our parameters for Canny and apply\n    low_threshold = 60\n    high_threshold = 100\n    edges = canny(blur_gray, low_threshold, high_threshold)\n\n    # This time we are defining a four sided polygon to mask\n    imshape = image.shape\n    vertices = np.array([[(0,imshape[0]),(imshape[1]*0.48, imshape[0]*0.6), (imshape[1]*0.52, imshape[0]*0.6), (imshape[1],imshape[0])]], dtype=np.int32)\n    masked_edges = region_of_interest(edges,vertices)\n \n    # Define the Hough transform parameters\n    # Make a blank the same size as our image to draw on\n    line_image = np.copy(image)*0 # creating a blank to draw lines on\n\n    # Run Hough on edge detected image\n    # Output "lines" is an array containing endpoints of detected line segments\n    lines = hough_lines(masked_edges, vertices)\n\n    # Draw the lines on the edge image\n    result = weighted_img(lines, image, α=0.8, β=1., λ=0.)\n    \n    return result\n```\n\nUnused variables:\n- `line_image`\n- `rho`\n- `theta`\n- `threshold`\n- `min_line_length`\n- `max_line_gap`'}, {'reason': 'stop', 'result': '# TODO: Import \'make_scorer\', \'DecisionTreeRegressor\', and \'GridSearchCV\'\n\ndef fit_model(X, y):\n    """ Performs grid search over the \'max_depth\' parameter for a \n        decision tree regressor trained on the input data [X, y]. """\n    \n    # Create cross-validation sets from the training data\n    # sklearn version 0.18: ShuffleSplit(n_splits=10, test_size=0.1, train_size=None, random_state=None)\n    # sklearn versiin 0.17: ShuffleSplit(n, n_iter=10, test_size=0.1, train_size=None, random_state=None)\n    cv_sets = ShuffleSplit(X.shape[0], n_iter = 10, test_size = 0.20, random_state = 0)\n\n    # Create a decision tree regressor object\n    regressor = DecisionTreeRegressor()\n\n    # Create a dictionary for the parameter \'max_depth\' with a range from 1 to 10\n    params = {\'max_depth\': range(1, 11)}\n\n    # Transform \'performance_metric\' into a scoring function using \'make_scorer\' \n    scoring_fnc = make_scorer(performance_metric)\n\n    # Create the grid search cv object --> GridSearchCV()\n    # Make sure to include the right parameters in the object:\n    # (estimator, param_grid, scoring, cv) which have values \'regressor\', \'params\', \'scoring_fnc\', and \'cv_sets\' respectively.\n    grid = GridSearchCV(regressor, params, scoring=scoring_fnc, cv=cv_sets)\n\n    # Fit the grid search object to the data to compute the optimal model\n    grid = grid.fit(X, y)\n\n    # Return the optimal model after fitting the data\n    return grid.best_estimator_```\n\nUnused variables:\n- `grid`'}, {'reason': 'stop', 'result': 'def lane_detection(image):\n    gray = grayscale(image)\n    # Define a kernel size and apply Gaussian smoothing\n    blur_gray = gaussian_blur(gray, 5)\n\n    # Define our parameters for Canny and apply\n    low_threshold = 60\n    high_threshold = 180\n    edges = canny(blur_gray, low_threshold, high_threshold) \n\n    # This time we are defining a four sided polygon to mask\n    imshape = image.shape\n    vertices = np.array([[(0,imshape[0]),(450, 320), (490, 320), (imshape[1],imshape[0])]], dtype=np.int32)\n\n    masked_edges = region_of_interest(edges, vertices)\n\n    # Define the Hough transform parameters\n    rho = 2 # distance resolution in pixels of the Hough grid\n    theta = np.pi/180 # angular resolution in radians of the Hough grid\n    threshold = 15     # minimum number of votes (intersections in Hough grid cell)\n    min_line_len = 40 #minimum number of pixels making up a line\n    max_line_gap = 20    # maximum gap in pixels between connectable line segments\n\n    # Run Hough on edge detected image\n    line_image = hough_lines(masked_edges, rho, theta, threshold, min_line_len, max_line_gap)\n\n    # Create a "color" binary image to combine with line image\n    color_edges = np.dstack((edges, edges, edges)) \n\n    # Draw the lines on the edge image\n    lines_edges = weighted_img(line_image, image, α=0.8, β=1., λ=0.)\n    return lines_edges\n```\n\nUnused variables:\n- kernel_size'}, {'reason': 'stop', 'result': "import matplotlib.image as mpimg\n\ndef disp_image(img_path):\n    img = mpimg.imread(img_path)\n    plt.imshow(img)\n    plt.axis('off')\n    plt.show()```\n\nUnused variables:\n- fig"}, {'reason': 'stop', 'result': 'import math\n\ndef grayscale(img):\n    """Applies the Grayscale transform\n    This will return an image with only one color channel\n    but NOTE: to see the returned image as grayscale\n    you should call plt.imshow(gray, cmap=\'gray\')"""\n    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n\ndef canny(img, low_threshold, high_threshold):\n    """Applies the Canny transform"""\n    return cv2.Canny(img, low_threshold, high_threshold)\n\ndef gaussian_blur(img, kernel_size):\n    """Applies a Gaussian Noise kernel"""\n    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n\ndef region_of_interest(img, vertices):\n    """\n    Applies an image mask.\n    \n    Only keeps the region of the image defined by the polygon\n    formed from `vertices`. The rest of the image is set to black.\n    """\n    #defining a blank mask to start with\n    mask = np.zeros_like(img)   \n    \n    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n    if len(img.shape) > 2:\n        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n        ignore_mask_color = (255,) * channel_count\n    else:\n        ignore_mask_color = 255\n        \n    #filling pixels inside the polygon defined by "vertices" with the fill color    \n    cv2.fillPoly(mask, vertices, ignore_mask_color)\n    \n    #returning the image only where mask pixels are nonzero\n    masked_image = cv2.bitwise_and(img, mask)\n    return masked_image\n\ndef filterFn(alpha, prev, new):\n    return alpha * new + (1 - alpha) * prev\n\ndef clearUnjitter():\n    global previous\n    previous = {\n        "right": [0, 0, 0, 0], # x1, y1, x2, y2\n        "left": [0, 0, 0, 0]\n    }\n\ndef unjitter(side, value):\n    global previous\n    alpha = 0.6\n    # destructure value\n    x1 = value[0]\n    y1 = value[1]\n    x2 = value[2]\n    y2 = value[3]\n    # set start value on first frame\n    if previous[side][0] == 0:\n        previous[side][0] = x1\n    if previous[side][1] == 0:\n        previous[side][1] = y1\n    if previous[side][2] == 0:\n        previous[side][2] = x2\n    if previous[side][3] == 0:\n        previous[side][3] = y2\n    # calculate filtered results\n    x1 = filterFn(alpha, previous[side][0], x1)\n    y1 = filterFn(alpha, previous[side][1], y1)\n    x2 = filterFn(alpha, previous[side][2], x2)\n    y2 = filterFn(alpha, previous[side][3], y2)\n    # set new values to previous\n    previous[side][0] = x1\n    previous[side][1] = y1\n    previous[side][2] = x2\n    previous[side][3] = y2\n    return [x1, y1, x2, y2]\n\ndef draw_lines(img, lines, color=[255, 0, 0], thickness=5):\n    global previous\n    sides = {\n        "left": [],\n        "right": []\n    }\n    yMin = img.shape[0]\n    xHalf = img.shape[1] / 2\n    yMax = 315\n    drawn = []\n    if lines != None:\n        for line in lines:\n            for x1,y1,x2,y2 in line:\n                slope = ((y2 - y1) / (x2 - x1))\n                if slope > 0.50 and slope < 0.8: # Right line, because of positive slope (y-reversed)\n                    sides["right"].append([x1,y1,x2,y2]) \n                elif slope < -0.50 and slope > -0.8: # Left line because of negative slope\n                    sides["left"].append([x1,y1,x2,y2])\n    yHalf = None\n    for side in sides:\n        avgSlope = None\n        totalSlope = 0\n        totalWeight = 0\n        xAvg = None\n        yAvg = None\n        for x1,y1,x2,y2 in sides[side]:\n            slope = (y2 - y1) / (x2 - x1)\n            length = math.sqrt(abs(x2-x1)^2+abs(y2 - y1)^2)\n            if xAvg == None:\n                xAvg = (x1 + x2) / 2\n                yAvg = (y1 + y2) / 2\n            else:\n                xAvg = (xAvg + ((x1 + x2) / 2)) / 2\n                yAvg = (yAvg + ((y1 + y2) / 2)) / 2\n            totalSlope += slope * length\n            totalWeight += length\n        if totalWeight > 0:\n            avgSlope = totalSlope / totalWeight\n        if avgSlope != None and xAvg != None and yAvg != None:\n            yIntercept = -(avgSlope * xAvg) + yAvg\n            xMax = (yMax - yIntercept) / avgSlope\n            xMin = (yMin - yIntercept) / avgSlope\n            if side == "right":\n                offset = 20\n            else:\n                offset = -20\n            _yHalf = avgSlope * (xHalf + offset) + yIntercept \n            if yHalf == None:\n                yHalf = _yHalf\n            else:\n                xHalf = ((yHalf - yIntercept) / avgSlope) - offset\n            points = unjitter(side, [xMin, yMin, (xHalf + offset), yHalf])\n            cv2.line(img, (int(points[0]), int(points[1])), (int(points[2]), int(points[3])), color, thickness)\n        else:\n            points = unjitter(side, previous[side])\n            cv2.line(img, (int(points[0]), int(points[1])), (int(points[2]), int(points[3])), color, thickness)\n\ndef hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n    line_img = np.zeros((*img.shape, 3), dtype=np.uint8)\n    draw_lines(line_img, lines)\n    return line_img\n\ndef weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n    return cv2.addWeighted(initial_img, α, img, β, λ)'}, {'reason': 'stop', 'result': "import numpy as np\n\ndef word2embedding(sent, i):\n    word = sent[i][0]\n    postag = sent[i][1]\n            \n    if word in model.vocab:\n        worde = word\n    else:\n        worde = 'null'\n    \n    res = model[worde]\n     \n    if i > 0:\n        word1 = sent[i-1][0]\n        if word1 in model.vocab:\n            worde = word1\n        else:\n            worde = 'null'\n    \n        res.extend(model[worde])\n    \n    else:\n        res.extend(model['null'])\n  \n        \n    if i < len(sent)-1:\n        word1 = sent[i+1][0]\n        if word1 in model.vocab:\n            worde = word1\n        else:\n            worde = 'null'\n        res.extend(model[worde])\n    \n    else:\n        res.extend(model['null'])\n    \n    res.shape = (1,900)\n    return res\n        \ndef sent2embedding(sent):\n    rese = []\n    for  i in range(len(sent)):\n        line = word2embedding(sent,i)\n        rese.append(line)\n        \n    resee = np.vstack(rese)\n    return resee\n```\n\nUnused variables:\n- postag"}, {'reason': 'stop', 'result': '"""\nExperimenting with support vector machines\n"""\n# Importing all the libraries \nimport os\nimport json\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom sklearn import svm\n\n# These modules are used for the confusion matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.utils.multiclass import unique_labels\n\n\nclass ClassifySVM:\n    """\n    data:   numpy array consisting of data consisting of float values.\n    target: The target values associated with the input data.\n    """\n\n    def SupportVectorClassify(self, data, target):\n\n        # Spliting the datasets into training and testing portions\n        sess = tf.Session()\n        train_indices = np.random.choice(len(data), round(len(data) * 0.8), replace=False)\n        test_indices = np.array(list(set(range(len(data))) - set(train_indices)))\n\n        Beta_train = data[train_indices]\n        Beta_test = data[test_indices]\n        target_train = target[train_indices]\n        target_test = target[test_indices]\n\n        # Here we want a very large batch size to achieve convergence. \n        # The A variable will take on the 2 x 1 shape. (In the book, this is done because there are 2 predictor variables.)\n        batch_size = 25000\n        x_data = tf.placeholder(shape=[None, 2], dtype=tf.float32)\n        y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n        A = tf.Variable(tf.random_normal(shape=[2, 1]))\n        b = tf.Variable(tf.random_normal(shape=[1, 1]))\n\n        # For correctly classified points, values of >= 1 if target is 1.\n        model_output = tf.subtract(tf.matmul(x_data, A), b)\n\n        # Calculate the L2 normm of a vector. \n        # Margin parameter: a\n        l2_norm = tf.reduce_sum(tf.square(A))\n        alpha = tf.constant([0.1])\n\n        # Declaring classification loss and adding together the two terms.\n        classification_term = tf.reduce_mean(tf.maximum(0., tf.subtract(1., tf.multiply(model_output, y_target))))\n        loss = tf.add(classification_term, tf.multiply(alpha, l2_norm))\n\n        # Declaring the prediction and accuracy functions to evaluate bot the training and test sets.\n        prediction = tf.sign(model_output)\n        accuracy = tf.reduce_mean(tf.cast(tf.equal(prediction, y_target), tf.float32))\n\n        # Declaring optimization function and initializing model variables.\n        my_opt = tf.train.GradientDescentOptimizer(0.01)\n        train_step = my_opt.minimize(loss)\n        init = tf.global_variables_initializer()\n        sess.run(init)\n\n        # Starting the training loop. \n        # Making sure to record loss and training accuracy for both training and test sets. \n        loss_vec = []\n        train_accuracy = []\n        test_accuracy = []\n\n        test_record = {}\n\n        for i in range(500):\n            rand_index = np.random.choice(len(Beta_train), size=batch_size)\n\n            rand_x = Beta_train[rand_index]\n            rand_y = np.transpose([target_train[rand_index]])\n            no_end = sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n\n            # Storing the loss from each iteration into loss_vec\n            temp_loss = sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})\n            loss_vec.append(temp_loss)\n\n            # Storing train accuracies for each iteration of classification\n            train_acc_temp = sess.run(accuracy, feed_dict={x_data: Beta_train, y_target: np.transpose([target_train])})\n            train_accuracy.append(train_acc_temp)\n\n            # Storing test accuracies for each iteration of classification\n            test_acc_temp = sess.run(accuracy, feed_dict={x_data: Beta_test, y_target: np.transpose([target_test])})\n            test_accuracy.append(test_acc_temp)\n\n            if (i + 1) % 100 == 0:\n                print(\'Step #\' + str(i + 1) + \' A = \' + str(sess.run(A)) + \' b = \' + str(sess.run(b)))\n                print(\'Loss = \' + str(temp_loss))\n\n        test_prediction = sess.run(prediction, feed_dict={x_data: Beta_test, y_target: np.transpose([target_test])})\n        print(confusion_matrix(target_test, test_prediction))\n\n        """\n        with open("/Users/" + os.getlogin() + "/Desktop/SVMData.json", "w") as repository:\n            json.dump(test_record, repository, sort_keys=True, indent=4)\n        repository.close()\n        """\n\n        # Plotting the outputs (fit, loss and accuracy), the coefficients.\n        [[a1], [a2]] = sess.run(A)\n        [[b]] = sess.run(b)\n        slope = -a2 / a1\n        y_intercept = b / a1\n        x1_vals = [d[1] for d in data]\n\n        best_fit = []\n        for i in x1_vals:\n            best_fit.append(slope * i + y_intercept)\n\n        feature_x = [d[1] for i, d in enumerate(data) if target[i] == 1]\n        feature_y = [d[0] for i, d in enumerate(data) if target[i] == 1]\n        not_feature_x = [d[1] for i, d in enumerate(data) if target[i] == -1]\n        not_feature_y = [d[0] for i, d in enumerate(data) if target[i] == -1]\n\n        plt.plot(feature_x, feature_y, \'o\', label=\'I. Distracted\')\n        plt.plot(not_feature_x, not_feature_y, \'x\', label=\'Not Distracted\')\n        plt.plot(x1_vals, best_fit, \'r-\', label=\'Linear Separator\', linewidth=3)\n        plt.ylim([0, 10])\n        plt.legend(loc=\'upper left\')\n        plt.title(\'Boundary Classification\')\n        plt.xlabel(\'Delta & Beta\')\n        plt.ylabel(\'targets\')\n        plt.show()\n\n        plt.plot(train_accuracy, \'k-\', label=\'Training Accuracy\')\n        plt.plot(test_accuracy, \'r--\', label=\'Test Accuracy\')\n        plt.title(\'Train and Test Set Accuracies\')\n        plt.xlabel(\'Generation\')\n        plt.ylabel(\'Accuracy\')\n        plt.legend(loc=\'lower right\')\n        plt.show()\n\n        plt.plot(loss_vec, \'k-\')\n        plt.title(\'Loss per Generation\')\n        plt.xlabel(\'Generation\')\n        plt.ylabel(\'Loss\')\n        plt.show()\n\n\n# Reading from the csv file.\npath = r\'/Users/KaushikBhimraj/Desktop/Merged1_Data.csv\'\n\n# List comprehension used to create numpy arrays for inputs and targets.\n# Removing the heading row and converting the string values to int.  \nI = [[line.split(\',\')[0], line.split(\',\')[1]] for line in open(path) if line[0:1] != \'\\n\'][1:]\nBetaDelta = np.array([[float(val[0]), float(val[1])] for val in I])\nTarget = np.array([line.split(\',\')[2] for line in open(path) if line[0:1] != \'\\n\'][1:])\n\n# Converting target to -1 or 1 format.\nT = np.array([float(1) if y == "Distracted\\n" else float(-1) for y in Target])\n\n# Calling the class object and the function inside it that will execute the suport vector algorithm.\nc = ClassifySVM()\nc.SupportVectorClassify(BetaDelta, T)\n```\n\nUnused variables:\n- `train_indices`\n- `test_indices`\n- `sess`\n- `no_end`\n- `test_record`'}, {'reason': 'stop', 'result': "from ipywidgets import interact\nfrom kf_book.book_plots import IntSlider, FloatSlider\n\ndef plot_FPFT(F00, F01, F10, F11, covar):   \n    plt.figure()\n    dt = 1.\n    x = np.array((0, 0.))\n    P = np.array(((1, covar), (covar, 2)))\n    F = np.array(((F00, F01), (F10, F11)))\n    plot_covariance_ellipse(x, P)\n    plot_covariance_ellipse(x, F @ P @ F.T, ec='r')\n    plt.gca().set_aspect('equal')\n    plt.xlim(-4, 4)\n    plt.ylim(-4, 4)\n    plt.xlabel('position')\n    plt.ylabel('velocity')\n    plt.show()\n                 \ninteract(plot_FPFT, \n         F00=IntSlider(value=1, min=0, max=2), \n         F01=FloatSlider(value=1, min=0, max=2, description='F01(dt)'),\n         F10=FloatSlider(value=0, min=0, max=2),\n         F11=FloatSlider(value=1, min=0, max=2),\n         covar=FloatSlider(value=0, min=0, max=1));```\n\nUnused variables: None"}]