[{'type': 'code', 'src': 'import pandas as pd \njeopardy = pd.read_csv("jeopardy.csv")\njeopardy.head(5)\n'}, {'type': 'code', 'src': 'jeopardy.columns'}, {'type': 'code', 'src': "jeopardy.columns = ['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question', 'Answer']"}, {'type': 'code', 'src': 'import re\ndef normalize_text(str):\n    str = str.lower()\n    str = re.sub("[^A-Za-z0-9\\s]", "", str)\n    return str\n    \njeopardy["clean_question"] = jeopardy["Question"].apply(normalize_text)\njeopardy["clean_answer"] = jeopardy["Answer"].apply(normalize_text)\n    \n    '}, {'type': 'code', 'src': 'import re\nimport pandas\ndef normalize_value(str):\n    str = re.sub("[^A-Za-z0-9\\s]", "", str)\n    try:\n        str = int(str)\n    except Exception:\n        str = 0\n    return str\n\njeopardy["clean_value"] = jeopardy["Value"].apply(normalize_value)\njeopardy["Air Date"] = pandas.to_datetime(jeopardy["Air Date"])'}, {'type': 'code', 'src': 'def count_matches(row):\n    split_answer = row["clean_answer"].split(" ")\n    split_question = row["clean_question"].split(" ")\n    if "the" in split_answer:\n        split_answer.remove("the")\n    if len(split_answer) == 0:\n        return 0\n    match_count = 0\n    for item in split_answer:\n        if item in split_question:\n            match_count += 1\n    return match_count / len(split_answer)\n\njeopardy["answer_in_question"] = jeopardy.apply(count_matches, axis=1)\n\njeopardy["answer_in_question"].mean()\n\n'}, {'type': 'markdown', 'src': "The answer only appears in the question about 6% of the time. This isn't a huge number, and we can't just hope that a question will enable us to figure out the answer. We'll have to study."}, {'type': 'code', 'src': 'question_overlap = []\nterms_used = set()\nfor i, row in jeopardy.iterrows():\n    split_question = row["clean_question"].split(" ")\n    split_question =  [item for item in split_question if len(item) > 5]\n    match_count = 0\n    for item in split_question:\n        if item in terms_used:\n            match_count += 1\n        else:\n            terms_used.add(item)\n    if len(split_question) > 0:\n        match_count = match_count / len(split_question)\n    question_overlap.append(match_count)\njeopardy["question_overlap"] = question_overlap\njeopardy["question_overlap"].mean()\n\n\n    \n'}, {'type': 'code', 'src': 'question_overlap = []\nterms_used = set()\nfor i, row in jeopardy.iterrows():\n        split_question = row["clean_question"].split(" ")\n        split_question = [q for q in split_question if len(q) > 5]\n        match_count = 0\n        for word in split_question:\n            if word in terms_used:\n                match_count += 1\n        for word in split_question:\n            terms_used.add(word)\n        if len(split_question) > 0:\n            match_count /= len(split_question)\n        question_overlap.append(match_count)\njeopardy["question_overlap"] = question_overlap\n\njeopardy["question_overlap"].mean()'}, {'type': 'markdown', 'src': "There is about 70% overlap between terms in new questions and terms in old questions. It does mean that it's worth looking more into the recycling of questions."}, {'type': 'code', 'src': 'def value(row):\n    value = 0\n    if row["clean_value"] > 800:\n        value = 1\n    return value\n\njeopardy["high_value"] = jeopardy.apply(value, axis=1)\n\n\n\n\ndef word_usage(word):\n    low_count = 0\n    high_count = 0\n    \n    for i, row in jeopardy.iterrows():\n        split_question = row["clean_question"].split(" ")\n        if word in split_question:\n            if row["high_value"] == 1:\n                high_count += 1\n            else: \n                low_count += 1\n    return high_count, low_count\n                \nobserved_expected = []   \ncomparison_terms = list(terms_used)[:5]\n\nfor term in comparison_terms:\n    observed_expected.append(word_usage(term))\n    \nobserved_expected\n                '}, {'type': 'code', 'src': "high_value_count = len(jeopardy[jeopardy['high_value']==1])\nlow_value_count = len(jeopardy[jeopardy['high_value']==0])\nchi_squared = []\n"}, {'type': 'code', 'src': 'from scipy.stats import chisquare\nimport numpy as np\n\nfor item in observed_expected:\n    total = sum(item)\n    total_prop = total/jeopardy.shape[0]\n    \n    high_value_exp = total_prop * high_value_count\n    low_value_exp = total_prop * low_value_count\n    \n    observed = np.array([item[0], item[1]])\n    expected = np.array([high_value_exp, low_value_exp])\n    chi_squared.append(chisquare(observed, expected))\n\nchi_squared\n    '}, {'type': 'code', 'src': ''}]