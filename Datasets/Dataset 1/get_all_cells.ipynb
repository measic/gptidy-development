{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# read in all commits in sample\n",
    "all_commits_in_sample = pd.read_csv(\"6All_Commits_in_Sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each unique notebook, take the latest commit\n",
    "first_commits = all_commits_in_sample.groupby(\"notebook\").first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all notebooks\n",
    "all_notebooks = pd.read_csv(\"1Notebook_Sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine which notebooks are missing from first_commits from all_notebooks\n",
    "missing_notebooks = all_notebooks[~all_notebooks[\"Repository\"].isin(first_commits[\"repo\"].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k9/bsfxsl8d74738cyp6h7w0vz80000gn/T/ipykernel_19852/1169057081.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_notebooks[\"commit\"] = \"\"\n",
      "remote: Repository not found.\n",
      "fatal: repository 'https://github.com/userkimcs/uit-grad.git/' not found\n",
      "remote: Repository not found.\n",
      "fatal: repository 'https://github.com/darshak10ramani/jupyternotebook.git/' not found\n",
      "remote: Repository not found.\n",
      "fatal: repository 'https://github.com/Oxxkar/PythonDataScienceHandbook.git/' not found\n",
      "remote: Repository not found.\n",
      "fatal: repository 'https://github.com/brucewuquant/ie598.git/' not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed:  4\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# get latest_commit_id\n",
    "missing_notebooks[\"commit\"] = \"\"\n",
    "failed = 0\n",
    "for notebook in missing_notebooks[\"Repository\"]:\n",
    "    command = f\"git ls-remote https://github.com/{notebook}.git\"\n",
    "    try:\n",
    "        output = subprocess.check_output(command, shell=True).decode(\"utf-8\")\n",
    "        latest_commit_id = output.split()[0]\n",
    "        missing_notebooks.loc[missing_notebooks[\"Repository\"] == notebook, \"commit\"] = latest_commit_id\n",
    "    except:\n",
    "        missing_notebooks.loc[missing_notebooks[\"Repository\"] == notebook, \"commit\"] = None\n",
    "        failed += 1\n",
    "print(\"Failed: \", failed)\n",
    "\n",
    "# drop repos that were not found\n",
    "missing_notebooks = missing_notebooks[missing_notebooks[\"commit\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename relevant columns\n",
    "missing_notebooks = missing_notebooks.rename(columns={\"Repository\": \"repo\", \"Notebook Path\": \"notebook\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make notebook the index column\n",
    "missing_notebooks = missing_notebooks.set_index(\"notebook\")\n",
    "# keep only repo, notebook, and commit columns in missing_notebooks\n",
    "missing_notebooks = missing_notebooks[[\"repo\", \"commit\"]]\n",
    "# keep only repo, notebook, and commit columns in first_commits\n",
    "first_commits = first_commits[[\"repo\", \"commit\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge missing_notebooks with first_commits\n",
    "merged = pd.concat([first_commits, missing_notebooks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_url(repo, commit_hash, notebook):\n",
    "    return f\"https://raw.githubusercontent.com/{repo}/{commit_hash}/{notebook}\"\n",
    "\n",
    "# Create a new column with the URL strings\n",
    "merged['url'] = merged.apply(lambda x: create_url(x['repo'], x['commit'], x.name), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each URL, replace any instance of '\\ ' with '%20'\n",
    "merged['url'] = merged['url'].str.replace(r'\\ ', '%20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  https://raw.githubusercontent.com/jpbacher/foreclosures/b321f02281384481e3c455f194e094b2adee9085/06_FinalScript.ipynb\n",
      "Error:  https://raw.githubusercontent.com/rfeinman/hw-mathtools/79c43583b73f8eb288cdef7d86e38ad17d0e5d2e/Feinman_Reuben_HW6/hw6.ipynb\n",
      "Error:  https://raw.githubusercontent.com/reedan88/QAQC_Sandbox/6788f56e857ddc6cbd2c117b67ccce2c17624aa3/Metadata_Review/Metadata_Review.ipynb\n",
      "Error:  https://raw.githubusercontent.com/stanlo229/MicrosoftMLwithPython/48d137dc459384c0645f5c90c3658bdf1fb96d90/Module5/Bias-Variance-Trade-Off.ipynb\n",
      "Error:  https://raw.githubusercontent.com/Rishivikram1/mxnet/768a0312b191d76d2a9ad273a030b3f15b17cffb/chapter02_supervised-learning/softmax-regression-scratch.ipynb\n",
      "Error:  https://raw.githubusercontent.com/jmartu/TFM/395c4a27c0d66fef032f9fe8e4cf2cc3c53cdae1/convnet/VGG16_04_bottleneck.ipynb\n",
      "Error:  https://raw.githubusercontent.com/SultanovAR/augmentation/6302b7c830945f50aa9d1c62c0dbb7b57bbe2bb6/deeppavlov/models/evolution/Results_analysis.ipynb\n",
      "Error:  https://raw.githubusercontent.com/invibe/ANEMO/bf4dbbaa2f921fa18b440d5c4e779eba8cadce93/dev/2018-06-08_Fit_position.ipynb\n",
      "Error:  https://raw.githubusercontent.com/gustavonalle/bfs/6ad29a7ec487620500d47ef200ec311cd63d5843/examples.ipynb\n",
      "Error:  https://raw.githubusercontent.com/PeteLowth/glm-utils/44d0c42ff13a8c579d6fdda285c286a413da157c/glm-build.ipynb\n",
      "Error:  https://raw.githubusercontent.com/naomi-e/ML-hw2/c12732b13d45147f178fc05f9d8f96bbb0c1b7be/hwa2.ipynb\n",
      "Error:  https://raw.githubusercontent.com/Vaibhav488/DataScience-iPython-notebooks/176172101d0628ff19dbe9ef28538b3820aefd9f/kaggle/titanic.ipynb\n",
      "Error:  https://raw.githubusercontent.com/babinyurii/cheet_sheets/bb2120a2c962e9c5f7066e9617b0a3daf0bf5098/matplotlib_cheet_sheet.ipynb\n",
      "Error:  https://raw.githubusercontent.com/biggstd/pyluminate/425970be4475ec459fe0e2b3f4f78829398995a6/notebooks/Al%20Review%20Figures.ipynb\n",
      "Error:  https://raw.githubusercontent.com/compercept/acm2017_abc/25d304018216573ad4e71a36b467732124118e19/notebooks/Tuberculosis.ipynb\n",
      "Error:  https://raw.githubusercontent.com/usgs-bcb/prov-it/6ff784b63dd25e70af623de0aa5088b3d483de89/prov-tutorial.ipynb\n",
      "Error:  https://raw.githubusercontent.com/KevinKrupa13/HackingChallenges/9f89a51aba13776ab8dbf7ff77617b0e9835de61/sorting_searching/selection_sort/selection_sort_solution.ipynb\n",
      "Error:  https://raw.githubusercontent.com/ChrisMats/MusicGAN/e5fc3d67fd76ac315f976b6c46bac5c66325f7e1/src/MusicGan.ipynb\n",
      "Error:  https://raw.githubusercontent.com/llv22/tensorflow_srclearnt/b416db37a20aa1945f928a2c253ae0a8a139c20f/tensorflow/contrib/eager/python/examples/nmt_with_attention/nmt_with_attention.ipynb\n",
      "Error:  https://raw.githubusercontent.com/tensorflow/agents/1233e328ec57aa81eb3a4232abc8e6c85758b5ac/tf_agents/colabs/2_environments_tutorial.ipynb\n",
      "Error:  https://raw.githubusercontent.com/stakky/tensorflow/cbfea2ccbe2fffde025fe018931e5c7a1a0db8b0/tensorflow/tools/docker/notebooks/3_mnist_from_scratch.ipynb\n",
      "Error:  https://raw.githubusercontent.com/krasserm/bayesian-machine-learning/a3b2583cd5dd4253347742973b6b63643955092e/variational_autoencoder.ipynb\n",
      "Error:  https://raw.githubusercontent.com/mth229/229-projects/6d98786c485702ff23e79780c206b22f4030845a/graphics.ipynb\n",
      "Total failed:  27\n"
     ]
    }
   ],
   "source": [
    "# fetch each notebook from github\n",
    "import requests\n",
    "def fetch_response_json(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "notebooks = []\n",
    "for url in merged['url']:\n",
    "    notebook = fetch_response_json(url)\n",
    "    if notebook is None:\n",
    "        print(\"Error: \", url)\n",
    "        failed += 1\n",
    "    else:\n",
    "        notebooks.append((url, notebook))\n",
    "\n",
    "print(\"Total failed: \", failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total failed:  37\n"
     ]
    }
   ],
   "source": [
    "# only support notebooks with version 4 or above\n",
    "# filter by supported notebooks and count the number of unsupported notebooks\n",
    "unsupported_count = 0\n",
    "supported = []\n",
    "for notebook in notebooks:\n",
    "    if notebook[1]['nbformat'] < 4:\n",
    "        unsupported_count += 1\n",
    "    else:\n",
    "        supported.append(notebook)\n",
    "failed += unsupported_count\n",
    "print(\"Total failed: \", failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each notebook, get each cell's source code\n",
    "def get_single_cell_src_lines(notebook, cell_id):\n",
    "        cell = notebook[1]['cells'][cell_id]\n",
    "        if type(cell['source']) == list:\n",
    "            src_lines = cell['source']\n",
    "        else:\n",
    "            assert type(cell['source']) == str\n",
    "            src_lines = cell['source'].split('\\n')\n",
    "        return (notebook[0], ''.join(src_lines))\n",
    "\n",
    "notebook_cells = []\n",
    "for notebook in supported:\n",
    "    cells = []\n",
    "    for cell_id in range(len(notebook[1]['cells'])):\n",
    "        # get only code cells\n",
    "        if notebook[1]['cells'][cell_id]['cell_type'] == 'code':\n",
    "            cell = get_single_cell_src_lines(notebook, cell_id)\n",
    "            cells.append(cell)\n",
    "    notebook_cells.append(cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty notebooks:  5\n",
      "Total failed (incl. empty):  42\n",
      "Total cells:  6344\n",
      "Empty cells:  246\n",
      "Nonempty cells:  6098\n",
      "Cells with more than one line:  4311\n"
     ]
    }
   ],
   "source": [
    "# count the total number of cells and total number of empty and nonempty cells\n",
    "empty_notebooks = 0\n",
    "total_cells = 0\n",
    "empty_cells = 0\n",
    "nonempty_cells = 0\n",
    "more_than_one_line = 0\n",
    "for notebook in notebook_cells:\n",
    "    if len(notebook) == 0:\n",
    "        empty_notebooks += 1\n",
    "        failed += 1\n",
    "        continue\n",
    "    total_cells += len(notebook)\n",
    "    for cell in notebook:\n",
    "        # empty cell\n",
    "        if cell[1] == '':\n",
    "            empty_cells += 1\n",
    "        # nonempty cell\n",
    "        elif cell[1] != '':\n",
    "            nonempty_cells += 1\n",
    "        # more than one code line\n",
    "        lines = cell[1].split('\\n')\n",
    "        comment_lines = 0\n",
    "        for line in lines:\n",
    "            if line.startswith('#') or line.strip() == '':\n",
    "                comment_lines += 1\n",
    "        if len(lines) - comment_lines > 1:\n",
    "            more_than_one_line += 1\n",
    "\n",
    "print(\"Empty notebooks: \", empty_notebooks)\n",
    "print(\"Total failed (incl. empty): \", failed)\n",
    "print(\"Total cells: \", total_cells)\n",
    "print(\"Empty cells: \", empty_cells)\n",
    "print(\"Nonempty cells: \", nonempty_cells)        \n",
    "print(\"Cells with more than one line: \", more_than_one_line)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove empty notebooks, empty cells, and cells with only one line (after removing comments and blank lines)\n",
    "# empty notebooks also count if all cells are empty or one line\n",
    "new_notebooks = []\n",
    "for notebook in notebook_cells:\n",
    "    new_notebooks.append([cell for cell in notebook if cell[1] != ''])\n",
    "notebook_cells = new_notebooks\n",
    "\n",
    "# new_notebooks = []\n",
    "# for notebook in notebook_cells:\n",
    "#     cells = []\n",
    "#     for cell in notebook:\n",
    "#         comment_lines = 0\n",
    "#         lines = cell.split('\\n')\n",
    "#         for line in lines:\n",
    "#             if line.startswith('#') or line.strip() == '':\n",
    "#                 comment_lines += 1\n",
    "#         if len(lines) - comment_lines > 1:\n",
    "#             cells.append(cell)\n",
    "#     new_notebooks.append(cells)\n",
    "# notebook_cells = new_notebooks\n",
    "        \n",
    "notebook_cells = [notebook for notebook in notebook_cells if len(notebook) != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of notebooks fetched:  233\n"
     ]
    }
   ],
   "source": [
    "# print number of notebooks fetched\n",
    "print(\"Number of notebooks fetched: \", len(notebook_cells))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cells:  6098\n"
     ]
    }
   ],
   "source": [
    "# get all cells\n",
    "all_cells = []\n",
    "for notebook in notebook_cells:\n",
    "    for cell in notebook:\n",
    "        all_cells.append(cell)\n",
    "\n",
    "print(\"Total cells: \", len(all_cells))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all cells to a folder called 'all_cells'\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"all_cells\"):\n",
    "    os.makedirs(\"all_cells\")\n",
    "\n",
    "for i in range(len(all_cells)):\n",
    "    with open(\"all_cells/\" + str(i) + \".py\", \"w\") as f:\n",
    "        f.write(all_cells[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print names of all urls into a single file called 'all_cells_urls.txt'\n",
    "with open(\"all_cells_urls.txt\", \"w\") as f:\n",
    "    for cell in all_cells:\n",
    "        f.write(cell[0] + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
