{"cells": [{"cell_type": "code", "execution_count": 19, "metadata": {"collapsed": false}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import os\n", "try:\n", "    import arcpy\n", "except ImportError:\n", "    pass\n", "\n", "OVERWRITE = True\n", "PATH = os.path.join('.', 'data')\n", "\n", "# TODO: There's some data that is inclued as a sort of separate table with the .xlsx file, that we are just throwing away at present\n", "# TODO: Handle combined precincts\n", "# TODO: Delete superfluous fields from derived_data.gdb/blocks"]}, {"cell_type": "code", "execution_count": 20, "metadata": {"collapsed": true}, "outputs": [], "source": ["def to_appropriate_column_name(s):\n", "    s = s.lower().replace(' ', '_')\n", "    s = ''.join([ch for ch in s if ch.isalnum() or ch == '_'])\n", "    return s"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Tables\n", "## Clean the population data"]}, {"cell_type": "code", "execution_count": 16, "metadata": {"collapsed": false}, "outputs": [{"data": {"text/html": ["<div>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>block</th>\n", "      <th>block_group</th>\n", "      <th>census_tract</th>\n", "      <th>american_indian_and_alaska_native</th>\n", "      <th>asian</th>\n", "      <th>black_or_african_american</th>\n", "      <th>hispanic_or_latino</th>\n", "      <th>native_hawaiian_and_other_pacific_islander</th>\n", "      <th>one_race_total</th>\n", "      <th>some_other_race</th>\n", "      <th>total_population</th>\n", "      <th>total_population_not_hispanic_or_latino</th>\n", "      <th>two_or_more_races</th>\n", "      <th>white</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>1000</td>\n", "      <td>1</td>\n", "      <td>010100</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>1001</td>\n", "      <td>1</td>\n", "      <td>010100</td>\n", "      <td>0</td>\n", "      <td>4</td>\n", "      <td>3</td>\n", "      <td>1</td>\n", "      <td>0</td>\n", "      <td>44</td>\n", "      <td>1</td>\n", "      <td>44</td>\n", "      <td>43</td>\n", "      <td>0</td>\n", "      <td>36</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>1002</td>\n", "      <td>1</td>\n", "      <td>010100</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>1003</td>\n", "      <td>1</td>\n", "      <td>010100</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>1004</td>\n", "      <td>1</td>\n", "      <td>010100</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "      <td>1</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "      <td>1</td>\n", "      <td>0</td>\n", "      <td>1</td>\n", "      <td>1</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["  block block_group census_tract  american_indian_and_alaska_native  asian  \\\n", "0  1000           1       010100                                  0      0   \n", "1  1001           1       010100                                  0      4   \n", "2  1002           1       010100                                  0      0   \n", "3  1003           1       010100                                  0      0   \n", "4  1004           1       010100                                  0      0   \n", "\n", "   black_or_african_american  hispanic_or_latino  \\\n", "0                          0                   0   \n", "1                          3                   1   \n", "2                          0                   0   \n", "3                          0                   0   \n", "4                          1                   0   \n", "\n", "   native_hawaiian_and_other_pacific_islander  one_race_total  \\\n", "0                                           0               0   \n", "1                                           0              44   \n", "2                                           0               0   \n", "3                                           0               0   \n", "4                                           0               1   \n", "\n", "   some_other_race  total_population  total_population_not_hispanic_or_latino  \\\n", "0                0                 0                                        0   \n", "1                1                44                                       43   \n", "2                0                 0                                        0   \n", "3                0                 0                                        0   \n", "4                0                 1                                        1   \n", "\n", "   two_or_more_races  white  \n", "0                  0      0  \n", "1                  0     36  \n", "2                  0      0  \n", "3                  0      0  \n", "4                  0      0  "]}, "execution_count": 16, "metadata": {}, "output_type": "execute_result"}], "source": ["pop_df = pd.read_excel(os.path.join(PATH, 'source_data', '2010_Pop_Block_County.xls'), sheetname='San Francisco County', header=4)\n", "\n", "pop_df = pd.read_excel(os.path.join(PATH, 'source_data', '2010_Pop_Block_County.xls'), sheetname='San Francisco County', header=4)\n", "pop_df = pop_df.drop('BLOCKS', axis='index').reset_index()\n", "pop_df = pop_df.rename(columns={'index': 'block_str'})\n", "\n", "records = []\n", "for ix, row in pop_df.iterrows():\n", "    splits = row['block_str'].split(', ')\n", "    record = row[[x for x in row.index if x != 'block_str']].to_dict()\n", "    record['block'] = str(splits[0].split('Block ')[-1])\n", "    record['block_group'] = str(splits[1].split('Block Group ')[-1])\n", "    census_tract = '0' + str(splits[2].split('Census Tract ')[-1].replace('.', ''))\n", "    census_tract += '0' * (6-len(census_tract))  # Even if it doesn't have a decimal part, needs to be 6 characters\n", "    record['census_tract'] = census_tract\n", "    records.append(record)\n", "pop_df = pd.DataFrame(records)\n", "\n", "pop_df.columns = [to_appropriate_column_name(x) for x in pop_df.columns]\n", "str_columns = ['block', 'block_group', 'census_tract']\n", "nonstr_columns = [x for x in pop_df.columns if x not in str_columns]\n", "pop_df.loc[:, nonstr_columns] = pop_df[nonstr_columns].astype(int)\n", "pop_df = pop_df[str_columns + nonstr_columns]\n", "pop_df.to_csv(os.path.join(PATH, 'derived_data', 'SF_2010_pop_block.csv'))\n", "pop_df.head()"]}, {"cell_type": "markdown", "metadata": {"collapsed": true}, "source": ["## Clean and split the election data"]}, {"cell_type": "code", "execution_count": 21, "metadata": {"collapsed": false}, "outputs": [], "source": ["vote_dfs = pd.read_excel(os.path.join(PATH, 'source_data', '20161206_sov.xlsx'), sheetname=None, header=3)\n", "\n", "# Since the sheet names get cut off, we can fix them using the Contents tab\n", "contents = vote_dfs['Contents'].copy()\n", "contents.columns = ['key', 'name']\n", "contents = contents.iloc[1:]\n", "contents['key'] = contents['key'].astype(int)\n", "contents = contents.set_index('key').to_dict(orient='index')\n", "\n", "fixed_names = {}\n", "for cut_name in vote_dfs:\n", "    if cut_name == 'Contents':\n", "        continue\n", "    key = int(cut_name[:3])\n", "    if key in contents:\n", "        prefix = cut_name[:6]\n", "        postfix = contents[key]['name']\n", "        fixed_names[prefix + postfix] = vote_dfs[cut_name]"]}, {"cell_type": "code", "execution_count": 22, "metadata": {"collapsed": false}, "outputs": [{"data": {"text/plain": ["Index([u'PrecinctName', u'ReportingType', u'PrecinctID', u'Precincts',\n", "       u'Registration', u'Ballots Cast', u'Turnout (%)', u'Yes', u'No',\n", "       u'Under Vote', u'Over Vote'],\n", "      dtype='object')"]}, "execution_count": 22, "metadata": {}, "output_type": "execute_result"}], "source": ["fixed_names.values()[0].columns"]}, {"cell_type": "code", "execution_count": 23, "metadata": {"collapsed": false}, "outputs": [], "source": ["for name, df in fixed_names.items():\n", "    if name == 'Contents':\n", "        continue\n", "    df = df[df['PrecinctName'].apply(lambda x: str(x).startswith('Pct '))]\n", "    df.columns = [to_appropriate_column_name(x.replace('(%)', 'Percent')) for x in df.columns]\n", "    df.to_csv(os.path.join(PATH, 'derived_data', '{}.csv'.format(name)), encoding='utf-8', index=False)\n", "    #####\n", "    agg_methods = {\n", "    'precincts': 'min',\n", "    'registration': 'min'\n", "    }\n", "    no_agg = ['OBJECTID', 'precinctname', 'reportingtype', 'precinctid', 'turnout_percent']\n", "    grouped_df = df.groupby('precinctid').agg({x: agg_methods.get(x, 'sum') for x in df.columns if x not in no_agg})\n", "    grouped_df.to_csv(os.path.join(PATH, 'derived_data', '{}.csv'.format('precinct_summary_' + name)), encoding='utf-8', index=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Make a geodatabase from the election CSVs"]}, {"cell_type": "code", "execution_count": 6, "metadata": {"collapsed": false}, "outputs": [{"data": {"text/plain": ["<Result 'C:\\\\Users\\\\Charles\\\\Documents\\\\ArcGIS\\\\SF_election_2016\\\\SF_vote_2016.gdb'>"]}, "execution_count": 6, "metadata": {}, "output_type": "execute_result"}], "source": ["if OVERWRITE:\n", "    arcpy.Delete_management(os.path.join(PATH, 'SF_vote_2016.gdb'))\n", "arcpy.CreateFileGDB_management(PATH, 'SF_vote_2016.gdb')\n", "arcpy.TableToGeodatabase_conversion(\n", "    [os.path.join(PATH, 'derived_data', '{}.csv'.format(x)) for x in fixed_names.keys()],\n", "    os.path.join(PATH, 'SF_vote_2016.gdb'))"]}, {"cell_type": "code", "execution_count": 7, "metadata": {"collapsed": false, "scrolled": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["T100___President_and_Vice_President complete\n", "T105___U_S__Senator complete\n", "T110___U_S__Representative__District_12 complete\n", "T115___U_S__Representative__District_13 complete\n", "T120___U_S__Representative__District_14 complete\n", "T125___State_Senate__District_11 complete\n", "T130___State_Assembly__District_17 complete\n", "T135___State_Assembly__District_19 complete\n", "T140___Board_of_Supervisors__District_1 complete\n", "T145___Board_of_Supervisors__District_3 complete\n", "T150___Board_of_Supervisors__District_5 complete\n", "T155___Board_of_Supervisors__District_7 complete\n", "T160___Board_of_Supervisors__District_9 complete\n", "T165___Board_of_Supervisors__District_11 complete\n", "T170___Superior_Court_Judge__Seat_7 complete\n", "T175___Member__Board_of_Education complete\n", "T180___Member__Community_College_Board complete\n", "T185___BART_Director__District_7 complete\n", "T190___BART_Director__District_9 complete\n", "T195___State_Proposition_51 complete\n", "T200___State_Proposition_52 complete\n", "T205___State_Proposition_53 complete\n", "T210___State_Proposition_54 complete\n", "T215___State_Proposition_55 complete\n", "T220___State_Proposition_56 complete\n", "T225___State_Proposition_57 complete\n", "T230___State_Proposition_58 complete\n", "T235___State_Proposition_59 complete\n", "T240___State_Proposition_60 complete\n", "T245___State_Proposition_61 complete\n", "T250___State_Proposition_62 complete\n", "T255___State_Proposition_63 complete\n", "T260___State_Proposition_64 complete\n", "T265___State_Proposition_65 complete\n", "T270___State_Proposition_66 complete\n", "T275___State_Proposition_67 complete\n", "T280___School_Measure_A complete\n", "T285___School_Measure_B complete\n", "T290___Local_Measure_C complete\n", "T295___Local_Measure_D complete\n", "T300___Local_Measure_E complete\n", "T305___Local_Measure_F complete\n", "T310___Local_Measure_G complete\n", "T315___Local_Measure_H complete\n", "T320___Local_Measure_I complete\n", "T325___Local_Measure_J complete\n", "T330___Local_Measure_K complete\n", "T335___Local_Measure_L complete\n", "T340___Local_Measure_M complete\n", "T345___Local_Measure_N complete\n", "T350___Local_Measure_O complete\n", "T355___Local_Measure_P complete\n", "T360___Local_Measure_Q complete\n", "T365___Local_Measure_R complete\n", "T370___Local_Measure_S complete\n", "T375___Local_Measure_T complete\n", "T380___Local_Measure_U complete\n", "T385___Local_Measure_V complete\n", "T390___Local_Measure_W complete\n", "T395___Local_Measure_X complete\n", "T400___District_Measure_RR complete\n"]}], "source": ["arcpy.env.workspace = os.path.join(PATH, 'SF_vote_2016.gdb')\n", "\n", "NO_TOUCH = ['OBJECTID', 'precinctname', 'reportingtype', 'precinctid']\n", "FLOAT = ['turnout_percent']\n", "\n", "for table in sorted(arcpy.ListTables()):\n", "    for field in arcpy.ListFields(table):\n", "        if field.name not in NO_TOUCH:\n", "            original_name = field.name\n", "            temp_name = field.name[:5] + '_temp'\n", "            arcpy.AddField_management(table, temp_name, 'FLOAT' if original_name in FLOAT else 'LONG')\n", "            arcpy.CalculateField_management(table, temp_name, u'!{}!'.format(original_name), \"PYTHON_9.3\")\n", "            arcpy.DeleteField_management(table, original_name)\n", "            arcpy.AlterField_management(table, temp_name, to_appropriate_column_name(original_name[:31]))\n", "    print('{} complete'.format(table))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Feature Classes\n", "## Spatial join blocks to precincts"]}, {"cell_type": "code", "execution_count": 9, "metadata": {"collapsed": false}, "outputs": [{"data": {"text/plain": ["<Result 'true'>"]}, "execution_count": 9, "metadata": {}, "output_type": "execute_result"}], "source": ["if OVERWRITE:\n", "    arcpy.Delete_management(os.path.join(PATH, 'source_data.gdb'))\n", "    arcpy.Delete_management(os.path.join(PATH, 'derived_data.gdb'))\n", "arcpy.CreateFileGDB_management(PATH, 'source_data.gdb')\n", "arcpy.CreateFileGDB_management(PATH, 'derived_data.gdb')\n", "arcpy.FeatureClassToGeodatabase_conversion(\n", "    [\n", "        os.path.join(PATH, 'source_data', 'Census 2010- Blocks for San Francisco', 'geo_export_72486aab-d116-414f-895d-9a7fbaa2a42c.shp'),\n", "        os.path.join(PATH, 'source_data', '2012lines', '2012lines', 'SF_DOE_Precincts_20120702.shp'),\n", "        os.path.join(PATH, 'source_data', '2012lines', '2012lines', 'SF_BOS_20120702_nowater.shp'),\n", "    ],\n", "    os.path.join(PATH, 'source_data.gdb'))\n", "arcpy.TableToGeodatabase_conversion(\n", "    os.path.join(PATH, 'derived_data', 'SF_2010_pop_block.cv'),\n", "    os.path.join(PATH, 'derived_data.gdb')\n", ")\n", "\n", "# We don't use a field mapping here because we actually want all the fields from both the target and join inputs\n", "arcpy.SpatialJoin_analysis(\n", "    os.path.join(PATH, 'source_data.gdb', 'geo_export_72486aab_d116_414f_895d_9a7fbaa2a42c'),\n", "    os.path.join(PATH, 'source_data.gdb', 'SF_DOE_Precincts_20120702'),\n", "    os.path.join(PATH, 'derived_data.gdb', 'blocks_join_precincts'),\n", "    match_option='WITHIN',\n", ")\n", "\n", "# Since some blocks don't fit in a precicnt, we at least want them to have a distict\n", "\n", "fms = arcpy.FieldMappings()\n", "for field in arcpy.ListFields(os.path.join(PATH, 'derived_data.gdb', 'blocks_join_precincts')):\n", "    if field.name.lower() == 'shape':\n", "        continue\n", "    map = arcpy.FieldMap()\n", "    map.addInputField(os.path.join(PATH, 'derived_data.gdb', 'blocks_join_precincts'), field.name)\n", "    fms.addFieldMap(map)\n", "map = arcpy.FieldMap()\n", "map.addInputField(os.path.join(PATH, 'source_data.gdb', 'SF_BOS_20120702_nowater'), 'DISTRICT')\n", "fms.addFieldMap(map)\n", "\n", "arcpy.SpatialJoin_analysis(\n", "    os.path.join(PATH, 'derived_data.gdb', 'blocks_join_precincts'),\n", "    os.path.join(PATH, 'source_data.gdb', 'SF_BOS_20120702_nowater'),\n", "    os.path.join(PATH, 'derived_data.gdb', 'pop_by_block'),\n", "    match_option='WITHIN',\n", "    field_mapping=fms\n", ")\n", "\n", "arcpy.AlterField_management(os.path.join(PATH, 'derived_data.gdb', 'pop_by_block'), 'Join_Count', 'join_count_precinct')\n", "arcpy.AlterField_management(os.path.join(PATH, 'derived_data.gdb', 'pop_by_block'), 'Join_Count_1', 'join_count_district')\n", "arcpy.Delete_management(os.path.join(PATH, 'derived_data.gdb', 'blocks_join_precincts'))"]}, {"cell_type": "markdown", "metadata": {"collapsed": true}, "source": ["## Join population data to blocks"]}, {"cell_type": "code", "execution_count": 10, "metadata": {"collapsed": false}, "outputs": [{"data": {"text/plain": ["<Result 'C:\\\\Users\\\\Charles\\\\Documents\\\\ArcGIS\\\\SF_election_2016\\\\derived_data.gdb\\\\pop_by_block'>"]}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}], "source": ["# First we have to make a precinct_id column, since PREC_2012 is text\n", "# arcpy.AddField_management(PATH + '\\\\derived_data.gdb\\\\pop_by_block', 'precinct_id', 'LONG')\n", "# arcpy.CalculateField_management(PATH + '\\\\derived_data.gdb\\\\pop_by_block', 'precinct_id', '!PREC_2012!', \"PYTHON_9.3\")\n", "\n", "# Create join key columns, this shit is so jenky\n", "arcpy.AddField_management(os.path.join(PATH, 'derived_data.gdb', 'pop_by_block'), 'pop_block_join_key', 'TEXT')\n", "arcpy.CalculateField_management(\n", "    os.path.join(PATH, 'derived_data.gdb', 'pop_by_block'),\n", "    'pop_block_join_key',\n", "    'str(!tractce10!) + str(!blockce10!)',\n", "    'PYTHON_9.3'\n", ")\n", "arcpy.AddField_management(os.path.join(PATH, 'derived_data.gdb', 'SF_2010_pop_block'), 'pop_block_join_key', 'TEXT')\n", "arcpy.CalculateField_management(\n", "    os.path.join(PATH, 'derived_data.gdb', 'SF_2010_pop_block'),\n", "    'pop_block_join_key',\n", "    \"'0' + str(!census_tract!) + str(!block!)\",\n", "    'PYTHON_9.3'\n", ")\n", "\n", "# Now do the actual join\n", "arcpy.JoinField_management(\n", "    os.path.join(PATH, 'derived_data.gdb', 'pop_by_block'),\n", "    'pop_block_join_key',\n", "    os.path.join(PATH, 'derived_data.gdb', 'SF_2010_pop_block'),\n", "    'pop_block_join_key'\n", ")\n", "\n", "# Also make a precinct_id column, since PREC_2012 is text\n", "arcpy.AddField_management(os.path.join(PATH, 'derived_data.gdb', 'pop_by_block'), 'precinct_id', 'LONG')\n", "func = \"\"\"def to_int(x):\n", "    if sum([a.isalnum() for a in x]) == 0:\n", "        return None\n", "    else:\n", "        return int(x)\n", "    \"\"\"\n", "arcpy.CalculateField_management(\n", "    os.path.join(PATH, 'derived_data.gdb', 'pop_by_block'),\n", "    'precinct_id',\n", "    'to_int(!PREC_2012!)',\n", "    'PYTHON_9.3',\n", "    func\n", ")"]}, {"cell_type": "code", "execution_count": 11, "metadata": {"collapsed": false}, "outputs": [{"data": {"text/plain": ["<Result 'C:\\\\Users\\\\Charles\\\\Documents\\\\ArcGIS\\\\SF_election_2016\\\\derived_data.gdb\\\\pop_by_precinct'>"]}, "execution_count": 11, "metadata": {}, "output_type": "execute_result"}], "source": ["agg_methods = {\n", "    'SupDist': 'MIN',\n", "    'BARTDist': 'MIN',\n", "    'AssemDist': 'MIN',\n", "    'CongDist': 'MIN',\n", "    'NeighRep': 'MIN',\n", "    'PREC_2012': 'MIN',\n", "    'PREC_2010': 'MIN',\n", "    'DISTRICT': 'MIN',\n", "    'american_indian_and_alaska_native': 'SUM',\n", "    'asian': 'SUM',\n", "    'black_or_african_american': 'SUM',\n", "    'hispanic_or_latino': 'SUM',\n", "    'native_hawaiian_and_other_pacific_islander': 'SUM',\n", "    'one_race_total': 'SUM',\n", "    'some_other_race': 'SUM',\n", "    'total_population': 'SUM',\n", "    'total_population_not_hispanic_or_latino': 'SUM',\n", "    'two_or_more_races': 'SUM',\n", "    'white': 'SUM'\n", "}\n", "\n", "\n", "if OVERWRITE:\n", "    arcpy.Delete_management(os.path.join(PATH, 'derived_data.gdb', 'pop_by_precinct'))\n", "arcpy.Statistics_analysis(\n", "    os.path.join(PATH, 'derived_data.gdb', 'pop_by_block'),\n", "    os.path.join(PATH, 'derived_data.gdb', 'pop_by_precinct'),\n", "    agg_methods.items(),\n", "    'precinct_id'\n", ")\n", "\n", "for field in arcpy.ListFields(os.path.join(PATH, 'derived_data.gdb', 'pop_by_precinct')):\n", "    if field.name[:4] in ('SUM_', 'MIN_'):\n", "        arcpy.AlterField_management(os.path.join(PATH, 'derived_data.gdb', 'pop_by_precinct'), field.name, field.name[4:35])\n", "arcpy.AlterField_management(os.path.join(PATH, 'derived_data.gdb', 'pop_by_precinct'), 'FREQUENCY', 'num_blocks')"]}], "metadata": {"anaconda-cloud": {}, "kernelspec": {"display_name": "Python [Root]", "language": "python", "name": "Python [Root]"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 2}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython2", "version": "2.7.12"}}, "nbformat": 4, "nbformat_minor": 0}